{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbtMxnkXCKK8"
   },
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1629097340229,
     "user": {
      "displayName": "Prashant Bande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEKnUOejpvS-UF0xdxbhX8fVTa3QebhtPWUxF7QA=s64",
      "userId": "14011116341686666445"
     },
     "user_tz": -330
    },
    "id": "fjTk3luaCKK_"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# for building DQN model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jQL8KL_CKLE"
   },
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1629097342115,
     "user": {
      "displayName": "Prashant Bande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEKnUOejpvS-UF0xdxbhX8fVTa3QebhtPWUxF7QA=s64",
      "userId": "14011116341686666445"
     },
     "user_tz": -330
    },
    "id": "dca9NJcJCKLE"
   },
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yihjX6jKCKLF"
   },
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1629097343060,
     "user": {
      "displayName": "Prashant Bande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEKnUOejpvS-UF0xdxbhX8fVTa3QebhtPWUxF7QA=s64",
      "userId": "14011116341686666445"
     },
     "user_tz": -330
    },
    "id": "bDd5Cw_FCKLF"
   },
   "outputs": [],
   "source": [
    "states_track = collections.defaultdict(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1629097344347,
     "user": {
      "displayName": "Prashant Bande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEKnUOejpvS-UF0xdxbhX8fVTa3QebhtPWUxF7QA=s64",
      "userId": "14011116341686666445"
     },
     "user_tz": -330
    },
    "id": "tiik23CcCKLF"
   },
   "outputs": [],
   "source": [
    "# Initialise states to be tracked\n",
    "def initialise_tracking_states():\n",
    "    sample_q_values = [((4,3,2),(4,1)),((3,4,2),(2,3)),((2,2,2),(3,2)),((1,22,4),(1,3)), ((4,24,3),(3,4))]     \n",
    "    for q_values in sample_q_values:\n",
    "        state = q_values[0]\n",
    "        action = q_values[1]\n",
    "        states_track[state][action] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1629097345564,
     "user": {
      "displayName": "Prashant Bande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEKnUOejpvS-UF0xdxbhX8fVTa3QebhtPWUxF7QA=s64",
      "userId": "14011116341686666445"
     },
     "user_tz": -330
    },
    "id": "ggCxbAj3CKLG"
   },
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ko0ImRnKCKLH"
   },
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1629097348125,
     "user": {
      "displayName": "Prashant Bande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEKnUOejpvS-UF0xdxbhX8fVTa3QebhtPWUxF7QA=s64",
      "userId": "14011116341686666445"
     },
     "user_tz": -330
    },
    "id": "Oh0-_Bb3CKLH"
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, discount_factor=0.90, learning_rate=0.001,\n",
    "                 epsilon=1, epsilon_decay=0.0003, epsilon_min=0.00001):\n",
    "        # Define size of state and action and all hyperparameters\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon_max = epsilon\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.batch_size = 32\n",
    "        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        \n",
    "        # Initialize the value of the states tracked\n",
    "        self.states_tracked = []\n",
    "        self.track_state = np.array(env.state_encod_arch1([0,0,0])).reshape(1, 36)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets   \n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "    def get_action(self, state, action_space, possible_actions_index):\n",
    "        # get action from model using epsilon-greedy policy\n",
    "        # Decay in Îµ after we generate each sample from the environment\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            index = random.randrange(len(possible_actions_index))\n",
    "            action_index = possible_actions_index[index]\n",
    "            action = action_space[action_index]\n",
    "            return action_index, action\n",
    "\n",
    "        else:\n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "\n",
    "            state = np.array(state).reshape(1, self.state_size)\n",
    "            q_value = self.model.predict(state)\n",
    "            \n",
    "            return np.argmax(q_value[0]), action_space[np.argmax(q_value[0])]\n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state):\n",
    "        # save sample <s,a,r,s'> to the replay memory\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "\n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    @tf.function # To train fast\n",
    "    def train_model(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            update_output = np.zeros((self.batch_size, self.state_size))  # write here\n",
    "            update_input = np.zeros((self.batch_size, self.state_size))  # write here\n",
    "            actions, rewards = [], []\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state = mini_batch[i]\n",
    "                update_input[i] = state\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                update_output[i] = next_state\n",
    "\n",
    "                # Predict the target from earlier model\n",
    "                target = self.model.predict(update_input)\n",
    "                # Get the target for the Q-network\n",
    "                target_qval = self.model.predict(update_output)\n",
    "                # Update your 'update_output' and 'update_input' batch\n",
    "            for i in range(self.batch_size):\n",
    "                target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "            # Fit your model and track the loss values\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "    \n",
    "    def store_q_values(self):\n",
    "        \"\"\" We are keeping track of q value for state [0,0,0] and action (0,2)\"\"\"\n",
    "        q_value = self.model.predict(self.track_state)\n",
    "        self.states_tracked.append(q_value[0][2])\n",
    "            \n",
    "    def save(self, name):\n",
    "        self.model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1629097351117,
     "user": {
      "displayName": "Prashant Bande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEKnUOejpvS-UF0xdxbhX8fVTa3QebhtPWUxF7QA=s64",
      "userId": "14011116341686666445"
     },
     "user_tz": -330
    },
    "id": "pmfZCQT7CKLI"
   },
   "outputs": [],
   "source": [
    "Episodes = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tLBVvczCKLI"
   },
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9805148,
     "status": "ok",
     "timestamp": 1629107157561,
     "user": {
      "displayName": "Prashant Bande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEKnUOejpvS-UF0xdxbhX8fVTa3QebhtPWUxF7QA=s64",
      "userId": "14011116341686666445"
     },
     "user_tz": -330
    },
    "id": "d9hV6GDRCKLJ",
    "outputId": "e2cceb9f-9a8e-4f57-a6f6-4cb900fa17b0",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "state terminated\n",
      "episode 2502, reward 205.0, memory_length 2000, epsilon 0.47208849698616884\n",
      "state terminated\n",
      "episode 2503, reward 94.0, memory_length 2000, epsilon 0.47194689467848117\n",
      "state terminated\n",
      "episode 2504, reward -50.0, memory_length 2000, epsilon 0.4718053348451143\n",
      "state terminated\n",
      "episode 2505, reward 105.0, memory_length 2000, epsilon 0.4716638174733279\n",
      "state terminated\n",
      "episode 2506, reward 45.0, memory_length 2000, epsilon 0.4715223425503854\n",
      "state terminated\n",
      "episode 2507, reward 156.0, memory_length 2000, epsilon 0.4713809100635541\n",
      "state terminated\n",
      "episode 2508, reward 330.0, memory_length 2000, epsilon 0.47123952000010494\n",
      "state terminated\n",
      "episode 2509, reward -40.0, memory_length 2000, epsilon 0.47109817234731294\n",
      "state terminated\n",
      "episode 2510, reward -7.0, memory_length 2000, epsilon 0.47095686709245677\n",
      "state terminated\n",
      "episode 2511, reward 36.0, memory_length 2000, epsilon 0.47081560422281893\n",
      "state terminated\n",
      "episode 2512, reward 3.0, memory_length 2000, epsilon 0.4706743837256858\n",
      "state terminated\n",
      "episode 2513, reward 208.0, memory_length 2000, epsilon 0.47053320558834755\n",
      "state terminated\n",
      "episode 2514, reward 129.0, memory_length 2000, epsilon 0.47039206979809806\n",
      "state terminated\n",
      "episode 2515, reward -43.0, memory_length 2000, epsilon 0.4702509763422353\n",
      "state terminated\n",
      "episode 2516, reward -81.0, memory_length 2000, epsilon 0.4701099252080606\n",
      "state terminated\n",
      "episode 2517, reward 108.0, memory_length 2000, epsilon 0.4699689163828795\n",
      "state terminated\n",
      "episode 2518, reward 45.0, memory_length 2000, epsilon 0.4698279498540012\n",
      "state terminated\n",
      "episode 2519, reward -5.0, memory_length 2000, epsilon 0.46968702560873876\n",
      "state terminated\n",
      "episode 2520, reward -6.0, memory_length 2000, epsilon 0.4695461436344089\n",
      "state terminated\n",
      "episode 2521, reward 7.0, memory_length 2000, epsilon 0.4694053039183323\n",
      "state terminated\n",
      "episode 2522, reward 72.0, memory_length 2000, epsilon 0.46926450644783335\n",
      "state terminated\n",
      "episode 2523, reward -245.0, memory_length 2000, epsilon 0.4691237512102403\n",
      "state terminated\n",
      "episode 2524, reward 189.0, memory_length 2000, epsilon 0.46898303819288517\n",
      "state terminated\n",
      "episode 2525, reward 201.0, memory_length 2000, epsilon 0.4688423673831038\n",
      "state terminated\n",
      "episode 2526, reward 104.0, memory_length 2000, epsilon 0.46870173876823584\n",
      "state terminated\n",
      "episode 2527, reward -37.0, memory_length 2000, epsilon 0.4685611523356247\n",
      "state terminated\n",
      "episode 2528, reward 62.0, memory_length 2000, epsilon 0.4684206080726175\n",
      "state terminated\n",
      "episode 2529, reward -25.0, memory_length 2000, epsilon 0.4682801059665654\n",
      "state terminated\n",
      "episode 2530, reward 93.0, memory_length 2000, epsilon 0.4681396460048231\n",
      "state terminated\n",
      "episode 2531, reward 89.0, memory_length 2000, epsilon 0.4679992281747493\n",
      "state terminated\n",
      "episode 2532, reward 167.0, memory_length 2000, epsilon 0.4678588524637064\n",
      "state terminated\n",
      "episode 2533, reward -5.0, memory_length 2000, epsilon 0.46771851885906046\n",
      "state terminated\n",
      "episode 2534, reward 36.0, memory_length 2000, epsilon 0.46757822734818155\n",
      "state terminated\n",
      "episode 2535, reward 80.0, memory_length 2000, epsilon 0.46743797791844344\n",
      "state terminated\n",
      "episode 2536, reward 122.0, memory_length 2000, epsilon 0.46729777055722366\n",
      "state terminated\n",
      "episode 2537, reward 282.0, memory_length 2000, epsilon 0.46715760525190353\n",
      "state terminated\n",
      "episode 2538, reward 354.0, memory_length 2000, epsilon 0.46701748198986814\n",
      "state terminated\n",
      "episode 2539, reward 354.0, memory_length 2000, epsilon 0.46687740075850653\n",
      "state terminated\n",
      "episode 2540, reward 208.0, memory_length 2000, epsilon 0.4667373615452113\n",
      "state terminated\n",
      "episode 2541, reward -87.0, memory_length 2000, epsilon 0.4665973643373788\n",
      "state terminated\n",
      "episode 2542, reward -194.0, memory_length 2000, epsilon 0.46645740912240957\n",
      "state terminated\n",
      "episode 2543, reward -32.0, memory_length 2000, epsilon 0.4663174958877074\n",
      "state terminated\n",
      "episode 2544, reward -99.0, memory_length 2000, epsilon 0.4661776246206802\n",
      "state terminated\n",
      "episode 2545, reward 31.0, memory_length 2000, epsilon 0.46603779530873946\n",
      "state terminated\n",
      "episode 2546, reward -71.0, memory_length 2000, epsilon 0.4658980079393007\n",
      "state terminated\n",
      "episode 2547, reward 228.0, memory_length 2000, epsilon 0.4657582624997829\n",
      "state terminated\n",
      "episode 2548, reward 214.0, memory_length 2000, epsilon 0.46561855897760906\n",
      "state terminated\n",
      "episode 2549, reward 4.0, memory_length 2000, epsilon 0.46547889736020587\n",
      "state terminated\n",
      "episode 2550, reward 83.0, memory_length 2000, epsilon 0.4653392776350037\n",
      "state terminated\n",
      "episode 2551, reward 276.0, memory_length 2000, epsilon 0.46519969978943687\n",
      "state terminated\n",
      "episode 2552, reward 71.0, memory_length 2000, epsilon 0.46506016381094334\n",
      "state terminated\n",
      "episode 2553, reward 284.0, memory_length 2000, epsilon 0.4649206696869649\n",
      "state terminated\n",
      "episode 2554, reward 251.0, memory_length 2000, epsilon 0.464781217404947\n",
      "state terminated\n",
      "episode 2555, reward -9.0, memory_length 2000, epsilon 0.464641806952339\n",
      "state terminated\n",
      "episode 2556, reward 108.0, memory_length 2000, epsilon 0.4645024383165939\n",
      "state terminated\n",
      "episode 2557, reward 270.0, memory_length 2000, epsilon 0.4643631114851686\n",
      "state terminated\n",
      "episode 2558, reward 177.0, memory_length 2000, epsilon 0.4642238264455236\n",
      "state terminated\n",
      "episode 2559, reward -45.0, memory_length 2000, epsilon 0.4640845831851233\n",
      "state terminated\n",
      "episode 2560, reward 238.0, memory_length 2000, epsilon 0.46394538169143584\n",
      "state terminated\n",
      "episode 2561, reward 181.0, memory_length 2000, epsilon 0.46380622195193305\n",
      "state terminated\n",
      "episode 2562, reward 28.0, memory_length 2000, epsilon 0.46366710395409055\n",
      "state terminated\n",
      "episode 2563, reward 56.0, memory_length 2000, epsilon 0.4635280276853877\n",
      "state terminated\n",
      "episode 2564, reward 261.0, memory_length 2000, epsilon 0.4633889931333076\n",
      "state terminated\n",
      "episode 2565, reward 142.0, memory_length 2000, epsilon 0.46325000028533725\n",
      "state terminated\n",
      "episode 2566, reward -91.0, memory_length 2000, epsilon 0.4631110491289673\n",
      "state terminated\n",
      "episode 2567, reward 296.0, memory_length 2000, epsilon 0.46297213965169204\n",
      "state terminated\n",
      "episode 2568, reward 383.0, memory_length 2000, epsilon 0.4628332718410096\n",
      "state terminated\n",
      "episode 2569, reward 48.0, memory_length 2000, epsilon 0.462694445684422\n",
      "state terminated\n",
      "episode 2570, reward -69.0, memory_length 2000, epsilon 0.46255566116943475\n",
      "state terminated\n",
      "episode 2571, reward 79.0, memory_length 2000, epsilon 0.4624169182835574\n",
      "state terminated\n",
      "episode 2572, reward 183.0, memory_length 2000, epsilon 0.462278217014303\n",
      "state terminated\n",
      "episode 2573, reward 157.0, memory_length 2000, epsilon 0.4621395573491884\n",
      "state terminated\n",
      "episode 2574, reward 270.0, memory_length 2000, epsilon 0.4620009392757343\n",
      "state terminated\n",
      "episode 2575, reward 93.0, memory_length 2000, epsilon 0.46186236278146503\n",
      "state terminated\n",
      "episode 2576, reward -6.0, memory_length 2000, epsilon 0.46172382785390875\n",
      "state terminated\n",
      "episode 2577, reward 50.0, memory_length 2000, epsilon 0.4615853344805973\n",
      "state terminated\n",
      "episode 2578, reward 29.0, memory_length 2000, epsilon 0.4614468826490662\n",
      "state terminated\n",
      "episode 2579, reward 65.0, memory_length 2000, epsilon 0.4613084723468549\n",
      "state terminated\n",
      "episode 2580, reward 115.0, memory_length 2000, epsilon 0.46117010356150645\n",
      "state terminated\n",
      "episode 2581, reward -172.0, memory_length 2000, epsilon 0.4610317762805676\n",
      "state terminated\n",
      "episode 2582, reward 112.0, memory_length 2000, epsilon 0.4608934904915889\n",
      "state terminated\n",
      "episode 2583, reward 5.0, memory_length 2000, epsilon 0.46075524618212466\n",
      "state terminated\n",
      "episode 2584, reward -23.0, memory_length 2000, epsilon 0.4606170433397329\n",
      "state terminated\n",
      "episode 2585, reward -50.0, memory_length 2000, epsilon 0.46047888195197534\n",
      "state terminated\n",
      "episode 2586, reward 137.0, memory_length 2000, epsilon 0.4603407620064175\n",
      "state terminated\n",
      "episode 2587, reward 318.0, memory_length 2000, epsilon 0.46020268349062854\n",
      "state terminated\n",
      "episode 2588, reward 264.0, memory_length 2000, epsilon 0.46006464639218136\n",
      "state terminated\n",
      "episode 2589, reward -109.0, memory_length 2000, epsilon 0.45992665069865274\n",
      "state terminated\n",
      "episode 2590, reward -15.0, memory_length 2000, epsilon 0.459788696397623\n",
      "state terminated\n",
      "episode 2591, reward -138.0, memory_length 2000, epsilon 0.45965078347667615\n",
      "state terminated\n",
      "episode 2592, reward 126.0, memory_length 2000, epsilon 0.45951291192340016\n",
      "state terminated\n",
      "episode 2593, reward 59.0, memory_length 2000, epsilon 0.4593750817253866\n",
      "state terminated\n",
      "episode 2594, reward 29.0, memory_length 2000, epsilon 0.4592372928702307\n",
      "state terminated\n",
      "episode 2595, reward 20.0, memory_length 2000, epsilon 0.4590995453455314\n",
      "state terminated\n",
      "episode 2596, reward 75.0, memory_length 2000, epsilon 0.45896183913889155\n",
      "state terminated\n",
      "episode 2597, reward -284.0, memory_length 2000, epsilon 0.45882417423791755\n",
      "state terminated\n",
      "episode 2598, reward 75.0, memory_length 2000, epsilon 0.45868655063021946\n",
      "state terminated\n",
      "episode 2599, reward 51.0, memory_length 2000, epsilon 0.45854896830341124\n",
      "state terminated\n",
      "episode 2600, reward -99.0, memory_length 2000, epsilon 0.4584114272451105\n",
      "state terminated\n",
      "episode 2601, reward -27.0, memory_length 2000, epsilon 0.4582739274429386\n",
      "state terminated\n",
      "episode 2602, reward -336.0, memory_length 2000, epsilon 0.4581364688845204\n",
      "state terminated\n",
      "episode 2603, reward -115.0, memory_length 2000, epsilon 0.45799905155748477\n",
      "state terminated\n",
      "episode 2604, reward 90.0, memory_length 2000, epsilon 0.45786167544946405\n",
      "state terminated\n",
      "episode 2605, reward -144.0, memory_length 2000, epsilon 0.4577243405480944\n",
      "state terminated\n",
      "episode 2606, reward -335.0, memory_length 2000, epsilon 0.45758704684101575\n",
      "state terminated\n",
      "episode 2607, reward -122.0, memory_length 2000, epsilon 0.4574497943158716\n",
      "state terminated\n",
      "episode 2608, reward 120.0, memory_length 2000, epsilon 0.4573125829603092\n",
      "state terminated\n",
      "episode 2609, reward 162.0, memory_length 2000, epsilon 0.4571754127619797\n",
      "state terminated\n",
      "episode 2610, reward -181.0, memory_length 2000, epsilon 0.4570382837085376\n",
      "state terminated\n",
      "episode 2611, reward 83.0, memory_length 2000, epsilon 0.4569011957876413\n",
      "state terminated\n",
      "episode 2612, reward 307.0, memory_length 2000, epsilon 0.45676414898695294\n",
      "state terminated\n",
      "episode 2613, reward 213.0, memory_length 2000, epsilon 0.45662714329413834\n",
      "state terminated\n",
      "episode 2614, reward 120.0, memory_length 2000, epsilon 0.4564901786968669\n",
      "state terminated\n",
      "episode 2615, reward -91.0, memory_length 2000, epsilon 0.4563532551828119\n",
      "state terminated\n",
      "episode 2616, reward 155.0, memory_length 2000, epsilon 0.45621637273965016\n",
      "state terminated\n",
      "episode 2617, reward 186.0, memory_length 2000, epsilon 0.4560795313550623\n",
      "state terminated\n",
      "episode 2618, reward -131.0, memory_length 2000, epsilon 0.4559427310167325\n",
      "state terminated\n",
      "episode 2619, reward 48.0, memory_length 2000, epsilon 0.4558059717123488\n",
      "state terminated\n",
      "episode 2620, reward -201.0, memory_length 2000, epsilon 0.4556692534296029\n",
      "state terminated\n",
      "episode 2621, reward 67.0, memory_length 2000, epsilon 0.45553257615619014\n",
      "state terminated\n",
      "episode 2622, reward 8.0, memory_length 2000, epsilon 0.45539593987980953\n",
      "state terminated\n",
      "episode 2623, reward -9.0, memory_length 2000, epsilon 0.4552593445881638\n",
      "state terminated\n",
      "episode 2624, reward -102.0, memory_length 2000, epsilon 0.45512279026895935\n",
      "state terminated\n",
      "episode 2625, reward -268.0, memory_length 2000, epsilon 0.4549862769099064\n",
      "state terminated\n",
      "episode 2626, reward 171.0, memory_length 2000, epsilon 0.4548498044987186\n",
      "state terminated\n",
      "episode 2627, reward 180.0, memory_length 2000, epsilon 0.4547133730231136\n",
      "state terminated\n",
      "episode 2628, reward -153.0, memory_length 2000, epsilon 0.45457698247081246\n",
      "state terminated\n",
      "episode 2629, reward -212.0, memory_length 2000, epsilon 0.45444063282954\n",
      "state terminated\n",
      "episode 2630, reward 252.0, memory_length 2000, epsilon 0.4543043240870248\n",
      "state terminated\n",
      "episode 2631, reward -126.0, memory_length 2000, epsilon 0.45416805623099915\n",
      "state terminated\n",
      "episode 2632, reward 287.0, memory_length 2000, epsilon 0.45403182924919877\n",
      "state terminated\n",
      "episode 2633, reward 12.0, memory_length 2000, epsilon 0.4538956431293634\n",
      "state terminated\n",
      "episode 2634, reward 159.0, memory_length 2000, epsilon 0.45375949785923625\n",
      "state terminated\n",
      "episode 2635, reward 10.0, memory_length 2000, epsilon 0.45362339342656416\n",
      "state terminated\n",
      "episode 2636, reward -126.0, memory_length 2000, epsilon 0.45348732981909773\n",
      "state terminated\n",
      "episode 2637, reward 165.0, memory_length 2000, epsilon 0.4533513070245914\n",
      "state terminated\n",
      "episode 2638, reward 114.0, memory_length 2000, epsilon 0.453215325030803\n",
      "state terminated\n",
      "episode 2639, reward -25.0, memory_length 2000, epsilon 0.453079383825494\n",
      "state terminated\n",
      "episode 2640, reward 44.0, memory_length 2000, epsilon 0.45294348339643004\n",
      "state terminated\n",
      "episode 2641, reward -177.0, memory_length 2000, epsilon 0.4528076237313798\n",
      "state terminated\n",
      "episode 2642, reward -43.0, memory_length 2000, epsilon 0.452671804818116\n",
      "state terminated\n",
      "episode 2643, reward 179.0, memory_length 2000, epsilon 0.45253602664441495\n",
      "state terminated\n",
      "episode 2644, reward -235.0, memory_length 2000, epsilon 0.45240028919805664\n",
      "state terminated\n",
      "episode 2645, reward 256.0, memory_length 2000, epsilon 0.4522645924668246\n",
      "state terminated\n",
      "episode 2646, reward 273.0, memory_length 2000, epsilon 0.4521289364385062\n",
      "state terminated\n",
      "episode 2647, reward 144.0, memory_length 2000, epsilon 0.45199332110089246\n",
      "state terminated\n",
      "episode 2648, reward 227.0, memory_length 2000, epsilon 0.4518577464417779\n",
      "state terminated\n",
      "episode 2649, reward 56.0, memory_length 2000, epsilon 0.4517222124489607\n",
      "state terminated\n",
      "episode 2650, reward 269.0, memory_length 2000, epsilon 0.45158671911024306\n",
      "state terminated\n",
      "episode 2651, reward -198.0, memory_length 2000, epsilon 0.4514512664134304\n",
      "state terminated\n",
      "episode 2652, reward 301.0, memory_length 2000, epsilon 0.451315854346332\n",
      "state terminated\n",
      "episode 2653, reward -19.0, memory_length 2000, epsilon 0.4511804828967609\n",
      "state terminated\n",
      "episode 2654, reward -169.0, memory_length 2000, epsilon 0.4510451520525335\n",
      "state terminated\n",
      "episode 2655, reward 211.0, memory_length 2000, epsilon 0.4509098618014701\n",
      "state terminated\n",
      "episode 2656, reward -253.0, memory_length 2000, epsilon 0.45077461213139447\n",
      "state terminated\n",
      "episode 2657, reward -50.0, memory_length 2000, epsilon 0.45063940303013433\n",
      "state terminated\n",
      "episode 2658, reward 81.0, memory_length 2000, epsilon 0.4505042344855208\n",
      "state terminated\n",
      "episode 2659, reward -97.0, memory_length 2000, epsilon 0.4503691064853885\n",
      "state terminated\n",
      "episode 2660, reward -9.0, memory_length 2000, epsilon 0.45023401901757626\n",
      "state terminated\n",
      "episode 2661, reward -133.0, memory_length 2000, epsilon 0.450098972069926\n",
      "state terminated\n",
      "episode 2662, reward -82.0, memory_length 2000, epsilon 0.44996396563028346\n",
      "state terminated\n",
      "episode 2663, reward -36.0, memory_length 2000, epsilon 0.44982899968649825\n",
      "state terminated\n",
      "episode 2664, reward 9.0, memory_length 2000, epsilon 0.44969407422642327\n",
      "state terminated\n",
      "episode 2665, reward 175.0, memory_length 2000, epsilon 0.44955918923791527\n",
      "state terminated\n",
      "episode 2666, reward 44.0, memory_length 2000, epsilon 0.4494243447088345\n",
      "state terminated\n",
      "episode 2667, reward 21.0, memory_length 2000, epsilon 0.4492895406270452\n",
      "state terminated\n",
      "episode 2668, reward 395.0, memory_length 2000, epsilon 0.4491547769804148\n",
      "state terminated\n",
      "episode 2669, reward 173.0, memory_length 2000, epsilon 0.4490200537568146\n",
      "state terminated\n",
      "episode 2670, reward -188.0, memory_length 2000, epsilon 0.4488853709441196\n",
      "state terminated\n",
      "episode 2671, reward 9.0, memory_length 2000, epsilon 0.4487507285302083\n",
      "state terminated\n",
      "episode 2672, reward -15.0, memory_length 2000, epsilon 0.4486161265029628\n",
      "state terminated\n",
      "episode 2673, reward -152.0, memory_length 2000, epsilon 0.4484815648502691\n",
      "state terminated\n",
      "episode 2674, reward -85.0, memory_length 2000, epsilon 0.4483470435600165\n",
      "state terminated\n",
      "episode 2675, reward 9.0, memory_length 2000, epsilon 0.448212562620098\n",
      "state terminated\n",
      "episode 2676, reward 101.0, memory_length 2000, epsilon 0.4480781220184105\n",
      "state terminated\n",
      "episode 2677, reward -25.0, memory_length 2000, epsilon 0.4479437217428544\n",
      "state terminated\n",
      "episode 2678, reward 11.0, memory_length 2000, epsilon 0.4478093617813334\n",
      "state terminated\n",
      "episode 2679, reward -145.0, memory_length 2000, epsilon 0.44767504212175535\n",
      "state terminated\n",
      "episode 2680, reward -153.0, memory_length 2000, epsilon 0.4475407627520314\n",
      "state terminated\n",
      "episode 2681, reward 85.0, memory_length 2000, epsilon 0.4474065236600764\n",
      "state terminated\n",
      "episode 2682, reward -293.0, memory_length 2000, epsilon 0.44727232483380874\n",
      "state terminated\n",
      "episode 2683, reward -87.0, memory_length 2000, epsilon 0.44713816626115066\n",
      "state terminated\n",
      "episode 2684, reward 239.0, memory_length 2000, epsilon 0.44700404793002796\n",
      "state terminated\n",
      "episode 2685, reward 148.0, memory_length 2000, epsilon 0.4468699698283698\n",
      "state terminated\n",
      "episode 2686, reward 192.0, memory_length 2000, epsilon 0.44673593194410915\n",
      "state terminated\n",
      "episode 2687, reward 0.0, memory_length 2000, epsilon 0.44660193426518274\n",
      "state terminated\n",
      "episode 2688, reward 123.0, memory_length 2000, epsilon 0.44646797677953076\n",
      "state terminated\n",
      "episode 2689, reward 73.0, memory_length 2000, epsilon 0.4463340594750969\n",
      "state terminated\n",
      "episode 2690, reward 52.0, memory_length 2000, epsilon 0.4462001823398288\n",
      "state terminated\n",
      "episode 2691, reward -96.0, memory_length 2000, epsilon 0.4460663453616773\n",
      "state terminated\n",
      "episode 2692, reward -298.0, memory_length 2000, epsilon 0.4459325485285972\n",
      "state terminated\n",
      "episode 2693, reward 138.0, memory_length 2000, epsilon 0.4457987918285468\n",
      "state terminated\n",
      "episode 2694, reward 42.0, memory_length 2000, epsilon 0.445665075249488\n",
      "state terminated\n",
      "episode 2695, reward -62.0, memory_length 2000, epsilon 0.44553139877938625\n",
      "state terminated\n",
      "episode 2696, reward -19.0, memory_length 2000, epsilon 0.4453977624062107\n",
      "state terminated\n",
      "episode 2697, reward -119.0, memory_length 2000, epsilon 0.445264166117934\n",
      "state terminated\n",
      "episode 2698, reward -97.0, memory_length 2000, epsilon 0.44513060990253267\n",
      "state terminated\n",
      "episode 2699, reward 225.0, memory_length 2000, epsilon 0.4449970937479864\n",
      "state terminated\n",
      "episode 2700, reward 163.0, memory_length 2000, epsilon 0.44486361764227894\n",
      "state terminated\n",
      "episode 2701, reward -91.0, memory_length 2000, epsilon 0.4447301815733974\n",
      "state terminated\n",
      "episode 2702, reward -103.0, memory_length 2000, epsilon 0.44459678552933246\n",
      "state terminated\n",
      "episode 2703, reward 395.0, memory_length 2000, epsilon 0.4444634294980785\n",
      "state terminated\n",
      "episode 2704, reward 281.0, memory_length 2000, epsilon 0.44433011346763357\n",
      "state terminated\n",
      "episode 2705, reward 30.0, memory_length 2000, epsilon 0.4441968374259991\n",
      "state terminated\n",
      "episode 2706, reward 99.0, memory_length 2000, epsilon 0.4440636013611802\n",
      "state terminated\n",
      "episode 2707, reward 159.0, memory_length 2000, epsilon 0.4439304052611859\n",
      "state terminated\n",
      "episode 2708, reward -294.0, memory_length 2000, epsilon 0.4437972491140283\n",
      "state terminated\n",
      "episode 2709, reward 149.0, memory_length 2000, epsilon 0.44366413290772333\n",
      "state terminated\n",
      "episode 2710, reward 263.0, memory_length 2000, epsilon 0.4435310566302907\n",
      "state terminated\n",
      "episode 2711, reward 53.0, memory_length 2000, epsilon 0.4433980202697535\n",
      "state terminated\n",
      "episode 2712, reward 142.0, memory_length 2000, epsilon 0.4432650238141384\n",
      "state terminated\n",
      "episode 2713, reward -91.0, memory_length 2000, epsilon 0.4431320672514757\n",
      "state terminated\n",
      "episode 2714, reward 411.0, memory_length 2000, epsilon 0.44299915056979944\n",
      "state terminated\n",
      "episode 2715, reward 44.0, memory_length 2000, epsilon 0.442866273757147\n",
      "state terminated\n",
      "episode 2716, reward -40.0, memory_length 2000, epsilon 0.44273343680155935\n",
      "state terminated\n",
      "episode 2717, reward 34.0, memory_length 2000, epsilon 0.44260063969108143\n",
      "state terminated\n",
      "episode 2718, reward 193.0, memory_length 2000, epsilon 0.44246788241376145\n",
      "state terminated\n",
      "episode 2719, reward -22.0, memory_length 2000, epsilon 0.4423351649576511\n",
      "state terminated\n",
      "episode 2720, reward 233.0, memory_length 2000, epsilon 0.4422024873108059\n",
      "state terminated\n",
      "episode 2721, reward -205.0, memory_length 2000, epsilon 0.4420698494612849\n",
      "state terminated\n",
      "episode 2722, reward 112.0, memory_length 2000, epsilon 0.4419372513971506\n",
      "state terminated\n",
      "episode 2723, reward 198.0, memory_length 2000, epsilon 0.44180469310646925\n",
      "state terminated\n",
      "episode 2724, reward 125.0, memory_length 2000, epsilon 0.4416721745773106\n",
      "state terminated\n",
      "episode 2725, reward 229.0, memory_length 2000, epsilon 0.44153969579774793\n",
      "state terminated\n",
      "episode 2726, reward 108.0, memory_length 2000, epsilon 0.4414072567558581\n",
      "state terminated\n",
      "episode 2727, reward 223.0, memory_length 2000, epsilon 0.44127485743972183\n",
      "state terminated\n",
      "episode 2728, reward -26.0, memory_length 2000, epsilon 0.44114249783742293\n",
      "state terminated\n",
      "episode 2729, reward -225.0, memory_length 2000, epsilon 0.44101017793704916\n",
      "state terminated\n",
      "episode 2730, reward 36.0, memory_length 2000, epsilon 0.4408778977266917\n",
      "state terminated\n",
      "episode 2731, reward 84.0, memory_length 2000, epsilon 0.44074565719444536\n",
      "state terminated\n",
      "episode 2732, reward 40.0, memory_length 2000, epsilon 0.4406134563284084\n",
      "state terminated\n",
      "episode 2733, reward 184.0, memory_length 2000, epsilon 0.4404812951166829\n",
      "state terminated\n",
      "episode 2734, reward -106.0, memory_length 2000, epsilon 0.4403491735473742\n",
      "state terminated\n",
      "episode 2735, reward 3.0, memory_length 2000, epsilon 0.4402170916085914\n",
      "state terminated\n",
      "episode 2736, reward 12.0, memory_length 2000, epsilon 0.4400850492884471\n",
      "state terminated\n",
      "episode 2737, reward -107.0, memory_length 2000, epsilon 0.4399530465750577\n",
      "state terminated\n",
      "episode 2738, reward 75.0, memory_length 2000, epsilon 0.43982108345654264\n",
      "state terminated\n",
      "episode 2739, reward -9.0, memory_length 2000, epsilon 0.4396891599210255\n",
      "state terminated\n",
      "episode 2740, reward 115.0, memory_length 2000, epsilon 0.4395572759566329\n",
      "state terminated\n",
      "episode 2741, reward -95.0, memory_length 2000, epsilon 0.4394254315514955\n",
      "state terminated\n",
      "episode 2742, reward -146.0, memory_length 2000, epsilon 0.4392936266937473\n",
      "state terminated\n",
      "episode 2743, reward -89.0, memory_length 2000, epsilon 0.43916186137152574\n",
      "state terminated\n",
      "episode 2744, reward 191.0, memory_length 2000, epsilon 0.439030135572972\n",
      "state terminated\n",
      "episode 2745, reward 5.0, memory_length 2000, epsilon 0.4388984492862308\n",
      "state terminated\n",
      "episode 2746, reward 125.0, memory_length 2000, epsilon 0.4387668024994502\n",
      "state terminated\n",
      "episode 2747, reward -31.0, memory_length 2000, epsilon 0.43863519520078226\n",
      "state terminated\n",
      "episode 2748, reward -142.0, memory_length 2000, epsilon 0.43850362737838217\n",
      "state terminated\n",
      "episode 2749, reward -28.0, memory_length 2000, epsilon 0.4383720990204088\n",
      "state terminated\n",
      "episode 2750, reward 227.0, memory_length 2000, epsilon 0.43824061011502463\n",
      "state terminated\n",
      "episode 2751, reward 143.0, memory_length 2000, epsilon 0.43810916065039573\n",
      "state terminated\n",
      "episode 2752, reward 124.0, memory_length 2000, epsilon 0.4379777506146915\n",
      "state terminated\n",
      "episode 2753, reward -54.0, memory_length 2000, epsilon 0.43784637999608517\n",
      "state terminated\n",
      "episode 2754, reward -148.0, memory_length 2000, epsilon 0.4377150487827533\n",
      "state terminated\n",
      "episode 2755, reward 35.0, memory_length 2000, epsilon 0.43758375696287616\n",
      "state terminated\n",
      "episode 2756, reward -214.0, memory_length 2000, epsilon 0.4374525045246374\n",
      "state terminated\n",
      "episode 2757, reward 249.0, memory_length 2000, epsilon 0.43732129145622445\n",
      "state terminated\n",
      "episode 2758, reward 105.0, memory_length 2000, epsilon 0.43719011774582794\n",
      "state terminated\n",
      "episode 2759, reward -51.0, memory_length 2000, epsilon 0.43705898338164234\n",
      "state terminated\n",
      "episode 2760, reward -90.0, memory_length 2000, epsilon 0.43692788835186547\n",
      "state terminated\n",
      "episode 2761, reward 96.0, memory_length 2000, epsilon 0.43679683264469893\n",
      "state terminated\n",
      "episode 2762, reward 105.0, memory_length 2000, epsilon 0.43666581624834755\n",
      "state terminated\n",
      "episode 2763, reward 120.0, memory_length 2000, epsilon 0.43653483915102\n",
      "state terminated\n",
      "episode 2764, reward -219.0, memory_length 2000, epsilon 0.43640390134092827\n",
      "state terminated\n",
      "episode 2765, reward 309.0, memory_length 2000, epsilon 0.43627300280628795\n",
      "state terminated\n",
      "episode 2766, reward 172.0, memory_length 2000, epsilon 0.43614214353531805\n",
      "state terminated\n",
      "episode 2767, reward 258.0, memory_length 2000, epsilon 0.43601132351624156\n",
      "state terminated\n",
      "episode 2768, reward -12.0, memory_length 2000, epsilon 0.4358805427372844\n",
      "state terminated\n",
      "episode 2769, reward 116.0, memory_length 2000, epsilon 0.43574980118667633\n",
      "state terminated\n",
      "episode 2770, reward -18.0, memory_length 2000, epsilon 0.43561909885265065\n",
      "state terminated\n",
      "episode 2771, reward 180.0, memory_length 2000, epsilon 0.43548843572344426\n",
      "state terminated\n",
      "episode 2772, reward 81.0, memory_length 2000, epsilon 0.4353578117872973\n",
      "state terminated\n",
      "episode 2773, reward 125.0, memory_length 2000, epsilon 0.4352272270324537\n",
      "state terminated\n",
      "episode 2774, reward -153.0, memory_length 2000, epsilon 0.43509668144716085\n",
      "state terminated\n",
      "episode 2775, reward -11.0, memory_length 2000, epsilon 0.43496617501966967\n",
      "state terminated\n",
      "episode 2776, reward -26.0, memory_length 2000, epsilon 0.43483570773823454\n",
      "state terminated\n",
      "episode 2777, reward -162.0, memory_length 2000, epsilon 0.4347052795911133\n",
      "state terminated\n",
      "episode 2778, reward 61.0, memory_length 2000, epsilon 0.43457489056656756\n",
      "state terminated\n",
      "episode 2779, reward 295.0, memory_length 2000, epsilon 0.4344445406528623\n",
      "state terminated\n",
      "episode 2780, reward 98.0, memory_length 2000, epsilon 0.4343142298382659\n",
      "state terminated\n",
      "episode 2781, reward 226.0, memory_length 2000, epsilon 0.4341839581110506\n",
      "state terminated\n",
      "episode 2782, reward 145.0, memory_length 2000, epsilon 0.4340537254594917\n",
      "state terminated\n",
      "episode 2783, reward 93.0, memory_length 2000, epsilon 0.43392353187186844\n",
      "state terminated\n",
      "episode 2784, reward 223.0, memory_length 2000, epsilon 0.4337933773364634\n",
      "state terminated\n",
      "episode 2785, reward 31.0, memory_length 2000, epsilon 0.43366326184156256\n",
      "state terminated\n",
      "episode 2786, reward 81.0, memory_length 2000, epsilon 0.4335331853754556\n",
      "state terminated\n",
      "episode 2787, reward 259.0, memory_length 2000, epsilon 0.4334031479264356\n",
      "state terminated\n",
      "episode 2788, reward 94.0, memory_length 2000, epsilon 0.43327314948279916\n",
      "state terminated\n",
      "episode 2789, reward -77.0, memory_length 2000, epsilon 0.43314319003284657\n",
      "state terminated\n",
      "episode 2790, reward -15.0, memory_length 2000, epsilon 0.4330132695648813\n",
      "state terminated\n",
      "episode 2791, reward 81.0, memory_length 2000, epsilon 0.43288338806721055\n",
      "state terminated\n",
      "episode 2792, reward -70.0, memory_length 2000, epsilon 0.4327535455281451\n",
      "state terminated\n",
      "episode 2793, reward 108.0, memory_length 2000, epsilon 0.43262374193599895\n",
      "state terminated\n",
      "episode 2794, reward 206.0, memory_length 2000, epsilon 0.43249397727908995\n",
      "state terminated\n",
      "episode 2795, reward 471.0, memory_length 2000, epsilon 0.43236425154573915\n",
      "state terminated\n",
      "episode 2796, reward 31.0, memory_length 2000, epsilon 0.43223456472427135\n",
      "state terminated\n",
      "episode 2797, reward -6.0, memory_length 2000, epsilon 0.43210491680301455\n",
      "state terminated\n",
      "episode 2798, reward 301.0, memory_length 2000, epsilon 0.4319753077703007\n",
      "state terminated\n",
      "episode 2799, reward 143.0, memory_length 2000, epsilon 0.4318457376144647\n",
      "state terminated\n",
      "episode 2800, reward 24.0, memory_length 2000, epsilon 0.43171620632384544\n",
      "state terminated\n",
      "episode 2801, reward -171.0, memory_length 2000, epsilon 0.43158671388678504\n",
      "state terminated\n",
      "episode 2802, reward 175.0, memory_length 2000, epsilon 0.43145726029162923\n",
      "state terminated\n",
      "episode 2803, reward 74.0, memory_length 2000, epsilon 0.43132784552672704\n",
      "state terminated\n",
      "episode 2804, reward 289.0, memory_length 2000, epsilon 0.4311984695804313\n",
      "state terminated\n",
      "episode 2805, reward 103.0, memory_length 2000, epsilon 0.4310691324410981\n",
      "state terminated\n",
      "episode 2806, reward -1.0, memory_length 2000, epsilon 0.43093983409708714\n",
      "state terminated\n",
      "episode 2807, reward 9.0, memory_length 2000, epsilon 0.43081057453676147\n",
      "state terminated\n",
      "episode 2808, reward -154.0, memory_length 2000, epsilon 0.43068135374848787\n",
      "state terminated\n",
      "episode 2809, reward -163.0, memory_length 2000, epsilon 0.43055217172063637\n",
      "state terminated\n",
      "episode 2810, reward 245.0, memory_length 2000, epsilon 0.43042302844158054\n",
      "state terminated\n",
      "episode 2811, reward -208.0, memory_length 2000, epsilon 0.4302939238996977\n",
      "state terminated\n",
      "episode 2812, reward 36.0, memory_length 2000, epsilon 0.4301648580833682\n",
      "state terminated\n",
      "episode 2813, reward -10.0, memory_length 2000, epsilon 0.43003583098097625\n",
      "state terminated\n",
      "episode 2814, reward 171.0, memory_length 2000, epsilon 0.4299068425809094\n",
      "state terminated\n",
      "episode 2815, reward -90.0, memory_length 2000, epsilon 0.42977789287155865\n",
      "state terminated\n",
      "episode 2816, reward -24.0, memory_length 2000, epsilon 0.42964898184131856\n",
      "state terminated\n",
      "episode 2817, reward 286.0, memory_length 2000, epsilon 0.4295201094785871\n",
      "state terminated\n",
      "episode 2818, reward 7.0, memory_length 2000, epsilon 0.4293912757717658\n",
      "state terminated\n",
      "episode 2819, reward 81.0, memory_length 2000, epsilon 0.4292624807092596\n",
      "state terminated\n",
      "episode 2820, reward 396.0, memory_length 2000, epsilon 0.429133724279477\n",
      "state terminated\n",
      "episode 2821, reward 34.0, memory_length 2000, epsilon 0.4290050064708298\n",
      "state terminated\n",
      "episode 2822, reward -165.0, memory_length 2000, epsilon 0.4288763272717335\n",
      "state terminated\n",
      "episode 2823, reward 272.0, memory_length 2000, epsilon 0.428747686670607\n",
      "state terminated\n",
      "episode 2824, reward 152.0, memory_length 2000, epsilon 0.4286190846558725\n",
      "state terminated\n",
      "episode 2825, reward -108.0, memory_length 2000, epsilon 0.42849052121595593\n",
      "state terminated\n",
      "episode 2826, reward 328.0, memory_length 2000, epsilon 0.4283619963392866\n",
      "state terminated\n",
      "episode 2827, reward 43.0, memory_length 2000, epsilon 0.4282335100142972\n",
      "state terminated\n",
      "episode 2828, reward 161.0, memory_length 2000, epsilon 0.42810506222942407\n",
      "state terminated\n",
      "episode 2829, reward 31.0, memory_length 2000, epsilon 0.4279766529731067\n",
      "state terminated\n",
      "episode 2830, reward 17.0, memory_length 2000, epsilon 0.42784828223378846\n",
      "state terminated\n",
      "episode 2831, reward 87.0, memory_length 2000, epsilon 0.4277199499999159\n",
      "state terminated\n",
      "episode 2832, reward 174.0, memory_length 2000, epsilon 0.42759165625993917\n",
      "state terminated\n",
      "episode 2833, reward 276.0, memory_length 2000, epsilon 0.4274634010023117\n",
      "state terminated\n",
      "episode 2834, reward 245.0, memory_length 2000, epsilon 0.42733518421549066\n",
      "state terminated\n",
      "episode 2835, reward 99.0, memory_length 2000, epsilon 0.42720700588793653\n",
      "state terminated\n",
      "episode 2836, reward 228.0, memory_length 2000, epsilon 0.4270788660081131\n",
      "state terminated\n",
      "episode 2837, reward -27.0, memory_length 2000, epsilon 0.42695076456448794\n",
      "state terminated\n",
      "episode 2838, reward -76.0, memory_length 2000, epsilon 0.426822701545532\n",
      "state terminated\n",
      "episode 2839, reward 109.0, memory_length 2000, epsilon 0.42669467693971935\n",
      "state terminated\n",
      "episode 2840, reward 105.0, memory_length 2000, epsilon 0.42656669073552794\n",
      "state terminated\n",
      "episode 2841, reward -249.0, memory_length 2000, epsilon 0.426438742921439\n",
      "state terminated\n",
      "episode 2842, reward 166.0, memory_length 2000, epsilon 0.4263108334859373\n",
      "state terminated\n",
      "episode 2843, reward 148.0, memory_length 2000, epsilon 0.4261829624175108\n",
      "state terminated\n",
      "episode 2844, reward -109.0, memory_length 2000, epsilon 0.4260551297046512\n",
      "state terminated\n",
      "episode 2845, reward 207.0, memory_length 2000, epsilon 0.4259273353358536\n",
      "state terminated\n",
      "episode 2846, reward 135.0, memory_length 2000, epsilon 0.4257995792996164\n",
      "state terminated\n",
      "episode 2847, reward 239.0, memory_length 2000, epsilon 0.4256718615844417\n",
      "state terminated\n",
      "episode 2848, reward -217.0, memory_length 2000, epsilon 0.42554418217883483\n",
      "state terminated\n",
      "episode 2849, reward -477.0, memory_length 2000, epsilon 0.42541654107130455\n",
      "state terminated\n",
      "episode 2850, reward 22.0, memory_length 2000, epsilon 0.4252889382503634\n",
      "state terminated\n",
      "episode 2851, reward 54.0, memory_length 2000, epsilon 0.42516137370452683\n",
      "state terminated\n",
      "episode 2852, reward 293.0, memory_length 2000, epsilon 0.4250338474223143\n",
      "state terminated\n",
      "episode 2853, reward -131.0, memory_length 2000, epsilon 0.42490635939224825\n",
      "state terminated\n",
      "episode 2854, reward -83.0, memory_length 2000, epsilon 0.42477890960285486\n",
      "state terminated\n",
      "episode 2855, reward -297.0, memory_length 2000, epsilon 0.42465149804266367\n",
      "state terminated\n",
      "episode 2856, reward -239.0, memory_length 2000, epsilon 0.42452412470020756\n",
      "state terminated\n",
      "episode 2857, reward 251.0, memory_length 2000, epsilon 0.4243967895640229\n",
      "state terminated\n",
      "episode 2858, reward 26.0, memory_length 2000, epsilon 0.42426949262264957\n",
      "state terminated\n",
      "episode 2859, reward -384.0, memory_length 2000, epsilon 0.42414223386463096\n",
      "state terminated\n",
      "episode 2860, reward 21.0, memory_length 2000, epsilon 0.42401501327851365\n",
      "state terminated\n",
      "episode 2861, reward 258.0, memory_length 2000, epsilon 0.42388783085284776\n",
      "state terminated\n",
      "episode 2862, reward 108.0, memory_length 2000, epsilon 0.42376068657618704\n",
      "state terminated\n",
      "episode 2863, reward 34.0, memory_length 2000, epsilon 0.4236335804370883\n",
      "state terminated\n",
      "episode 2864, reward -136.0, memory_length 2000, epsilon 0.42350651242411214\n",
      "state terminated\n",
      "episode 2865, reward -77.0, memory_length 2000, epsilon 0.42337948252582236\n",
      "state terminated\n",
      "episode 2866, reward -40.0, memory_length 2000, epsilon 0.42325249073078636\n",
      "state terminated\n",
      "episode 2867, reward 171.0, memory_length 2000, epsilon 0.4231255370275747\n",
      "state terminated\n",
      "episode 2868, reward 41.0, memory_length 2000, epsilon 0.42299862140476174\n",
      "state terminated\n",
      "episode 2869, reward 76.0, memory_length 2000, epsilon 0.42287174385092496\n",
      "state terminated\n",
      "episode 2870, reward 40.0, memory_length 2000, epsilon 0.42274490435464546\n",
      "state terminated\n",
      "episode 2871, reward 110.0, memory_length 2000, epsilon 0.4226181029045076\n",
      "state terminated\n",
      "episode 2872, reward 20.0, memory_length 2000, epsilon 0.4224913394890992\n",
      "state terminated\n",
      "episode 2873, reward 165.0, memory_length 2000, epsilon 0.4223646140970118\n",
      "state terminated\n",
      "episode 2874, reward 63.0, memory_length 2000, epsilon 0.42223792671683985\n",
      "state terminated\n",
      "episode 2875, reward 44.0, memory_length 2000, epsilon 0.4221112773371817\n",
      "state terminated\n",
      "episode 2876, reward 387.0, memory_length 2000, epsilon 0.42198466594663864\n",
      "state terminated\n",
      "episode 2877, reward -125.0, memory_length 2000, epsilon 0.42185809253381584\n",
      "state terminated\n",
      "episode 2878, reward 105.0, memory_length 2000, epsilon 0.42173155708732174\n",
      "state terminated\n",
      "episode 2879, reward -99.0, memory_length 2000, epsilon 0.421605059595768\n",
      "state terminated\n",
      "episode 2880, reward -191.0, memory_length 2000, epsilon 0.4214786000477699\n",
      "state terminated\n",
      "episode 2881, reward -203.0, memory_length 2000, epsilon 0.4213521784319461\n",
      "state terminated\n",
      "episode 2882, reward 153.0, memory_length 2000, epsilon 0.4212257947369187\n",
      "state terminated\n",
      "episode 2883, reward -212.0, memory_length 2000, epsilon 0.421099448951313\n",
      "state terminated\n",
      "episode 2884, reward -59.0, memory_length 2000, epsilon 0.42097314106375805\n",
      "state terminated\n",
      "episode 2885, reward 137.0, memory_length 2000, epsilon 0.4208468710628861\n",
      "state terminated\n",
      "episode 2886, reward -148.0, memory_length 2000, epsilon 0.4207206389373328\n",
      "state terminated\n",
      "episode 2887, reward 24.0, memory_length 2000, epsilon 0.4205944446757373\n",
      "state terminated\n",
      "episode 2888, reward 65.0, memory_length 2000, epsilon 0.4204682882667421\n",
      "state terminated\n",
      "episode 2889, reward -1.0, memory_length 2000, epsilon 0.4203421696989932\n",
      "state terminated\n",
      "episode 2890, reward 139.0, memory_length 2000, epsilon 0.4202160889611397\n",
      "state terminated\n",
      "episode 2891, reward -325.0, memory_length 2000, epsilon 0.4200900460418346\n",
      "state terminated\n",
      "episode 2892, reward -78.0, memory_length 2000, epsilon 0.4199640409297339\n",
      "state terminated\n",
      "episode 2893, reward -11.0, memory_length 2000, epsilon 0.4198380736134972\n",
      "state terminated\n",
      "episode 2894, reward 66.0, memory_length 2000, epsilon 0.4197121440817873\n",
      "state terminated\n",
      "episode 2895, reward -87.0, memory_length 2000, epsilon 0.4195862523232708\n",
      "state terminated\n",
      "episode 2896, reward 151.0, memory_length 2000, epsilon 0.4194603983266172\n",
      "state terminated\n",
      "episode 2897, reward 178.0, memory_length 2000, epsilon 0.4193345820804998\n",
      "state terminated\n",
      "episode 2898, reward 72.0, memory_length 2000, epsilon 0.41920880357359497\n",
      "state terminated\n",
      "episode 2899, reward 48.0, memory_length 2000, epsilon 0.4190830627945828\n",
      "state terminated\n",
      "episode 2900, reward 135.0, memory_length 2000, epsilon 0.4189573597321466\n",
      "state terminated\n",
      "episode 2901, reward -38.0, memory_length 2000, epsilon 0.418831694374973\n",
      "state terminated\n",
      "episode 2902, reward 205.0, memory_length 2000, epsilon 0.4187060667117522\n",
      "state terminated\n",
      "episode 2903, reward 22.0, memory_length 2000, epsilon 0.4185804767311777\n",
      "state terminated\n",
      "episode 2904, reward 611.0, memory_length 2000, epsilon 0.4184549244219463\n",
      "state terminated\n",
      "episode 2905, reward 27.0, memory_length 2000, epsilon 0.4183294097727585\n",
      "state terminated\n",
      "episode 2906, reward -127.0, memory_length 2000, epsilon 0.4182039327723179\n",
      "state terminated\n",
      "episode 2907, reward 108.0, memory_length 2000, epsilon 0.4180784934093314\n",
      "state terminated\n",
      "episode 2908, reward 261.0, memory_length 2000, epsilon 0.4179530916725096\n",
      "state terminated\n",
      "episode 2909, reward 232.0, memory_length 2000, epsilon 0.41782772755056635\n",
      "state terminated\n",
      "episode 2910, reward -41.0, memory_length 2000, epsilon 0.4177024010322189\n",
      "state terminated\n",
      "episode 2911, reward 130.0, memory_length 2000, epsilon 0.41757711210618775\n",
      "state terminated\n",
      "episode 2912, reward -186.0, memory_length 2000, epsilon 0.41745186076119706\n",
      "state terminated\n",
      "episode 2913, reward -105.0, memory_length 2000, epsilon 0.41732664698597416\n",
      "state terminated\n",
      "episode 2914, reward 146.0, memory_length 2000, epsilon 0.4172014707692496\n",
      "state terminated\n",
      "episode 2915, reward 23.0, memory_length 2000, epsilon 0.41707633209975786\n",
      "state terminated\n",
      "episode 2916, reward 83.0, memory_length 2000, epsilon 0.4169512309662362\n",
      "state terminated\n",
      "episode 2917, reward 31.0, memory_length 2000, epsilon 0.41682616735742567\n",
      "state terminated\n",
      "episode 2918, reward 306.0, memory_length 2000, epsilon 0.41670114126207036\n",
      "state terminated\n",
      "episode 2919, reward 223.0, memory_length 2000, epsilon 0.4165761526689182\n",
      "state terminated\n",
      "episode 2920, reward 353.0, memory_length 2000, epsilon 0.41645120156671994\n",
      "state terminated\n",
      "episode 2921, reward -197.0, memory_length 2000, epsilon 0.41632628794423016\n",
      "state terminated\n",
      "episode 2922, reward -46.0, memory_length 2000, epsilon 0.4162014117902066\n",
      "state terminated\n",
      "episode 2923, reward 112.0, memory_length 2000, epsilon 0.41607657309341034\n",
      "state terminated\n",
      "episode 2924, reward -9.0, memory_length 2000, epsilon 0.41595177184260596\n",
      "state terminated\n",
      "episode 2925, reward 321.0, memory_length 2000, epsilon 0.41582700802656125\n",
      "state terminated\n",
      "episode 2926, reward -224.0, memory_length 2000, epsilon 0.4157022816340476\n",
      "state terminated\n",
      "episode 2927, reward 14.0, memory_length 2000, epsilon 0.41557759265383964\n",
      "state terminated\n",
      "episode 2928, reward -176.0, memory_length 2000, epsilon 0.4154529410747152\n",
      "state terminated\n",
      "episode 2929, reward -108.0, memory_length 2000, epsilon 0.4153283268854558\n",
      "state terminated\n",
      "episode 2930, reward 31.0, memory_length 2000, epsilon 0.41520375007484606\n",
      "state terminated\n",
      "episode 2931, reward -119.0, memory_length 2000, epsilon 0.41507921063167413\n",
      "state terminated\n",
      "episode 2932, reward 20.0, memory_length 2000, epsilon 0.4149547085447315\n",
      "state terminated\n",
      "episode 2933, reward 152.0, memory_length 2000, epsilon 0.41483024380281286\n",
      "state terminated\n",
      "episode 2934, reward 99.0, memory_length 2000, epsilon 0.41470581639471643\n",
      "state terminated\n",
      "episode 2935, reward 316.0, memory_length 2000, epsilon 0.4145814263092437\n",
      "state terminated\n",
      "episode 2936, reward 351.0, memory_length 2000, epsilon 0.4144570735351997\n",
      "state terminated\n",
      "episode 2937, reward -3.0, memory_length 2000, epsilon 0.4143327580613926\n",
      "state terminated\n",
      "episode 2938, reward 236.0, memory_length 2000, epsilon 0.41420847987663395\n",
      "state terminated\n",
      "episode 2939, reward -279.0, memory_length 2000, epsilon 0.4140842389697388\n",
      "state terminated\n",
      "episode 2940, reward 354.0, memory_length 2000, epsilon 0.4139600353295254\n",
      "state terminated\n",
      "episode 2941, reward 189.0, memory_length 2000, epsilon 0.4138358689448155\n",
      "state terminated\n",
      "episode 2942, reward 155.0, memory_length 2000, epsilon 0.4137117398044341\n",
      "state terminated\n",
      "episode 2943, reward 183.0, memory_length 2000, epsilon 0.41358764789720953\n",
      "state terminated\n",
      "episode 2944, reward 323.0, memory_length 2000, epsilon 0.4134635932119736\n",
      "state terminated\n",
      "episode 2945, reward 72.0, memory_length 2000, epsilon 0.4133395757375613\n",
      "state terminated\n",
      "episode 2946, reward -2.0, memory_length 2000, epsilon 0.4132155954628111\n",
      "state terminated\n",
      "episode 2947, reward -6.0, memory_length 2000, epsilon 0.41309165237656476\n",
      "state terminated\n",
      "episode 2948, reward -36.0, memory_length 2000, epsilon 0.41296774646766743\n",
      "state terminated\n",
      "episode 2949, reward 431.0, memory_length 2000, epsilon 0.41284387772496756\n",
      "state terminated\n",
      "episode 2950, reward -74.0, memory_length 2000, epsilon 0.41272004613731694\n",
      "state terminated\n",
      "episode 2951, reward 85.0, memory_length 2000, epsilon 0.4125962516935707\n",
      "state terminated\n",
      "episode 2952, reward 330.0, memory_length 2000, epsilon 0.4124724943825875\n",
      "state terminated\n",
      "episode 2953, reward -27.0, memory_length 2000, epsilon 0.412348774193229\n",
      "state terminated\n",
      "episode 2954, reward 127.0, memory_length 2000, epsilon 0.41222509111436056\n",
      "state terminated\n",
      "episode 2955, reward 0.0, memory_length 2000, epsilon 0.4121014451348505\n",
      "state terminated\n",
      "episode 2956, reward 24.0, memory_length 2000, epsilon 0.4119778362435708\n",
      "state terminated\n",
      "episode 2957, reward -28.0, memory_length 2000, epsilon 0.41185426442939665\n",
      "state terminated\n",
      "episode 2958, reward -42.0, memory_length 2000, epsilon 0.41173072968120655\n",
      "state terminated\n",
      "episode 2959, reward 93.0, memory_length 2000, epsilon 0.4116072319878824\n",
      "state terminated\n",
      "episode 2960, reward 386.0, memory_length 2000, epsilon 0.4114837713383095\n",
      "state terminated\n",
      "episode 2961, reward -113.0, memory_length 2000, epsilon 0.4113603477213762\n",
      "state terminated\n",
      "episode 2962, reward -134.0, memory_length 2000, epsilon 0.41123696112597447\n",
      "state terminated\n",
      "episode 2963, reward 119.0, memory_length 2000, epsilon 0.41111361154099957\n",
      "state terminated\n",
      "episode 2964, reward 130.0, memory_length 2000, epsilon 0.41099029895534994\n",
      "state terminated\n",
      "episode 2965, reward 73.0, memory_length 2000, epsilon 0.4108670233579275\n",
      "state terminated\n",
      "episode 2966, reward -131.0, memory_length 2000, epsilon 0.41074378473763745\n",
      "state terminated\n",
      "episode 2967, reward -276.0, memory_length 2000, epsilon 0.41062058308338834\n",
      "state terminated\n",
      "episode 2968, reward -74.0, memory_length 2000, epsilon 0.4104974183840919\n",
      "state terminated\n",
      "episode 2969, reward 162.0, memory_length 2000, epsilon 0.4103742906286635\n",
      "state terminated\n",
      "episode 2970, reward 108.0, memory_length 2000, epsilon 0.4102511998060215\n",
      "state terminated\n",
      "episode 2971, reward -19.0, memory_length 2000, epsilon 0.4101281459050877\n",
      "state terminated\n",
      "episode 2972, reward -207.0, memory_length 2000, epsilon 0.41000512891478735\n",
      "state terminated\n",
      "episode 2973, reward 255.0, memory_length 2000, epsilon 0.4098821488240489\n",
      "state terminated\n",
      "episode 2974, reward 53.0, memory_length 2000, epsilon 0.40975920562180407\n",
      "state terminated\n",
      "episode 2975, reward 35.0, memory_length 2000, epsilon 0.409636299296988\n",
      "state terminated\n",
      "episode 2976, reward 210.0, memory_length 2000, epsilon 0.4095134298385392\n",
      "state terminated\n",
      "episode 2977, reward 85.0, memory_length 2000, epsilon 0.4093905972353994\n",
      "state terminated\n",
      "episode 2978, reward -66.0, memory_length 2000, epsilon 0.4092678014765136\n",
      "state terminated\n",
      "episode 2979, reward 171.0, memory_length 2000, epsilon 0.4091450425508302\n",
      "state terminated\n",
      "episode 2980, reward 155.0, memory_length 2000, epsilon 0.4090223204473009\n",
      "state terminated\n",
      "episode 2981, reward 6.0, memory_length 2000, epsilon 0.4088996351548807\n",
      "state terminated\n",
      "episode 2982, reward 165.0, memory_length 2000, epsilon 0.40877698666252793\n",
      "state terminated\n",
      "episode 2983, reward 26.0, memory_length 2000, epsilon 0.40865437495920426\n",
      "state terminated\n",
      "episode 2984, reward 265.0, memory_length 2000, epsilon 0.4085318000338746\n",
      "state terminated\n",
      "episode 2985, reward -136.0, memory_length 2000, epsilon 0.4084092618755072\n",
      "state terminated\n",
      "episode 2986, reward 36.0, memory_length 2000, epsilon 0.4082867604730737\n",
      "state terminated\n",
      "episode 2987, reward -2.0, memory_length 2000, epsilon 0.4081642958155489\n",
      "state terminated\n",
      "episode 2988, reward 9.0, memory_length 2000, epsilon 0.40804186789191094\n",
      "state terminated\n",
      "episode 2989, reward 160.0, memory_length 2000, epsilon 0.4079194766911415\n",
      "state terminated\n",
      "episode 2990, reward 219.0, memory_length 2000, epsilon 0.40779712220222514\n",
      "state terminated\n",
      "episode 2991, reward 99.0, memory_length 2000, epsilon 0.40767480441415005\n",
      "state terminated\n",
      "episode 2992, reward 18.0, memory_length 2000, epsilon 0.40755252331590763\n",
      "state terminated\n",
      "episode 2993, reward 116.0, memory_length 2000, epsilon 0.40743027889649264\n",
      "state terminated\n",
      "episode 2994, reward 111.0, memory_length 2000, epsilon 0.40730807114490303\n",
      "state terminated\n",
      "episode 2995, reward -165.0, memory_length 2000, epsilon 0.40718590005014\n",
      "state terminated\n",
      "episode 2996, reward 17.0, memory_length 2000, epsilon 0.4070637656012083\n",
      "state terminated\n",
      "episode 2997, reward 107.0, memory_length 2000, epsilon 0.4069416677871158\n",
      "state terminated\n",
      "episode 2998, reward 2.0, memory_length 2000, epsilon 0.40681960659687366\n",
      "state terminated\n",
      "episode 2999, reward 75.0, memory_length 2000, epsilon 0.40669758201949635\n",
      "state terminated\n",
      "episode 3000, reward 54.0, memory_length 2000, epsilon 0.4065755940440018\n",
      "INFO:tensorflow:Assets written to: model.pkl/assets\n",
      "Total time taken  4340.499067783356\n",
      "state terminated\n",
      "episode 3001, reward 177.0, memory_length 2000, epsilon 0.4064536426594109\n",
      "state terminated\n",
      "episode 3002, reward 110.0, memory_length 2000, epsilon 0.4063317278547481\n",
      "state terminated\n",
      "episode 3003, reward 143.0, memory_length 2000, epsilon 0.40620984961904116\n",
      "state terminated\n",
      "episode 3004, reward 186.0, memory_length 2000, epsilon 0.40608800794132094\n",
      "state terminated\n",
      "episode 3005, reward 10.0, memory_length 2000, epsilon 0.4059662028106216\n",
      "state terminated\n",
      "episode 3006, reward -59.0, memory_length 2000, epsilon 0.4058444342159809\n",
      "state terminated\n",
      "episode 3007, reward -154.0, memory_length 2000, epsilon 0.4057227021464396\n",
      "state terminated\n",
      "episode 3008, reward -56.0, memory_length 2000, epsilon 0.40560100659104165\n",
      "state terminated\n",
      "episode 3009, reward 312.0, memory_length 2000, epsilon 0.4054793475388346\n",
      "state terminated\n",
      "episode 3010, reward 251.0, memory_length 2000, epsilon 0.4053577249788691\n",
      "state terminated\n",
      "episode 3011, reward -3.0, memory_length 2000, epsilon 0.40523613890019916\n",
      "state terminated\n",
      "episode 3012, reward 90.0, memory_length 2000, epsilon 0.40511458929188193\n",
      "state terminated\n",
      "episode 3013, reward 85.0, memory_length 2000, epsilon 0.4049930761429781\n",
      "state terminated\n",
      "episode 3014, reward 148.0, memory_length 2000, epsilon 0.40487159944255136\n",
      "state terminated\n",
      "episode 3015, reward -13.0, memory_length 2000, epsilon 0.4047501591796688\n",
      "state terminated\n",
      "episode 3016, reward 360.0, memory_length 2000, epsilon 0.40462875534340087\n",
      "state terminated\n",
      "episode 3017, reward 106.0, memory_length 2000, epsilon 0.40450738792282115\n",
      "state terminated\n",
      "episode 3018, reward 130.0, memory_length 2000, epsilon 0.40438605690700674\n",
      "state terminated\n",
      "episode 3019, reward 182.0, memory_length 2000, epsilon 0.4042647622850376\n",
      "state terminated\n",
      "episode 3020, reward -165.0, memory_length 2000, epsilon 0.4041435040459974\n",
      "state terminated\n",
      "episode 3021, reward 106.0, memory_length 2000, epsilon 0.4040222821789728\n",
      "state terminated\n",
      "episode 3022, reward -59.0, memory_length 2000, epsilon 0.4039010966730539\n",
      "state terminated\n",
      "episode 3023, reward -180.0, memory_length 2000, epsilon 0.4037799475173339\n",
      "state terminated\n",
      "episode 3024, reward 112.0, memory_length 2000, epsilon 0.4036588347009096\n",
      "state terminated\n",
      "episode 3025, reward -49.0, memory_length 2000, epsilon 0.4035377582128805\n",
      "state terminated\n",
      "episode 3026, reward -16.0, memory_length 2000, epsilon 0.4034167180423501\n",
      "state terminated\n",
      "episode 3027, reward 108.0, memory_length 2000, epsilon 0.40329571417842447\n",
      "state terminated\n",
      "episode 3028, reward -135.0, memory_length 2000, epsilon 0.40317474661021346\n",
      "state terminated\n",
      "episode 3029, reward 228.0, memory_length 2000, epsilon 0.4030538153268299\n",
      "state terminated\n",
      "episode 3030, reward 54.0, memory_length 2000, epsilon 0.40293292031739\n",
      "state terminated\n",
      "episode 3031, reward -15.0, memory_length 2000, epsilon 0.4028120615710132\n",
      "state terminated\n",
      "episode 3032, reward -41.0, memory_length 2000, epsilon 0.40269123907682214\n",
      "state terminated\n",
      "episode 3033, reward -18.0, memory_length 2000, epsilon 0.4025704528239429\n",
      "state terminated\n",
      "episode 3034, reward 107.0, memory_length 2000, epsilon 0.4024497028015047\n",
      "state terminated\n",
      "episode 3035, reward 101.0, memory_length 2000, epsilon 0.40232898899864006\n",
      "state terminated\n",
      "episode 3036, reward -38.0, memory_length 2000, epsilon 0.40220831140448465\n",
      "state terminated\n",
      "episode 3037, reward 385.0, memory_length 2000, epsilon 0.4020876700081776\n",
      "state terminated\n",
      "episode 3038, reward -191.0, memory_length 2000, epsilon 0.4019670647988611\n",
      "state terminated\n",
      "episode 3039, reward 207.0, memory_length 2000, epsilon 0.40184649576568066\n",
      "state terminated\n",
      "episode 3040, reward 27.0, memory_length 2000, epsilon 0.4017259628977851\n",
      "state terminated\n",
      "episode 3041, reward -67.0, memory_length 2000, epsilon 0.4016054661843266\n",
      "state terminated\n",
      "episode 3042, reward -186.0, memory_length 2000, epsilon 0.40148500561446016\n",
      "state terminated\n",
      "episode 3043, reward 115.0, memory_length 2000, epsilon 0.4013645811773446\n",
      "state terminated\n",
      "episode 3044, reward 503.0, memory_length 2000, epsilon 0.4012441928621416\n",
      "state terminated\n",
      "episode 3045, reward 3.0, memory_length 2000, epsilon 0.4011238406580162\n",
      "state terminated\n",
      "episode 3046, reward 219.0, memory_length 2000, epsilon 0.40100352455413674\n",
      "state terminated\n",
      "episode 3047, reward 26.0, memory_length 2000, epsilon 0.4008832445396748\n",
      "state terminated\n",
      "episode 3048, reward -106.0, memory_length 2000, epsilon 0.4007630006038051\n",
      "state terminated\n",
      "episode 3049, reward 7.0, memory_length 2000, epsilon 0.4006427927357057\n",
      "state terminated\n",
      "episode 3050, reward 123.0, memory_length 2000, epsilon 0.400522620924558\n",
      "state terminated\n",
      "episode 3051, reward 220.0, memory_length 2000, epsilon 0.40040248515954635\n",
      "state terminated\n",
      "episode 3052, reward -109.0, memory_length 2000, epsilon 0.4002823854298587\n",
      "state terminated\n",
      "episode 3053, reward 85.0, memory_length 2000, epsilon 0.40016232172468597\n",
      "state terminated\n",
      "episode 3054, reward 78.0, memory_length 2000, epsilon 0.4000422940332225\n",
      "state terminated\n",
      "episode 3055, reward 31.0, memory_length 2000, epsilon 0.39992230234466575\n",
      "state terminated\n",
      "episode 3056, reward -142.0, memory_length 2000, epsilon 0.3998023466482165\n",
      "state terminated\n",
      "episode 3057, reward -153.0, memory_length 2000, epsilon 0.3996824269330787\n",
      "state terminated\n",
      "episode 3058, reward 53.0, memory_length 2000, epsilon 0.39956254318845963\n",
      "state terminated\n",
      "episode 3059, reward 339.0, memory_length 2000, epsilon 0.39944269540356964\n",
      "state terminated\n",
      "episode 3060, reward -291.0, memory_length 2000, epsilon 0.3993228835676225\n",
      "state terminated\n",
      "episode 3061, reward 0.0, memory_length 2000, epsilon 0.3992031076698353\n",
      "state terminated\n",
      "episode 3062, reward -50.0, memory_length 2000, epsilon 0.3990833676994279\n",
      "state terminated\n",
      "episode 3063, reward 305.0, memory_length 2000, epsilon 0.39896366364562397\n",
      "state terminated\n",
      "episode 3064, reward 357.0, memory_length 2000, epsilon 0.39884399549765\n",
      "state terminated\n",
      "episode 3065, reward 99.0, memory_length 2000, epsilon 0.39872436324473587\n",
      "state terminated\n",
      "episode 3066, reward -100.0, memory_length 2000, epsilon 0.39860476687611474\n",
      "state terminated\n",
      "episode 3067, reward 249.0, memory_length 2000, epsilon 0.39848520638102286\n",
      "state terminated\n",
      "episode 3068, reward -71.0, memory_length 2000, epsilon 0.39836568174869985\n",
      "state terminated\n",
      "episode 3069, reward -36.0, memory_length 2000, epsilon 0.39824619296838837\n",
      "state terminated\n",
      "episode 3070, reward -95.0, memory_length 2000, epsilon 0.3981267400293347\n",
      "state terminated\n",
      "episode 3071, reward 223.0, memory_length 2000, epsilon 0.3980073229207878\n",
      "state terminated\n",
      "episode 3072, reward -127.0, memory_length 2000, epsilon 0.3978879416320002\n",
      "state terminated\n",
      "episode 3073, reward 20.0, memory_length 2000, epsilon 0.39776859615222765\n",
      "state terminated\n",
      "episode 3074, reward 343.0, memory_length 2000, epsilon 0.39764928647072906\n",
      "state terminated\n",
      "episode 3075, reward 196.0, memory_length 2000, epsilon 0.39753001257676646\n",
      "state terminated\n",
      "episode 3076, reward 308.0, memory_length 2000, epsilon 0.3974107744596053\n",
      "state terminated\n",
      "episode 3077, reward 121.0, memory_length 2000, epsilon 0.3972915721085141\n",
      "state terminated\n",
      "episode 3078, reward 18.0, memory_length 2000, epsilon 0.39717240551276467\n",
      "state terminated\n",
      "episode 3079, reward -198.0, memory_length 2000, epsilon 0.397053274661632\n",
      "state terminated\n",
      "episode 3080, reward 117.0, memory_length 2000, epsilon 0.3969341795443943\n",
      "state terminated\n",
      "episode 3081, reward -198.0, memory_length 2000, epsilon 0.39681512015033304\n",
      "state terminated\n",
      "episode 3082, reward 268.0, memory_length 2000, epsilon 0.39669609646873283\n",
      "state terminated\n",
      "episode 3083, reward 10.0, memory_length 2000, epsilon 0.3965771084888816\n",
      "state terminated\n",
      "episode 3084, reward 16.0, memory_length 2000, epsilon 0.3964581562000704\n",
      "state terminated\n",
      "episode 3085, reward 85.0, memory_length 2000, epsilon 0.39633923959159356\n",
      "state terminated\n",
      "episode 3086, reward 92.0, memory_length 2000, epsilon 0.3962203586527485\n",
      "state terminated\n",
      "episode 3087, reward 40.0, memory_length 2000, epsilon 0.396101513372836\n",
      "state terminated\n",
      "episode 3088, reward -73.0, memory_length 2000, epsilon 0.39598270374115996\n",
      "state terminated\n",
      "episode 3089, reward 216.0, memory_length 2000, epsilon 0.3958639297470275\n",
      "state terminated\n",
      "episode 3090, reward -27.0, memory_length 2000, epsilon 0.39574519137974906\n",
      "state terminated\n",
      "episode 3091, reward 63.0, memory_length 2000, epsilon 0.3956264886286381\n",
      "state terminated\n",
      "episode 3092, reward -95.0, memory_length 2000, epsilon 0.39550782148301133\n",
      "state terminated\n",
      "episode 3093, reward 43.0, memory_length 2000, epsilon 0.39538918993218874\n",
      "state terminated\n",
      "episode 3094, reward -61.0, memory_length 2000, epsilon 0.39527059396549363\n",
      "state terminated\n",
      "episode 3095, reward 130.0, memory_length 2000, epsilon 0.39515203357225215\n",
      "state terminated\n",
      "episode 3096, reward 299.0, memory_length 2000, epsilon 0.39503350874179394\n",
      "state terminated\n",
      "episode 3097, reward 20.0, memory_length 2000, epsilon 0.3949150194634518\n",
      "state terminated\n",
      "episode 3098, reward 288.0, memory_length 2000, epsilon 0.39479656572656174\n",
      "state terminated\n",
      "episode 3099, reward 31.0, memory_length 2000, epsilon 0.3946781475204628\n",
      "state terminated\n",
      "episode 3100, reward 18.0, memory_length 2000, epsilon 0.39455976483449745\n",
      "state terminated\n",
      "episode 3101, reward 206.0, memory_length 2000, epsilon 0.3944414176580112\n",
      "state terminated\n",
      "episode 3102, reward 355.0, memory_length 2000, epsilon 0.39432310598035275\n",
      "state terminated\n",
      "episode 3103, reward -74.0, memory_length 2000, epsilon 0.3942048297908742\n",
      "state terminated\n",
      "episode 3104, reward -9.0, memory_length 2000, epsilon 0.3940865890789305\n",
      "state terminated\n",
      "episode 3105, reward 77.0, memory_length 2000, epsilon 0.39396838383388016\n",
      "state terminated\n",
      "episode 3106, reward -144.0, memory_length 2000, epsilon 0.3938502140450845\n",
      "state terminated\n",
      "episode 3107, reward -43.0, memory_length 2000, epsilon 0.3937320797019085\n",
      "state terminated\n",
      "episode 3108, reward 5.0, memory_length 2000, epsilon 0.3936139807937199\n",
      "state terminated\n",
      "episode 3109, reward -10.0, memory_length 2000, epsilon 0.3934959173098898\n",
      "state terminated\n",
      "episode 3110, reward 166.0, memory_length 2000, epsilon 0.3933778892397926\n",
      "state terminated\n",
      "episode 3111, reward 80.0, memory_length 2000, epsilon 0.39325989657280563\n",
      "state terminated\n",
      "episode 3112, reward 215.0, memory_length 2000, epsilon 0.39314193929830965\n",
      "state terminated\n",
      "episode 3113, reward 36.0, memory_length 2000, epsilon 0.3930240174056885\n",
      "state terminated\n",
      "episode 3114, reward 207.0, memory_length 2000, epsilon 0.39290613088432913\n",
      "state terminated\n",
      "episode 3115, reward -54.0, memory_length 2000, epsilon 0.39278827972362185\n",
      "state terminated\n",
      "episode 3116, reward 378.0, memory_length 2000, epsilon 0.39267046391295995\n",
      "state terminated\n",
      "episode 3117, reward 188.0, memory_length 2000, epsilon 0.3925526834417401\n",
      "state terminated\n",
      "episode 3118, reward -104.0, memory_length 2000, epsilon 0.392434938299362\n",
      "state terminated\n",
      "episode 3119, reward 169.0, memory_length 2000, epsilon 0.39231722847522865\n",
      "state terminated\n",
      "episode 3120, reward 201.0, memory_length 2000, epsilon 0.3921995539587461\n",
      "state terminated\n",
      "episode 3121, reward 14.0, memory_length 2000, epsilon 0.3920819147393237\n",
      "state terminated\n",
      "episode 3122, reward -146.0, memory_length 2000, epsilon 0.3919643108063739\n",
      "state terminated\n",
      "episode 3123, reward 201.0, memory_length 2000, epsilon 0.3918467421493123\n",
      "state terminated\n",
      "episode 3124, reward 31.0, memory_length 2000, epsilon 0.3917292087575578\n",
      "state terminated\n",
      "episode 3125, reward -70.0, memory_length 2000, epsilon 0.3916117106205323\n",
      "state terminated\n",
      "episode 3126, reward -243.0, memory_length 2000, epsilon 0.391494247727661\n",
      "state terminated\n",
      "episode 3127, reward 225.0, memory_length 2000, epsilon 0.3913768200683723\n",
      "state terminated\n",
      "episode 3128, reward 148.0, memory_length 2000, epsilon 0.3912594276320977\n",
      "state terminated\n",
      "episode 3129, reward 97.0, memory_length 2000, epsilon 0.39114207040827187\n",
      "state terminated\n",
      "episode 3130, reward 150.0, memory_length 2000, epsilon 0.39102474838633255\n",
      "state terminated\n",
      "episode 3131, reward 210.0, memory_length 2000, epsilon 0.3909074615557209\n",
      "state terminated\n",
      "episode 3132, reward 9.0, memory_length 2000, epsilon 0.3907902099058811\n",
      "state terminated\n",
      "episode 3133, reward 103.0, memory_length 2000, epsilon 0.39067299342626033\n",
      "state terminated\n",
      "episode 3134, reward -37.0, memory_length 2000, epsilon 0.39055581210630935\n",
      "state terminated\n",
      "episode 3135, reward -6.0, memory_length 2000, epsilon 0.39043866593548165\n",
      "state terminated\n",
      "episode 3136, reward 130.0, memory_length 2000, epsilon 0.39032155490323417\n",
      "state terminated\n",
      "episode 3137, reward 64.0, memory_length 2000, epsilon 0.39020447899902694\n",
      "state terminated\n",
      "episode 3138, reward 106.0, memory_length 2000, epsilon 0.390087438212323\n",
      "state terminated\n",
      "episode 3139, reward 102.0, memory_length 2000, epsilon 0.3899704325325888\n",
      "state terminated\n",
      "episode 3140, reward 49.0, memory_length 2000, epsilon 0.38985346194929377\n",
      "state terminated\n",
      "episode 3141, reward 213.0, memory_length 2000, epsilon 0.38973652645191065\n",
      "state terminated\n",
      "episode 3142, reward 123.0, memory_length 2000, epsilon 0.3896196260299152\n",
      "state terminated\n",
      "episode 3143, reward 261.0, memory_length 2000, epsilon 0.38950276067278616\n",
      "state terminated\n",
      "episode 3144, reward 147.0, memory_length 2000, epsilon 0.389385930370006\n",
      "state terminated\n",
      "episode 3145, reward 143.0, memory_length 2000, epsilon 0.3892691351110598\n",
      "state terminated\n",
      "episode 3146, reward -135.0, memory_length 2000, epsilon 0.389152374885436\n",
      "state terminated\n",
      "episode 3147, reward -55.0, memory_length 2000, epsilon 0.38903564968262627\n",
      "state terminated\n",
      "episode 3148, reward 49.0, memory_length 2000, epsilon 0.38891895949212524\n",
      "state terminated\n",
      "episode 3149, reward 170.0, memory_length 2000, epsilon 0.3888023043034308\n",
      "state terminated\n",
      "episode 3150, reward 274.0, memory_length 2000, epsilon 0.38868568410604404\n",
      "state terminated\n",
      "episode 3151, reward 159.0, memory_length 2000, epsilon 0.3885690988894691\n",
      "state terminated\n",
      "episode 3152, reward -239.0, memory_length 2000, epsilon 0.3884525486432133\n",
      "state terminated\n",
      "episode 3153, reward -64.0, memory_length 2000, epsilon 0.3883360333567872\n",
      "state terminated\n",
      "episode 3154, reward -72.0, memory_length 2000, epsilon 0.3882195530197043\n",
      "state terminated\n",
      "episode 3155, reward -61.0, memory_length 2000, epsilon 0.3881031076214815\n",
      "state terminated\n",
      "episode 3156, reward 18.0, memory_length 2000, epsilon 0.38798669715163864\n",
      "state terminated\n",
      "episode 3157, reward 285.0, memory_length 2000, epsilon 0.3878703215996987\n",
      "state terminated\n",
      "episode 3158, reward 51.0, memory_length 2000, epsilon 0.38775398095518804\n",
      "state terminated\n",
      "episode 3159, reward 42.0, memory_length 2000, epsilon 0.3876376752076359\n",
      "state terminated\n",
      "episode 3160, reward 256.0, memory_length 2000, epsilon 0.3875214043465748\n",
      "state terminated\n",
      "episode 3161, reward 65.0, memory_length 2000, epsilon 0.3874051683615404\n",
      "state terminated\n",
      "episode 3162, reward 37.0, memory_length 2000, epsilon 0.38728896724207135\n",
      "state terminated\n",
      "episode 3163, reward 128.0, memory_length 2000, epsilon 0.38717280097770956\n",
      "state terminated\n",
      "episode 3164, reward 106.0, memory_length 2000, epsilon 0.3870566695580002\n",
      "state terminated\n",
      "episode 3165, reward 341.0, memory_length 2000, epsilon 0.3869405729724914\n",
      "state terminated\n",
      "episode 3166, reward 99.0, memory_length 2000, epsilon 0.38682451121073436\n",
      "state terminated\n",
      "episode 3167, reward 204.0, memory_length 2000, epsilon 0.3867084842622836\n",
      "state terminated\n",
      "episode 3168, reward -5.0, memory_length 2000, epsilon 0.3865924921166967\n",
      "state terminated\n",
      "episode 3169, reward 394.0, memory_length 2000, epsilon 0.3864765347635344\n",
      "state terminated\n",
      "episode 3170, reward 245.0, memory_length 2000, epsilon 0.3863606121923604\n",
      "state terminated\n",
      "episode 3171, reward 195.0, memory_length 2000, epsilon 0.3862447243927418\n",
      "state terminated\n",
      "episode 3172, reward 137.0, memory_length 2000, epsilon 0.3861288713542486\n",
      "state terminated\n",
      "episode 3173, reward -144.0, memory_length 2000, epsilon 0.38601305306645417\n",
      "state terminated\n",
      "episode 3174, reward -214.0, memory_length 2000, epsilon 0.3858972695189347\n",
      "state terminated\n",
      "episode 3175, reward -42.0, memory_length 2000, epsilon 0.3857815207012698\n",
      "state terminated\n",
      "episode 3176, reward 40.0, memory_length 2000, epsilon 0.38566580660304206\n",
      "state terminated\n",
      "episode 3177, reward 75.0, memory_length 2000, epsilon 0.3855501272138371\n",
      "state terminated\n",
      "episode 3178, reward -63.0, memory_length 2000, epsilon 0.3854344825232439\n",
      "state terminated\n",
      "episode 3179, reward -3.0, memory_length 2000, epsilon 0.38531887252085434\n",
      "state terminated\n",
      "episode 3180, reward 214.0, memory_length 2000, epsilon 0.38520329719626356\n",
      "state terminated\n",
      "episode 3181, reward 187.0, memory_length 2000, epsilon 0.38508775653906985\n",
      "state terminated\n",
      "episode 3182, reward 130.0, memory_length 2000, epsilon 0.38497225053887446\n",
      "state terminated\n",
      "episode 3183, reward 206.0, memory_length 2000, epsilon 0.3848567791852818\n",
      "state terminated\n",
      "episode 3184, reward 274.0, memory_length 2000, epsilon 0.38474134246789965\n",
      "state terminated\n",
      "episode 3185, reward -86.0, memory_length 2000, epsilon 0.38462594037633857\n",
      "state terminated\n",
      "episode 3186, reward 189.0, memory_length 2000, epsilon 0.3845105729002123\n",
      "state terminated\n",
      "episode 3187, reward 55.0, memory_length 2000, epsilon 0.3843952400291379\n",
      "state terminated\n",
      "episode 3188, reward 113.0, memory_length 2000, epsilon 0.3842799417527354\n",
      "state terminated\n",
      "episode 3189, reward 137.0, memory_length 2000, epsilon 0.3841646780606278\n",
      "state terminated\n",
      "episode 3190, reward 27.0, memory_length 2000, epsilon 0.38404944894244153\n",
      "state terminated\n",
      "episode 3191, reward -9.0, memory_length 2000, epsilon 0.383934254387806\n",
      "state terminated\n",
      "episode 3192, reward 40.0, memory_length 2000, epsilon 0.3838190943863536\n",
      "state terminated\n",
      "episode 3193, reward 310.0, memory_length 2000, epsilon 0.3837039689277199\n",
      "state terminated\n",
      "episode 3194, reward 120.0, memory_length 2000, epsilon 0.38358887800154373\n",
      "state terminated\n",
      "episode 3195, reward 353.0, memory_length 2000, epsilon 0.3834738215974668\n",
      "state terminated\n",
      "episode 3196, reward 163.0, memory_length 2000, epsilon 0.38335879970513403\n",
      "state terminated\n",
      "episode 3197, reward 46.0, memory_length 2000, epsilon 0.3832438123141935\n",
      "state terminated\n",
      "episode 3198, reward 4.0, memory_length 2000, epsilon 0.3831288594142964\n",
      "state terminated\n",
      "episode 3199, reward 147.0, memory_length 2000, epsilon 0.3830139409950969\n",
      "state terminated\n",
      "episode 3200, reward -198.0, memory_length 2000, epsilon 0.3828990570462523\n",
      "state terminated\n",
      "episode 3201, reward -32.0, memory_length 2000, epsilon 0.38278420755742315\n",
      "state terminated\n",
      "episode 3202, reward -156.0, memory_length 2000, epsilon 0.3826693925182729\n",
      "state terminated\n",
      "episode 3203, reward -136.0, memory_length 2000, epsilon 0.3825546119184683\n",
      "state terminated\n",
      "episode 3204, reward -352.0, memory_length 2000, epsilon 0.3824398657476789\n",
      "state terminated\n",
      "episode 3205, reward 247.0, memory_length 2000, epsilon 0.3823251539955778\n",
      "state terminated\n",
      "episode 3206, reward 270.0, memory_length 2000, epsilon 0.38221047665184077\n",
      "state terminated\n",
      "episode 3207, reward -5.0, memory_length 2000, epsilon 0.38209583370614686\n",
      "state terminated\n",
      "episode 3208, reward -164.0, memory_length 2000, epsilon 0.3819812251481783\n",
      "state terminated\n",
      "episode 3209, reward 332.0, memory_length 2000, epsilon 0.38186665096762024\n",
      "state terminated\n",
      "episode 3210, reward 40.0, memory_length 2000, epsilon 0.38175211115416097\n",
      "state terminated\n",
      "episode 3211, reward 67.0, memory_length 2000, epsilon 0.38163760569749205\n",
      "state terminated\n",
      "episode 3212, reward -172.0, memory_length 2000, epsilon 0.38152313458730786\n",
      "state terminated\n",
      "episode 3213, reward 57.0, memory_length 2000, epsilon 0.3814086978133061\n",
      "state terminated\n",
      "episode 3214, reward -58.0, memory_length 2000, epsilon 0.3812942953651873\n",
      "state terminated\n",
      "episode 3215, reward 161.0, memory_length 2000, epsilon 0.38117992723265537\n",
      "state terminated\n",
      "episode 3216, reward 49.0, memory_length 2000, epsilon 0.3810655934054172\n",
      "state terminated\n",
      "episode 3217, reward 217.0, memory_length 2000, epsilon 0.3809512938731826\n",
      "state terminated\n",
      "episode 3218, reward 67.0, memory_length 2000, epsilon 0.38083702862566476\n",
      "state terminated\n",
      "episode 3219, reward -29.0, memory_length 2000, epsilon 0.3807227976525798\n",
      "state terminated\n",
      "episode 3220, reward 302.0, memory_length 2000, epsilon 0.3806086009436468\n",
      "state terminated\n",
      "episode 3221, reward 112.0, memory_length 2000, epsilon 0.3804944384885882\n",
      "state terminated\n",
      "episode 3222, reward -104.0, memory_length 2000, epsilon 0.3803803102771293\n",
      "state terminated\n",
      "episode 3223, reward -73.0, memory_length 2000, epsilon 0.38026621629899865\n",
      "state terminated\n",
      "episode 3224, reward 125.0, memory_length 2000, epsilon 0.3801521565439276\n",
      "state terminated\n",
      "episode 3225, reward -112.0, memory_length 2000, epsilon 0.38003813100165096\n",
      "state terminated\n",
      "episode 3226, reward 118.0, memory_length 2000, epsilon 0.37992413966190636\n",
      "state terminated\n",
      "episode 3227, reward 211.0, memory_length 2000, epsilon 0.37981018251443455\n",
      "state terminated\n",
      "episode 3228, reward -131.0, memory_length 2000, epsilon 0.3796962595489795\n",
      "state terminated\n",
      "episode 3229, reward 110.0, memory_length 2000, epsilon 0.37958237075528806\n",
      "state terminated\n",
      "episode 3230, reward 170.0, memory_length 2000, epsilon 0.37946851612311017\n",
      "state terminated\n",
      "episode 3231, reward 54.0, memory_length 2000, epsilon 0.379354695642199\n",
      "state terminated\n",
      "episode 3232, reward 404.0, memory_length 2000, epsilon 0.37924090930231075\n",
      "state terminated\n",
      "episode 3233, reward 68.0, memory_length 2000, epsilon 0.37912715709320455\n",
      "state terminated\n",
      "episode 3234, reward -126.0, memory_length 2000, epsilon 0.3790134390046428\n",
      "state terminated\n",
      "episode 3235, reward 407.0, memory_length 2000, epsilon 0.3788997550263907\n",
      "state terminated\n",
      "episode 3236, reward 179.0, memory_length 2000, epsilon 0.3787861051482169\n",
      "state terminated\n",
      "episode 3237, reward 303.0, memory_length 2000, epsilon 0.37867248935989284\n",
      "state terminated\n",
      "episode 3238, reward 62.0, memory_length 2000, epsilon 0.37855890765119304\n",
      "state terminated\n",
      "episode 3239, reward 162.0, memory_length 2000, epsilon 0.3784453600118952\n",
      "state terminated\n",
      "episode 3240, reward 288.0, memory_length 2000, epsilon 0.37833184643178003\n",
      "state terminated\n",
      "episode 3241, reward -136.0, memory_length 2000, epsilon 0.3782183669006312\n",
      "state terminated\n",
      "episode 3242, reward 235.0, memory_length 2000, epsilon 0.37810492140823576\n",
      "state terminated\n",
      "episode 3243, reward 0.0, memory_length 2000, epsilon 0.3779915099443834\n",
      "state terminated\n",
      "episode 3244, reward 275.0, memory_length 2000, epsilon 0.37787813249886726\n",
      "state terminated\n",
      "episode 3245, reward 111.0, memory_length 2000, epsilon 0.3777647890614833\n",
      "state terminated\n",
      "episode 3246, reward 8.0, memory_length 2000, epsilon 0.3776514796220306\n",
      "state terminated\n",
      "episode 3247, reward 212.0, memory_length 2000, epsilon 0.37753820417031125\n",
      "state terminated\n",
      "episode 3248, reward 153.0, memory_length 2000, epsilon 0.37742496269613063\n",
      "state terminated\n",
      "episode 3249, reward -3.0, memory_length 2000, epsilon 0.3773117551892969\n",
      "state terminated\n",
      "episode 3250, reward -163.0, memory_length 2000, epsilon 0.37719858163962133\n",
      "state terminated\n",
      "episode 3251, reward -325.0, memory_length 2000, epsilon 0.3770854420369184\n",
      "state terminated\n",
      "episode 3252, reward 67.0, memory_length 2000, epsilon 0.3769723363710055\n",
      "state terminated\n",
      "episode 3253, reward 193.0, memory_length 2000, epsilon 0.3768592646317031\n",
      "state terminated\n",
      "episode 3254, reward 11.0, memory_length 2000, epsilon 0.37674622680883485\n",
      "state terminated\n",
      "episode 3255, reward 0.0, memory_length 2000, epsilon 0.37663322289222717\n",
      "state terminated\n",
      "episode 3256, reward 310.0, memory_length 2000, epsilon 0.3765202528717099\n",
      "state terminated\n",
      "episode 3257, reward 9.0, memory_length 2000, epsilon 0.3764073167371156\n",
      "state terminated\n",
      "episode 3258, reward 427.0, memory_length 2000, epsilon 0.37629441447828005\n",
      "state terminated\n",
      "episode 3259, reward 139.0, memory_length 2000, epsilon 0.37618154608504206\n",
      "state terminated\n",
      "episode 3260, reward -14.0, memory_length 2000, epsilon 0.37606871154724353\n",
      "state terminated\n",
      "episode 3261, reward 245.0, memory_length 2000, epsilon 0.3759559108547292\n",
      "state terminated\n",
      "episode 3262, reward 420.0, memory_length 2000, epsilon 0.37584314399734714\n",
      "state terminated\n",
      "episode 3263, reward 148.0, memory_length 2000, epsilon 0.3757304109649483\n",
      "state terminated\n",
      "episode 3264, reward 35.0, memory_length 2000, epsilon 0.3756177117473867\n",
      "state terminated\n",
      "episode 3265, reward -198.0, memory_length 2000, epsilon 0.3755050463345194\n",
      "state terminated\n",
      "episode 3266, reward 333.0, memory_length 2000, epsilon 0.3753924147162065\n",
      "state terminated\n",
      "episode 3267, reward 106.0, memory_length 2000, epsilon 0.37527981688231127\n",
      "state terminated\n",
      "episode 3268, reward 183.0, memory_length 2000, epsilon 0.3751672528226997\n",
      "state terminated\n",
      "episode 3269, reward 274.0, memory_length 2000, epsilon 0.3750547225272412\n",
      "state terminated\n",
      "episode 3270, reward 154.0, memory_length 2000, epsilon 0.37494222598580795\n",
      "state terminated\n",
      "episode 3271, reward 179.0, memory_length 2000, epsilon 0.37482976318827527\n",
      "state terminated\n",
      "episode 3272, reward 474.0, memory_length 2000, epsilon 0.3747173341245216\n",
      "state terminated\n",
      "episode 3273, reward 129.0, memory_length 2000, epsilon 0.37460493878442824\n",
      "state terminated\n",
      "episode 3274, reward -3.0, memory_length 2000, epsilon 0.3744925771578796\n",
      "state terminated\n",
      "episode 3275, reward 138.0, memory_length 2000, epsilon 0.37438024923476315\n",
      "state terminated\n",
      "episode 3276, reward 238.0, memory_length 2000, epsilon 0.3742679550049694\n",
      "state terminated\n",
      "episode 3277, reward -152.0, memory_length 2000, epsilon 0.37415569445839186\n",
      "state terminated\n",
      "episode 3278, reward 459.0, memory_length 2000, epsilon 0.37404346758492707\n",
      "state terminated\n",
      "episode 3279, reward 112.0, memory_length 2000, epsilon 0.3739312743744746\n",
      "state terminated\n",
      "episode 3280, reward 128.0, memory_length 2000, epsilon 0.3738191148169371\n",
      "state terminated\n",
      "episode 3281, reward -99.0, memory_length 2000, epsilon 0.37370698890222015\n",
      "state terminated\n",
      "episode 3282, reward -142.0, memory_length 2000, epsilon 0.37359489662023243\n",
      "state terminated\n",
      "episode 3283, reward 182.0, memory_length 2000, epsilon 0.37348283796088577\n",
      "state terminated\n",
      "episode 3284, reward 13.0, memory_length 2000, epsilon 0.3733708129140947\n",
      "state terminated\n",
      "episode 3285, reward 73.0, memory_length 2000, epsilon 0.37325882146977707\n",
      "state terminated\n",
      "episode 3286, reward 143.0, memory_length 2000, epsilon 0.3731468636178536\n",
      "state terminated\n",
      "episode 3287, reward 31.0, memory_length 2000, epsilon 0.37303493934824816\n",
      "state terminated\n",
      "episode 3288, reward 67.0, memory_length 2000, epsilon 0.3729230486508874\n",
      "state terminated\n",
      "episode 3289, reward 225.0, memory_length 2000, epsilon 0.37281119151570136\n",
      "state terminated\n",
      "episode 3290, reward 223.0, memory_length 2000, epsilon 0.37269936793262276\n",
      "state terminated\n",
      "episode 3291, reward 121.0, memory_length 2000, epsilon 0.37258757789158753\n",
      "state terminated\n",
      "episode 3292, reward 322.0, memory_length 2000, epsilon 0.3724758213825346\n",
      "state terminated\n",
      "episode 3293, reward -61.0, memory_length 2000, epsilon 0.3723640983954059\n",
      "state terminated\n",
      "episode 3294, reward 162.0, memory_length 2000, epsilon 0.37225240892014616\n",
      "state terminated\n",
      "episode 3295, reward 242.0, memory_length 2000, epsilon 0.37214075294670357\n",
      "state terminated\n",
      "episode 3296, reward 108.0, memory_length 2000, epsilon 0.372029130465029\n",
      "state terminated\n",
      "episode 3297, reward -131.0, memory_length 2000, epsilon 0.3719175414650764\n",
      "state terminated\n",
      "episode 3298, reward 140.0, memory_length 2000, epsilon 0.3718059859368028\n",
      "state terminated\n",
      "episode 3299, reward -234.0, memory_length 2000, epsilon 0.37169446387016813\n",
      "state terminated\n",
      "episode 3300, reward 4.0, memory_length 2000, epsilon 0.3715829752551355\n",
      "state terminated\n",
      "episode 3301, reward 243.0, memory_length 2000, epsilon 0.3714715200816709\n",
      "state terminated\n",
      "episode 3302, reward 71.0, memory_length 2000, epsilon 0.3713600983397433\n",
      "state terminated\n",
      "episode 3303, reward -44.0, memory_length 2000, epsilon 0.3712487100193249\n",
      "state terminated\n",
      "episode 3304, reward 109.0, memory_length 2000, epsilon 0.37113735511039064\n",
      "state terminated\n",
      "episode 3305, reward -108.0, memory_length 2000, epsilon 0.3710260336029185\n",
      "state terminated\n",
      "episode 3306, reward 144.0, memory_length 2000, epsilon 0.3709147454868897\n",
      "state terminated\n",
      "episode 3307, reward 109.0, memory_length 2000, epsilon 0.3708034907522883\n",
      "state terminated\n",
      "episode 3308, reward -193.0, memory_length 2000, epsilon 0.3706922693891012\n",
      "state terminated\n",
      "episode 3309, reward 119.0, memory_length 2000, epsilon 0.37058108138731866\n",
      "state terminated\n",
      "episode 3310, reward -3.0, memory_length 2000, epsilon 0.3704699267369337\n",
      "state terminated\n",
      "episode 3311, reward -6.0, memory_length 2000, epsilon 0.37035880542794236\n",
      "state terminated\n",
      "episode 3312, reward 418.0, memory_length 2000, epsilon 0.3702477174503438\n",
      "state terminated\n",
      "episode 3313, reward -123.0, memory_length 2000, epsilon 0.37013666279414004\n",
      "state terminated\n",
      "episode 3314, reward 184.0, memory_length 2000, epsilon 0.3700256414493362\n",
      "state terminated\n",
      "episode 3315, reward 341.0, memory_length 2000, epsilon 0.36991465340594026\n",
      "state terminated\n",
      "episode 3316, reward 225.0, memory_length 2000, epsilon 0.36980369865396345\n",
      "state terminated\n",
      "episode 3317, reward 195.0, memory_length 2000, epsilon 0.3696927771834198\n",
      "state terminated\n",
      "episode 3318, reward 199.0, memory_length 2000, epsilon 0.3695818889843262\n",
      "state terminated\n",
      "episode 3319, reward -143.0, memory_length 2000, epsilon 0.369471034046703\n",
      "state terminated\n",
      "episode 3320, reward -54.0, memory_length 2000, epsilon 0.3693602123605731\n",
      "state terminated\n",
      "episode 3321, reward 362.0, memory_length 2000, epsilon 0.3692494239159625\n",
      "state terminated\n",
      "episode 3322, reward -79.0, memory_length 2000, epsilon 0.36913866870290035\n",
      "state terminated\n",
      "episode 3323, reward -70.0, memory_length 2000, epsilon 0.36902794671141864\n",
      "state terminated\n",
      "episode 3324, reward 132.0, memory_length 2000, epsilon 0.36891725793155233\n",
      "state terminated\n",
      "episode 3325, reward 229.0, memory_length 2000, epsilon 0.3688066023533395\n",
      "state terminated\n",
      "episode 3326, reward -11.0, memory_length 2000, epsilon 0.36869597996682113\n",
      "state terminated\n",
      "episode 3327, reward -140.0, memory_length 2000, epsilon 0.3685853907620413\n",
      "state terminated\n",
      "episode 3328, reward -72.0, memory_length 2000, epsilon 0.36847483472904674\n",
      "state terminated\n",
      "episode 3329, reward -25.0, memory_length 2000, epsilon 0.36836431185788765\n",
      "state terminated\n",
      "episode 3330, reward 9.0, memory_length 2000, epsilon 0.36825382213861685\n",
      "state terminated\n",
      "episode 3331, reward 53.0, memory_length 2000, epsilon 0.36814336556129024\n",
      "state terminated\n",
      "episode 3332, reward -99.0, memory_length 2000, epsilon 0.3680329421159668\n",
      "state terminated\n",
      "episode 3333, reward 254.0, memory_length 2000, epsilon 0.3679225517927085\n",
      "state terminated\n",
      "episode 3334, reward 106.0, memory_length 2000, epsilon 0.36781219458158004\n",
      "state terminated\n",
      "episode 3335, reward 73.0, memory_length 2000, epsilon 0.3677018704726493\n",
      "state terminated\n",
      "episode 3336, reward 43.0, memory_length 2000, epsilon 0.3675915794559872\n",
      "state terminated\n",
      "episode 3337, reward -45.0, memory_length 2000, epsilon 0.3674813215216675\n",
      "state terminated\n",
      "episode 3338, reward -200.0, memory_length 2000, epsilon 0.367371096659767\n",
      "state terminated\n",
      "episode 3339, reward 99.0, memory_length 2000, epsilon 0.36726090486036544\n",
      "state terminated\n",
      "episode 3340, reward 114.0, memory_length 2000, epsilon 0.3671507461135455\n",
      "state terminated\n",
      "episode 3341, reward 17.0, memory_length 2000, epsilon 0.367040620409393\n",
      "state terminated\n",
      "episode 3342, reward 133.0, memory_length 2000, epsilon 0.3669305277379966\n",
      "state terminated\n",
      "episode 3343, reward 211.0, memory_length 2000, epsilon 0.36682046808944796\n",
      "state terminated\n",
      "episode 3344, reward -115.0, memory_length 2000, epsilon 0.36671044145384163\n",
      "state terminated\n",
      "episode 3345, reward 85.0, memory_length 2000, epsilon 0.3666004478212753\n",
      "state terminated\n",
      "episode 3346, reward 129.0, memory_length 2000, epsilon 0.3664904871818496\n",
      "state terminated\n",
      "episode 3347, reward -45.0, memory_length 2000, epsilon 0.36638055952566784\n",
      "state terminated\n",
      "episode 3348, reward 233.0, memory_length 2000, epsilon 0.36627066484283677\n",
      "state terminated\n",
      "episode 3349, reward 123.0, memory_length 2000, epsilon 0.36616080312346583\n",
      "state terminated\n",
      "episode 3350, reward 24.0, memory_length 2000, epsilon 0.36605097435766737\n",
      "state terminated\n",
      "episode 3351, reward 99.0, memory_length 2000, epsilon 0.36594117853555685\n",
      "state terminated\n",
      "episode 3352, reward -20.0, memory_length 2000, epsilon 0.3658314156472527\n",
      "state terminated\n",
      "episode 3353, reward 283.0, memory_length 2000, epsilon 0.36572168568287605\n",
      "state terminated\n",
      "episode 3354, reward 130.0, memory_length 2000, epsilon 0.3656119886325515\n",
      "state terminated\n",
      "episode 3355, reward 281.0, memory_length 2000, epsilon 0.3655023244864062\n",
      "state terminated\n",
      "episode 3356, reward 201.0, memory_length 2000, epsilon 0.36539269323457024\n",
      "state terminated\n",
      "episode 3357, reward 251.0, memory_length 2000, epsilon 0.36528309486717697\n",
      "state terminated\n",
      "episode 3358, reward 202.0, memory_length 2000, epsilon 0.36517352937436254\n",
      "state terminated\n",
      "episode 3359, reward 99.0, memory_length 2000, epsilon 0.3650639967462659\n",
      "state terminated\n",
      "episode 3360, reward 44.0, memory_length 2000, epsilon 0.36495449697302923\n",
      "state terminated\n",
      "episode 3361, reward -6.0, memory_length 2000, epsilon 0.36484503004479757\n",
      "state terminated\n",
      "episode 3362, reward -132.0, memory_length 2000, epsilon 0.36473559595171884\n",
      "state terminated\n",
      "episode 3363, reward 210.0, memory_length 2000, epsilon 0.364626194683944\n",
      "state terminated\n",
      "episode 3364, reward -71.0, memory_length 2000, epsilon 0.36451682623162696\n",
      "state terminated\n",
      "episode 3365, reward 210.0, memory_length 2000, epsilon 0.3644074905849245\n",
      "state terminated\n",
      "episode 3366, reward 23.0, memory_length 2000, epsilon 0.3642981877339964\n",
      "state terminated\n",
      "episode 3367, reward 6.0, memory_length 2000, epsilon 0.36418891766900546\n",
      "state terminated\n",
      "episode 3368, reward 216.0, memory_length 2000, epsilon 0.36407968038011734\n",
      "state terminated\n",
      "episode 3369, reward 229.0, memory_length 2000, epsilon 0.36397047585750075\n",
      "state terminated\n",
      "episode 3370, reward 478.0, memory_length 2000, epsilon 0.3638613040913273\n",
      "state terminated\n",
      "episode 3371, reward 399.0, memory_length 2000, epsilon 0.3637521650717713\n",
      "state terminated\n",
      "episode 3372, reward -37.0, memory_length 2000, epsilon 0.36364305878901054\n",
      "state terminated\n",
      "episode 3373, reward -81.0, memory_length 2000, epsilon 0.3635339852332252\n",
      "state terminated\n",
      "episode 3374, reward 171.0, memory_length 2000, epsilon 0.3634249443945988\n",
      "state terminated\n",
      "episode 3375, reward -278.0, memory_length 2000, epsilon 0.3633159362633177\n",
      "state terminated\n",
      "episode 3376, reward -243.0, memory_length 2000, epsilon 0.3632069608295711\n",
      "state terminated\n",
      "episode 3377, reward 165.0, memory_length 2000, epsilon 0.36309801808355124\n",
      "state terminated\n",
      "episode 3378, reward -16.0, memory_length 2000, epsilon 0.3629891080154532\n",
      "state terminated\n",
      "episode 3379, reward 146.0, memory_length 2000, epsilon 0.3628802306154752\n",
      "state terminated\n",
      "episode 3380, reward -129.0, memory_length 2000, epsilon 0.362771385873818\n",
      "state terminated\n",
      "episode 3381, reward 120.0, memory_length 2000, epsilon 0.36266257378068595\n",
      "state terminated\n",
      "episode 3382, reward 117.0, memory_length 2000, epsilon 0.3625537943262858\n",
      "state terminated\n",
      "episode 3383, reward -96.0, memory_length 2000, epsilon 0.3624450475008273\n",
      "state terminated\n",
      "episode 3384, reward 83.0, memory_length 2000, epsilon 0.36233633329452336\n",
      "state terminated\n",
      "episode 3385, reward -117.0, memory_length 2000, epsilon 0.3622276516975897\n",
      "state terminated\n",
      "episode 3386, reward 81.0, memory_length 2000, epsilon 0.3621190027002449\n",
      "state terminated\n",
      "episode 3387, reward -153.0, memory_length 2000, epsilon 0.3620103862927105\n",
      "state terminated\n",
      "episode 3388, reward 346.0, memory_length 2000, epsilon 0.3619018024652112\n",
      "state terminated\n",
      "episode 3389, reward 296.0, memory_length 2000, epsilon 0.3617932512079744\n",
      "state terminated\n",
      "episode 3390, reward 215.0, memory_length 2000, epsilon 0.3616847325112304\n",
      "state terminated\n",
      "episode 3391, reward 102.0, memory_length 2000, epsilon 0.3615762463652126\n",
      "state terminated\n",
      "episode 3392, reward -5.0, memory_length 2000, epsilon 0.3614677927601572\n",
      "state terminated\n",
      "episode 3393, reward -1.0, memory_length 2000, epsilon 0.36135937168630344\n",
      "state terminated\n",
      "episode 3394, reward 129.0, memory_length 2000, epsilon 0.36125098313389326\n",
      "state terminated\n",
      "episode 3395, reward -91.0, memory_length 2000, epsilon 0.36114262709317185\n",
      "state terminated\n",
      "episode 3396, reward -18.0, memory_length 2000, epsilon 0.36103430355438715\n",
      "state terminated\n",
      "episode 3397, reward 44.0, memory_length 2000, epsilon 0.36092601250779005\n",
      "state terminated\n",
      "episode 3398, reward 156.0, memory_length 2000, epsilon 0.36081775394363425\n",
      "state terminated\n",
      "episode 3399, reward 31.0, memory_length 2000, epsilon 0.3607095278521766\n",
      "state terminated\n",
      "episode 3400, reward -84.0, memory_length 2000, epsilon 0.3606013342236766\n",
      "state terminated\n",
      "episode 3401, reward -48.0, memory_length 2000, epsilon 0.36049317304839695\n",
      "state terminated\n",
      "episode 3402, reward 24.0, memory_length 2000, epsilon 0.36038504431660323\n",
      "state terminated\n",
      "episode 3403, reward 126.0, memory_length 2000, epsilon 0.3602769480185637\n",
      "state terminated\n",
      "episode 3404, reward 108.0, memory_length 2000, epsilon 0.3601688841445497\n",
      "state terminated\n",
      "episode 3405, reward 434.0, memory_length 2000, epsilon 0.3600608526848355\n",
      "state terminated\n",
      "episode 3406, reward -1.0, memory_length 2000, epsilon 0.35995285362969837\n",
      "state terminated\n",
      "episode 3407, reward 69.0, memory_length 2000, epsilon 0.3598448869694182\n",
      "state terminated\n",
      "episode 3408, reward -190.0, memory_length 2000, epsilon 0.35973695269427813\n",
      "state terminated\n",
      "episode 3409, reward 180.0, memory_length 2000, epsilon 0.35962905079456414\n",
      "state terminated\n",
      "episode 3410, reward 18.0, memory_length 2000, epsilon 0.35952118126056487\n",
      "state terminated\n",
      "episode 3411, reward 183.0, memory_length 2000, epsilon 0.3594133440825722\n",
      "state terminated\n",
      "episode 3412, reward 64.0, memory_length 2000, epsilon 0.3593055392508807\n",
      "state terminated\n",
      "episode 3413, reward 262.0, memory_length 2000, epsilon 0.359197766755788\n",
      "state terminated\n",
      "episode 3414, reward 65.0, memory_length 2000, epsilon 0.3590900265875945\n",
      "state terminated\n",
      "episode 3415, reward 512.0, memory_length 2000, epsilon 0.3589823187366037\n",
      "state terminated\n",
      "episode 3416, reward -248.0, memory_length 2000, epsilon 0.3588746431931218\n",
      "state terminated\n",
      "episode 3417, reward 216.0, memory_length 2000, epsilon 0.35876699994745803\n",
      "state terminated\n",
      "episode 3418, reward -6.0, memory_length 2000, epsilon 0.35865938898992455\n",
      "state terminated\n",
      "episode 3419, reward -52.0, memory_length 2000, epsilon 0.35855181031083627\n",
      "state terminated\n",
      "episode 3420, reward 206.0, memory_length 2000, epsilon 0.3584442639005112\n",
      "state terminated\n",
      "episode 3421, reward 120.0, memory_length 2000, epsilon 0.35833674974927004\n",
      "state terminated\n",
      "episode 3422, reward -78.0, memory_length 2000, epsilon 0.35822926784743664\n",
      "state terminated\n",
      "episode 3423, reward -57.0, memory_length 2000, epsilon 0.35812181818533756\n",
      "state terminated\n",
      "episode 3424, reward 336.0, memory_length 2000, epsilon 0.35801440075330243\n",
      "state terminated\n",
      "episode 3425, reward -198.0, memory_length 2000, epsilon 0.3579070155416636\n",
      "state terminated\n",
      "episode 3426, reward 123.0, memory_length 2000, epsilon 0.35779966254075635\n",
      "state terminated\n",
      "episode 3427, reward -192.0, memory_length 2000, epsilon 0.35769234174091896\n",
      "state terminated\n",
      "episode 3428, reward 154.0, memory_length 2000, epsilon 0.35758505313249267\n",
      "state terminated\n",
      "episode 3429, reward -132.0, memory_length 2000, epsilon 0.3574777967058213\n",
      "state terminated\n",
      "episode 3430, reward 195.0, memory_length 2000, epsilon 0.357370572451252\n",
      "state terminated\n",
      "episode 3431, reward 85.0, memory_length 2000, epsilon 0.35726338035913435\n",
      "state terminated\n",
      "episode 3432, reward 37.0, memory_length 2000, epsilon 0.3571562204198212\n",
      "state terminated\n",
      "episode 3433, reward 102.0, memory_length 2000, epsilon 0.3570490926236682\n",
      "state terminated\n",
      "episode 3434, reward 146.0, memory_length 2000, epsilon 0.3569419969610336\n",
      "state terminated\n",
      "episode 3435, reward 276.0, memory_length 2000, epsilon 0.3568349334222791\n",
      "state terminated\n",
      "episode 3436, reward 172.0, memory_length 2000, epsilon 0.3567279019977688\n",
      "state terminated\n",
      "episode 3437, reward 58.0, memory_length 2000, epsilon 0.35662090267787\n",
      "state terminated\n",
      "episode 3438, reward 198.0, memory_length 2000, epsilon 0.3565139354529527\n",
      "state terminated\n",
      "episode 3439, reward 313.0, memory_length 2000, epsilon 0.35640700031338973\n",
      "state terminated\n",
      "episode 3440, reward 301.0, memory_length 2000, epsilon 0.3563000972495571\n",
      "state terminated\n",
      "episode 3441, reward 116.0, memory_length 2000, epsilon 0.3561932262518333\n",
      "state terminated\n",
      "episode 3442, reward 271.0, memory_length 2000, epsilon 0.35608638731060027\n",
      "state terminated\n",
      "episode 3443, reward 255.0, memory_length 2000, epsilon 0.3559795804162423\n",
      "state terminated\n",
      "episode 3444, reward 188.0, memory_length 2000, epsilon 0.3558728055591468\n",
      "state terminated\n",
      "episode 3445, reward 109.0, memory_length 2000, epsilon 0.35576606272970407\n",
      "state terminated\n",
      "episode 3446, reward 70.0, memory_length 2000, epsilon 0.3556593519183072\n",
      "state terminated\n",
      "episode 3447, reward 34.0, memory_length 2000, epsilon 0.3555526731153522\n",
      "state terminated\n",
      "episode 3448, reward 345.0, memory_length 2000, epsilon 0.35544602631123806\n",
      "state terminated\n",
      "episode 3449, reward 333.0, memory_length 2000, epsilon 0.35533941149636655\n",
      "state terminated\n",
      "episode 3450, reward -51.0, memory_length 2000, epsilon 0.3552328286611423\n",
      "state terminated\n",
      "episode 3451, reward 238.0, memory_length 2000, epsilon 0.3551262777959729\n",
      "state terminated\n",
      "episode 3452, reward 99.0, memory_length 2000, epsilon 0.3550197588912687\n",
      "state terminated\n",
      "episode 3453, reward 50.0, memory_length 2000, epsilon 0.35491327193744304\n",
      "state terminated\n",
      "episode 3454, reward 63.0, memory_length 2000, epsilon 0.35480681692491206\n",
      "state terminated\n",
      "episode 3455, reward 252.0, memory_length 2000, epsilon 0.3547003938440949\n",
      "state terminated\n",
      "episode 3456, reward -72.0, memory_length 2000, epsilon 0.3545940026854134\n",
      "state terminated\n",
      "episode 3457, reward 47.0, memory_length 2000, epsilon 0.3544876434392924\n",
      "state terminated\n",
      "episode 3458, reward -58.0, memory_length 2000, epsilon 0.3543813160961595\n",
      "state terminated\n",
      "episode 3459, reward 378.0, memory_length 2000, epsilon 0.3542750206464454\n",
      "state terminated\n",
      "episode 3460, reward -89.0, memory_length 2000, epsilon 0.3541687570805833\n",
      "state terminated\n",
      "episode 3461, reward 85.0, memory_length 2000, epsilon 0.35406252538900956\n",
      "state terminated\n",
      "episode 3462, reward -40.0, memory_length 2000, epsilon 0.3539563255621634\n",
      "state terminated\n",
      "episode 3463, reward 309.0, memory_length 2000, epsilon 0.35385015759048677\n",
      "state terminated\n",
      "episode 3464, reward -68.0, memory_length 2000, epsilon 0.3537440214644246\n",
      "state terminated\n",
      "episode 3465, reward 112.0, memory_length 2000, epsilon 0.35363791717442455\n",
      "state terminated\n",
      "episode 3466, reward 355.0, memory_length 2000, epsilon 0.35353184471093724\n",
      "state terminated\n",
      "episode 3467, reward 44.0, memory_length 2000, epsilon 0.3534258040644163\n",
      "state terminated\n",
      "episode 3468, reward 12.0, memory_length 2000, epsilon 0.35331979522531787\n",
      "state terminated\n",
      "episode 3469, reward -4.0, memory_length 2000, epsilon 0.35321381818410125\n",
      "state terminated\n",
      "episode 3470, reward -57.0, memory_length 2000, epsilon 0.3531078729312286\n",
      "state terminated\n",
      "episode 3471, reward 313.0, memory_length 2000, epsilon 0.35300195945716467\n",
      "state terminated\n",
      "episode 3472, reward 124.0, memory_length 2000, epsilon 0.35289607775237736\n",
      "state terminated\n",
      "episode 3473, reward 208.0, memory_length 2000, epsilon 0.3527902278073373\n",
      "state terminated\n",
      "episode 3474, reward 268.0, memory_length 2000, epsilon 0.3526844096125179\n",
      "state terminated\n",
      "episode 3475, reward 37.0, memory_length 2000, epsilon 0.35257862315839567\n",
      "state terminated\n",
      "episode 3476, reward 183.0, memory_length 2000, epsilon 0.3524728684354497\n",
      "state terminated\n",
      "episode 3477, reward -142.0, memory_length 2000, epsilon 0.35236714543416225\n",
      "state terminated\n",
      "episode 3478, reward -224.0, memory_length 2000, epsilon 0.3522614541450181\n",
      "state terminated\n",
      "episode 3479, reward 190.0, memory_length 2000, epsilon 0.352155794558505\n",
      "state terminated\n",
      "episode 3480, reward 20.0, memory_length 2000, epsilon 0.35205016666511363\n",
      "state terminated\n",
      "episode 3481, reward 282.0, memory_length 2000, epsilon 0.3519445704553375\n",
      "state terminated\n",
      "episode 3482, reward -75.0, memory_length 2000, epsilon 0.351839005919673\n",
      "state terminated\n",
      "episode 3483, reward 398.0, memory_length 2000, epsilon 0.35173347304861924\n",
      "state terminated\n",
      "episode 3484, reward 103.0, memory_length 2000, epsilon 0.3516279718326783\n",
      "state terminated\n",
      "episode 3485, reward 198.0, memory_length 2000, epsilon 0.3515225022623551\n",
      "state terminated\n",
      "episode 3486, reward 225.0, memory_length 2000, epsilon 0.35141706432815734\n",
      "state terminated\n",
      "episode 3487, reward 332.0, memory_length 2000, epsilon 0.3513116580205956\n",
      "state terminated\n",
      "episode 3488, reward 16.0, memory_length 2000, epsilon 0.35120628333018317\n",
      "state terminated\n",
      "episode 3489, reward 141.0, memory_length 2000, epsilon 0.35110094024743665\n",
      "state terminated\n",
      "episode 3490, reward -1.0, memory_length 2000, epsilon 0.35099562876287493\n",
      "state terminated\n",
      "episode 3491, reward 125.0, memory_length 2000, epsilon 0.3508903488670201\n",
      "state terminated\n",
      "episode 3492, reward 141.0, memory_length 2000, epsilon 0.35078510055039686\n",
      "state terminated\n",
      "episode 3493, reward -19.0, memory_length 2000, epsilon 0.3506798838035329\n",
      "state terminated\n",
      "episode 3494, reward 61.0, memory_length 2000, epsilon 0.35057469861695867\n",
      "state terminated\n",
      "episode 3495, reward -177.0, memory_length 2000, epsilon 0.3504695449812076\n",
      "state terminated\n",
      "episode 3496, reward 304.0, memory_length 2000, epsilon 0.3503644228868158\n",
      "state terminated\n",
      "episode 3497, reward 130.0, memory_length 2000, epsilon 0.3502593323243223\n",
      "state terminated\n",
      "episode 3498, reward 106.0, memory_length 2000, epsilon 0.350154273284269\n",
      "state terminated\n",
      "episode 3499, reward 189.0, memory_length 2000, epsilon 0.3500492457572005\n",
      "state terminated\n",
      "episode 3500, reward 348.0, memory_length 2000, epsilon 0.34994424973366434\n",
      "state terminated\n",
      "episode 3501, reward 280.0, memory_length 2000, epsilon 0.3498392852042108\n",
      "state terminated\n",
      "episode 3502, reward -199.0, memory_length 2000, epsilon 0.3497343521593933\n",
      "state terminated\n",
      "episode 3503, reward 76.0, memory_length 2000, epsilon 0.3496294505897677\n",
      "state terminated\n",
      "episode 3504, reward 300.0, memory_length 2000, epsilon 0.34952458048589286\n",
      "state terminated\n",
      "episode 3505, reward 179.0, memory_length 2000, epsilon 0.3494197418383306\n",
      "state terminated\n",
      "episode 3506, reward 253.0, memory_length 2000, epsilon 0.3493149346376452\n",
      "state terminated\n",
      "episode 3507, reward -216.0, memory_length 2000, epsilon 0.34921015887440426\n",
      "state terminated\n",
      "episode 3508, reward -295.0, memory_length 2000, epsilon 0.3491054145391777\n",
      "state terminated\n",
      "episode 3509, reward -18.0, memory_length 2000, epsilon 0.3490007016225388\n",
      "state terminated\n",
      "episode 3510, reward 234.0, memory_length 2000, epsilon 0.34889602011506327\n",
      "state terminated\n",
      "episode 3511, reward 23.0, memory_length 2000, epsilon 0.3487913700073298\n",
      "state terminated\n",
      "episode 3512, reward 245.0, memory_length 2000, epsilon 0.34868675128991994\n",
      "state terminated\n",
      "episode 3513, reward 179.0, memory_length 2000, epsilon 0.34858216395341785\n",
      "state terminated\n",
      "episode 3514, reward -77.0, memory_length 2000, epsilon 0.3484776079884107\n",
      "state terminated\n",
      "episode 3515, reward 160.0, memory_length 2000, epsilon 0.3483730833854885\n",
      "state terminated\n",
      "episode 3516, reward 236.0, memory_length 2000, epsilon 0.34826859013524414\n",
      "state terminated\n",
      "episode 3517, reward 106.0, memory_length 2000, epsilon 0.34816412822827303\n",
      "state terminated\n",
      "episode 3518, reward 183.0, memory_length 2000, epsilon 0.3480596976551738\n",
      "state terminated\n",
      "episode 3519, reward 270.0, memory_length 2000, epsilon 0.34795529840654754\n",
      "state terminated\n",
      "episode 3520, reward 56.0, memory_length 2000, epsilon 0.34785093047299837\n",
      "state terminated\n",
      "episode 3521, reward 105.0, memory_length 2000, epsilon 0.3477465938451331\n",
      "state terminated\n",
      "episode 3522, reward 46.0, memory_length 2000, epsilon 0.3476422885135616\n",
      "state terminated\n",
      "episode 3523, reward 252.0, memory_length 2000, epsilon 0.3475380144688963\n",
      "state terminated\n",
      "episode 3524, reward 76.0, memory_length 2000, epsilon 0.34743377170175255\n",
      "state terminated\n",
      "episode 3525, reward 117.0, memory_length 2000, epsilon 0.3473295602027484\n",
      "state terminated\n",
      "episode 3526, reward 191.0, memory_length 2000, epsilon 0.347225379962505\n",
      "state terminated\n",
      "episode 3527, reward 128.0, memory_length 2000, epsilon 0.34712123097164604\n",
      "state terminated\n",
      "episode 3528, reward 72.0, memory_length 2000, epsilon 0.347017113220798\n",
      "state terminated\n",
      "episode 3529, reward -102.0, memory_length 2000, epsilon 0.34691302670059043\n",
      "state terminated\n",
      "episode 3530, reward 117.0, memory_length 2000, epsilon 0.3468089714016555\n",
      "state terminated\n",
      "episode 3531, reward -30.0, memory_length 2000, epsilon 0.34670494731462825\n",
      "state terminated\n",
      "episode 3532, reward 82.0, memory_length 2000, epsilon 0.3466009544301465\n",
      "state terminated\n",
      "episode 3533, reward -3.0, memory_length 2000, epsilon 0.3464969927388509\n",
      "state terminated\n",
      "episode 3534, reward 162.0, memory_length 2000, epsilon 0.34639306223138483\n",
      "state terminated\n",
      "episode 3535, reward 196.0, memory_length 2000, epsilon 0.34628916289839456\n",
      "state terminated\n",
      "episode 3536, reward 265.0, memory_length 2000, epsilon 0.3461852947305292\n",
      "state terminated\n",
      "episode 3537, reward 31.0, memory_length 2000, epsilon 0.3460814577184407\n",
      "state terminated\n",
      "episode 3538, reward -61.0, memory_length 2000, epsilon 0.3459776518527835\n",
      "state terminated\n",
      "episode 3539, reward 94.0, memory_length 2000, epsilon 0.34587387712421536\n",
      "state terminated\n",
      "episode 3540, reward 360.0, memory_length 2000, epsilon 0.34577013352339625\n",
      "state terminated\n",
      "episode 3541, reward -63.0, memory_length 2000, epsilon 0.3456664210409895\n",
      "state terminated\n",
      "episode 3542, reward -122.0, memory_length 2000, epsilon 0.3455627396676607\n",
      "state terminated\n",
      "episode 3543, reward 125.0, memory_length 2000, epsilon 0.3454590893940788\n",
      "state terminated\n",
      "episode 3544, reward 245.0, memory_length 2000, epsilon 0.3453554702109153\n",
      "state terminated\n",
      "episode 3545, reward 335.0, memory_length 2000, epsilon 0.3452518821088442\n",
      "state terminated\n",
      "episode 3546, reward 76.0, memory_length 2000, epsilon 0.3451483250785428\n",
      "state terminated\n",
      "episode 3547, reward 236.0, memory_length 2000, epsilon 0.34504479911069086\n",
      "state terminated\n",
      "episode 3548, reward 72.0, memory_length 2000, epsilon 0.344941304195971\n",
      "state terminated\n",
      "episode 3549, reward 141.0, memory_length 2000, epsilon 0.34483784032506887\n",
      "state terminated\n",
      "episode 3550, reward -126.0, memory_length 2000, epsilon 0.3447344074886725\n",
      "state terminated\n",
      "episode 3551, reward 152.0, memory_length 2000, epsilon 0.3446310056774731\n",
      "state terminated\n",
      "episode 3552, reward 89.0, memory_length 2000, epsilon 0.3445276348821645\n",
      "state terminated\n",
      "episode 3553, reward 198.0, memory_length 2000, epsilon 0.34442429509344324\n",
      "state terminated\n",
      "episode 3554, reward -37.0, memory_length 2000, epsilon 0.3443209863020087\n",
      "state terminated\n",
      "episode 3555, reward 18.0, memory_length 2000, epsilon 0.34421770849856315\n",
      "state terminated\n",
      "episode 3556, reward 164.0, memory_length 2000, epsilon 0.34411446167381166\n",
      "state terminated\n",
      "episode 3557, reward 351.0, memory_length 2000, epsilon 0.34401124581846193\n",
      "state terminated\n",
      "episode 3558, reward 198.0, memory_length 2000, epsilon 0.34390806092322457\n",
      "state terminated\n",
      "episode 3559, reward 175.0, memory_length 2000, epsilon 0.34380490697881294\n",
      "state terminated\n",
      "episode 3560, reward -219.0, memory_length 2000, epsilon 0.34370178397594314\n",
      "state terminated\n",
      "episode 3561, reward -213.0, memory_length 2000, epsilon 0.34359869190533415\n",
      "state terminated\n",
      "episode 3562, reward -145.0, memory_length 2000, epsilon 0.3434956307577076\n",
      "state terminated\n",
      "episode 3563, reward -196.0, memory_length 2000, epsilon 0.3433926005237881\n",
      "state terminated\n",
      "episode 3564, reward -143.0, memory_length 2000, epsilon 0.34328960119430296\n",
      "state terminated\n",
      "episode 3565, reward 206.0, memory_length 2000, epsilon 0.34318663275998207\n",
      "state terminated\n",
      "episode 3566, reward 311.0, memory_length 2000, epsilon 0.3430836952115584\n",
      "state terminated\n",
      "episode 3567, reward -23.0, memory_length 2000, epsilon 0.3429807885397675\n",
      "state terminated\n",
      "episode 3568, reward 139.0, memory_length 2000, epsilon 0.3428779127353478\n",
      "state terminated\n",
      "episode 3569, reward 227.0, memory_length 2000, epsilon 0.34277506778904043\n",
      "state terminated\n",
      "episode 3570, reward 103.0, memory_length 2000, epsilon 0.34267225369158943\n",
      "state terminated\n",
      "episode 3571, reward 311.0, memory_length 2000, epsilon 0.34256947043374153\n",
      "state terminated\n",
      "episode 3572, reward 164.0, memory_length 2000, epsilon 0.3424667180062462\n",
      "state terminated\n",
      "episode 3573, reward 51.0, memory_length 2000, epsilon 0.34236399639985565\n",
      "state terminated\n",
      "episode 3574, reward 73.0, memory_length 2000, epsilon 0.3422613056053251\n",
      "state terminated\n",
      "episode 3575, reward -52.0, memory_length 2000, epsilon 0.34215864561341214\n",
      "state terminated\n",
      "episode 3576, reward 208.0, memory_length 2000, epsilon 0.34205601641487765\n",
      "state terminated\n",
      "episode 3577, reward 166.0, memory_length 2000, epsilon 0.34195341800048484\n",
      "state terminated\n",
      "episode 3578, reward 252.0, memory_length 2000, epsilon 0.3418508503609999\n",
      "state terminated\n",
      "episode 3579, reward -130.0, memory_length 2000, epsilon 0.3417483134871917\n",
      "state terminated\n",
      "episode 3580, reward -79.0, memory_length 2000, epsilon 0.34164580736983197\n",
      "state terminated\n",
      "episode 3581, reward 85.0, memory_length 2000, epsilon 0.3415433319996951\n",
      "state terminated\n",
      "episode 3582, reward 13.0, memory_length 2000, epsilon 0.3414408873675583\n",
      "state terminated\n",
      "episode 3583, reward 106.0, memory_length 2000, epsilon 0.34133847346420165\n",
      "state terminated\n",
      "episode 3584, reward 303.0, memory_length 2000, epsilon 0.3412360902804078\n",
      "state terminated\n",
      "episode 3585, reward -109.0, memory_length 2000, epsilon 0.3411337378069624\n",
      "state terminated\n",
      "episode 3586, reward 66.0, memory_length 2000, epsilon 0.34103141603465353\n",
      "state terminated\n",
      "episode 3587, reward 22.0, memory_length 2000, epsilon 0.34092912495427247\n",
      "state terminated\n",
      "episode 3588, reward 132.0, memory_length 2000, epsilon 0.34082686455661276\n",
      "state terminated\n",
      "episode 3589, reward 87.0, memory_length 2000, epsilon 0.340724634832471\n",
      "state terminated\n",
      "episode 3590, reward -22.0, memory_length 2000, epsilon 0.3406224357726468\n",
      "state terminated\n",
      "episode 3591, reward 203.0, memory_length 2000, epsilon 0.340520267367942\n",
      "state terminated\n",
      "episode 3592, reward -7.0, memory_length 2000, epsilon 0.34041812960916146\n",
      "state terminated\n",
      "episode 3593, reward 67.0, memory_length 2000, epsilon 0.34031602248711285\n",
      "state terminated\n",
      "episode 3594, reward 288.0, memory_length 2000, epsilon 0.34021394599260646\n",
      "state terminated\n",
      "episode 3595, reward 97.0, memory_length 2000, epsilon 0.34011190011645537\n",
      "state terminated\n",
      "episode 3596, reward 252.0, memory_length 2000, epsilon 0.3400098848494756\n",
      "state terminated\n",
      "episode 3597, reward 25.0, memory_length 2000, epsilon 0.3399079001824857\n",
      "state terminated\n",
      "episode 3598, reward 620.0, memory_length 2000, epsilon 0.3398059461063071\n",
      "state terminated\n",
      "episode 3599, reward 66.0, memory_length 2000, epsilon 0.3397040226117638\n",
      "state terminated\n",
      "episode 3600, reward 51.0, memory_length 2000, epsilon 0.3396021296896828\n",
      "state terminated\n",
      "episode 3601, reward 189.0, memory_length 2000, epsilon 0.33950026733089367\n",
      "state terminated\n",
      "episode 3602, reward 361.0, memory_length 2000, epsilon 0.3393984355262288\n",
      "state terminated\n",
      "episode 3603, reward -99.0, memory_length 2000, epsilon 0.3392966342665234\n",
      "state terminated\n",
      "episode 3604, reward 22.0, memory_length 2000, epsilon 0.3391948635426153\n",
      "state terminated\n",
      "episode 3605, reward 146.0, memory_length 2000, epsilon 0.33909312334534514\n",
      "state terminated\n",
      "episode 3606, reward 247.0, memory_length 2000, epsilon 0.3389914136655564\n",
      "state terminated\n",
      "episode 3607, reward 133.0, memory_length 2000, epsilon 0.33888973449409504\n",
      "state terminated\n",
      "episode 3608, reward -16.0, memory_length 2000, epsilon 0.33878808582181\n",
      "state terminated\n",
      "episode 3609, reward 61.0, memory_length 2000, epsilon 0.33868646763955285\n",
      "state terminated\n",
      "episode 3610, reward 198.0, memory_length 2000, epsilon 0.33858487993817815\n",
      "state terminated\n",
      "episode 3611, reward 165.0, memory_length 2000, epsilon 0.3384833227085428\n",
      "state terminated\n",
      "episode 3612, reward 80.0, memory_length 2000, epsilon 0.3383817959415068\n",
      "state terminated\n",
      "episode 3613, reward 35.0, memory_length 2000, epsilon 0.3382802996279326\n",
      "state terminated\n",
      "episode 3614, reward 161.0, memory_length 2000, epsilon 0.3381788337586856\n",
      "state terminated\n",
      "episode 3615, reward 77.0, memory_length 2000, epsilon 0.3380773983246339\n",
      "state terminated\n",
      "episode 3616, reward 62.0, memory_length 2000, epsilon 0.3379759933166482\n",
      "state terminated\n",
      "episode 3617, reward -5.0, memory_length 2000, epsilon 0.3378746187256022\n",
      "state terminated\n",
      "episode 3618, reward 218.0, memory_length 2000, epsilon 0.33777327454237205\n",
      "state terminated\n",
      "episode 3619, reward 169.0, memory_length 2000, epsilon 0.3376719607578369\n",
      "state terminated\n",
      "episode 3620, reward 78.0, memory_length 2000, epsilon 0.3375706773628784\n",
      "state terminated\n",
      "episode 3621, reward 30.0, memory_length 2000, epsilon 0.3374694243483811\n",
      "state terminated\n",
      "episode 3622, reward -127.0, memory_length 2000, epsilon 0.3373682017052322\n",
      "state terminated\n",
      "episode 3623, reward 110.0, memory_length 2000, epsilon 0.3372670094243217\n",
      "state terminated\n",
      "episode 3624, reward 183.0, memory_length 2000, epsilon 0.3371658474965423\n",
      "state terminated\n",
      "episode 3625, reward 189.0, memory_length 2000, epsilon 0.3370647159127894\n",
      "state terminated\n",
      "episode 3626, reward 295.0, memory_length 2000, epsilon 0.3369636146639612\n",
      "state terminated\n",
      "episode 3627, reward -87.0, memory_length 2000, epsilon 0.3368625437409585\n",
      "state terminated\n",
      "episode 3628, reward 164.0, memory_length 2000, epsilon 0.33676150313468495\n",
      "state terminated\n",
      "episode 3629, reward 313.0, memory_length 2000, epsilon 0.3366604928360469\n",
      "state terminated\n",
      "episode 3630, reward 250.0, memory_length 2000, epsilon 0.3365595128359534\n",
      "state terminated\n",
      "episode 3631, reward 288.0, memory_length 2000, epsilon 0.33645856312531636\n",
      "state terminated\n",
      "episode 3632, reward 11.0, memory_length 2000, epsilon 0.3363576436950502\n",
      "state terminated\n",
      "episode 3633, reward 228.0, memory_length 2000, epsilon 0.33625675453607223\n",
      "state terminated\n",
      "episode 3634, reward 220.0, memory_length 2000, epsilon 0.33615589563930237\n",
      "state terminated\n",
      "episode 3635, reward 189.0, memory_length 2000, epsilon 0.33605506699566334\n",
      "state terminated\n",
      "episode 3636, reward 135.0, memory_length 2000, epsilon 0.3359542685960805\n",
      "state terminated\n",
      "episode 3637, reward 88.0, memory_length 2000, epsilon 0.3358535004314821\n",
      "state terminated\n",
      "episode 3638, reward 73.0, memory_length 2000, epsilon 0.33575276249279906\n",
      "state terminated\n",
      "episode 3639, reward 13.0, memory_length 2000, epsilon 0.33565205477096477\n",
      "state terminated\n",
      "episode 3640, reward 132.0, memory_length 2000, epsilon 0.3355513772569157\n",
      "state terminated\n",
      "episode 3641, reward 79.0, memory_length 2000, epsilon 0.3354507299415908\n",
      "state terminated\n",
      "episode 3642, reward 44.0, memory_length 2000, epsilon 0.3353501128159318\n",
      "state terminated\n",
      "episode 3643, reward 162.0, memory_length 2000, epsilon 0.33524952587088314\n",
      "state terminated\n",
      "episode 3644, reward 104.0, memory_length 2000, epsilon 0.3351489690973921\n",
      "state terminated\n",
      "episode 3645, reward 78.0, memory_length 2000, epsilon 0.33504844248640847\n",
      "state terminated\n",
      "episode 3646, reward 250.0, memory_length 2000, epsilon 0.33494794602888495\n",
      "state terminated\n",
      "episode 3647, reward 139.0, memory_length 2000, epsilon 0.3348474797157767\n",
      "state terminated\n",
      "episode 3648, reward 188.0, memory_length 2000, epsilon 0.33474704353804197\n",
      "state terminated\n",
      "episode 3649, reward 174.0, memory_length 2000, epsilon 0.3346466374866412\n",
      "state terminated\n",
      "episode 3650, reward 215.0, memory_length 2000, epsilon 0.33454626155253814\n",
      "state terminated\n",
      "episode 3651, reward 364.0, memory_length 2000, epsilon 0.33444591572669885\n",
      "state terminated\n",
      "episode 3652, reward -54.0, memory_length 2000, epsilon 0.3343456000000923\n",
      "state terminated\n",
      "episode 3653, reward -118.0, memory_length 2000, epsilon 0.33424531436368987\n",
      "state terminated\n",
      "episode 3654, reward -127.0, memory_length 2000, epsilon 0.3341450588084659\n",
      "state terminated\n",
      "episode 3655, reward 103.0, memory_length 2000, epsilon 0.3340448333253976\n",
      "state terminated\n",
      "episode 3656, reward 317.0, memory_length 2000, epsilon 0.33394463790546436\n",
      "state terminated\n",
      "episode 3657, reward -37.0, memory_length 2000, epsilon 0.3338444725396488\n",
      "state terminated\n",
      "episode 3658, reward 110.0, memory_length 2000, epsilon 0.33374433721893604\n",
      "state terminated\n",
      "episode 3659, reward 113.0, memory_length 2000, epsilon 0.33364423193431386\n",
      "state terminated\n",
      "episode 3660, reward 198.0, memory_length 2000, epsilon 0.3335441566767728\n",
      "state terminated\n",
      "episode 3661, reward 239.0, memory_length 2000, epsilon 0.333444111437306\n",
      "state terminated\n",
      "episode 3662, reward -132.0, memory_length 2000, epsilon 0.33334409620690947\n",
      "state terminated\n",
      "episode 3663, reward 75.0, memory_length 2000, epsilon 0.3332441109765818\n",
      "state terminated\n",
      "episode 3664, reward 234.0, memory_length 2000, epsilon 0.33314415573732437\n",
      "state terminated\n",
      "episode 3665, reward -126.0, memory_length 2000, epsilon 0.3330442304801412\n",
      "state terminated\n",
      "episode 3666, reward -92.0, memory_length 2000, epsilon 0.33294433519603905\n",
      "state terminated\n",
      "episode 3667, reward 349.0, memory_length 2000, epsilon 0.3328444698760272\n",
      "state terminated\n",
      "episode 3668, reward 125.0, memory_length 2000, epsilon 0.3327446345111179\n",
      "state terminated\n",
      "episode 3669, reward 38.0, memory_length 2000, epsilon 0.3326448290923259\n",
      "state terminated\n",
      "episode 3670, reward 294.0, memory_length 2000, epsilon 0.3325450536106688\n",
      "state terminated\n",
      "episode 3671, reward 188.0, memory_length 2000, epsilon 0.33244530805716666\n",
      "state terminated\n",
      "episode 3672, reward 66.0, memory_length 2000, epsilon 0.33234559242284256\n",
      "state terminated\n",
      "episode 3673, reward 31.0, memory_length 2000, epsilon 0.332245906698722\n",
      "state terminated\n",
      "episode 3674, reward 62.0, memory_length 2000, epsilon 0.33214625087583327\n",
      "state terminated\n",
      "episode 3675, reward -35.0, memory_length 2000, epsilon 0.33204662494520726\n",
      "state terminated\n",
      "episode 3676, reward 271.0, memory_length 2000, epsilon 0.33194702889787775\n",
      "state terminated\n",
      "episode 3677, reward 134.0, memory_length 2000, epsilon 0.3318474627248811\n",
      "state terminated\n",
      "episode 3678, reward 307.0, memory_length 2000, epsilon 0.33174792641725626\n",
      "state terminated\n",
      "episode 3679, reward 123.0, memory_length 2000, epsilon 0.33164841996604505\n",
      "state terminated\n",
      "episode 3680, reward 82.0, memory_length 2000, epsilon 0.3315489433622919\n",
      "state terminated\n",
      "episode 3681, reward -521.0, memory_length 2000, epsilon 0.33144949659704387\n",
      "state terminated\n",
      "episode 3682, reward 72.0, memory_length 2000, epsilon 0.33135007966135077\n",
      "state terminated\n",
      "episode 3683, reward 249.0, memory_length 2000, epsilon 0.33125069254626494\n",
      "state terminated\n",
      "episode 3684, reward 182.0, memory_length 2000, epsilon 0.3311513352428418\n",
      "state terminated\n",
      "episode 3685, reward 154.0, memory_length 2000, epsilon 0.33105200774213905\n",
      "state terminated\n",
      "episode 3686, reward -86.0, memory_length 2000, epsilon 0.33095271003521715\n",
      "state terminated\n",
      "episode 3687, reward 298.0, memory_length 2000, epsilon 0.33085344211313944\n",
      "state terminated\n",
      "episode 3688, reward -45.0, memory_length 2000, epsilon 0.3307542039669717\n",
      "state terminated\n",
      "episode 3689, reward 177.0, memory_length 2000, epsilon 0.33065499558778255\n",
      "state terminated\n",
      "episode 3690, reward 89.0, memory_length 2000, epsilon 0.33055581696664316\n",
      "state terminated\n",
      "episode 3691, reward 71.0, memory_length 2000, epsilon 0.33045666809462765\n",
      "state terminated\n",
      "episode 3692, reward 292.0, memory_length 2000, epsilon 0.33035754896281244\n",
      "state terminated\n",
      "episode 3693, reward 2.0, memory_length 2000, epsilon 0.33025845956227684\n",
      "state terminated\n",
      "episode 3694, reward 323.0, memory_length 2000, epsilon 0.3301593998841028\n",
      "state terminated\n",
      "episode 3695, reward -113.0, memory_length 2000, epsilon 0.33006036991937504\n",
      "state terminated\n",
      "episode 3696, reward -2.0, memory_length 2000, epsilon 0.3299613696591807\n",
      "state terminated\n",
      "episode 3697, reward 71.0, memory_length 2000, epsilon 0.3298623990946099\n",
      "state terminated\n",
      "episode 3698, reward 156.0, memory_length 2000, epsilon 0.32976345821675523\n",
      "state terminated\n",
      "episode 3699, reward 176.0, memory_length 2000, epsilon 0.3296645470167121\n",
      "state terminated\n",
      "episode 3700, reward 180.0, memory_length 2000, epsilon 0.32956566548557836\n",
      "state terminated\n",
      "episode 3701, reward 256.0, memory_length 2000, epsilon 0.3294668136144548\n",
      "state terminated\n",
      "episode 3702, reward 205.0, memory_length 2000, epsilon 0.3293679913944446\n",
      "state terminated\n",
      "episode 3703, reward 100.0, memory_length 2000, epsilon 0.32926919881665384\n",
      "state terminated\n",
      "episode 3704, reward -29.0, memory_length 2000, epsilon 0.32917043587219125\n",
      "state terminated\n",
      "episode 3705, reward 152.0, memory_length 2000, epsilon 0.3290717025521681\n",
      "state terminated\n",
      "episode 3706, reward 164.0, memory_length 2000, epsilon 0.3289729988476984\n",
      "state terminated\n",
      "episode 3707, reward 354.0, memory_length 2000, epsilon 0.3288743247498988\n",
      "state terminated\n",
      "episode 3708, reward 151.0, memory_length 2000, epsilon 0.3287756802498887\n",
      "state terminated\n",
      "episode 3709, reward 261.0, memory_length 2000, epsilon 0.32867706533879004\n",
      "state terminated\n",
      "episode 3710, reward 15.0, memory_length 2000, epsilon 0.3285784800077274\n",
      "state terminated\n",
      "episode 3711, reward 387.0, memory_length 2000, epsilon 0.32847992424782824\n",
      "state terminated\n",
      "episode 3712, reward 63.0, memory_length 2000, epsilon 0.3283813980502225\n",
      "state terminated\n",
      "episode 3713, reward 165.0, memory_length 2000, epsilon 0.32828290140604277\n",
      "state terminated\n",
      "episode 3714, reward -28.0, memory_length 2000, epsilon 0.3281844343064244\n",
      "state terminated\n",
      "episode 3715, reward -259.0, memory_length 2000, epsilon 0.3280859967425054\n",
      "state terminated\n",
      "episode 3716, reward -6.0, memory_length 2000, epsilon 0.32798758870542616\n",
      "state terminated\n",
      "episode 3717, reward -91.0, memory_length 2000, epsilon 0.32788921018633027\n",
      "state terminated\n",
      "episode 3718, reward 110.0, memory_length 2000, epsilon 0.3277908611763635\n",
      "state terminated\n",
      "episode 3719, reward 99.0, memory_length 2000, epsilon 0.32769254166667444\n",
      "state terminated\n",
      "episode 3720, reward -63.0, memory_length 2000, epsilon 0.3275942516484144\n",
      "state terminated\n",
      "episode 3721, reward -167.0, memory_length 2000, epsilon 0.32749599111273714\n",
      "state terminated\n",
      "episode 3722, reward 116.0, memory_length 2000, epsilon 0.32739776005079935\n",
      "state terminated\n",
      "episode 3723, reward 216.0, memory_length 2000, epsilon 0.32729955845376013\n",
      "state terminated\n",
      "episode 3724, reward 58.0, memory_length 2000, epsilon 0.32720138631278145\n",
      "state terminated\n",
      "episode 3725, reward 207.0, memory_length 2000, epsilon 0.32710324361902776\n",
      "state terminated\n",
      "episode 3726, reward 166.0, memory_length 2000, epsilon 0.32700513036366624\n",
      "state terminated\n",
      "episode 3727, reward 73.0, memory_length 2000, epsilon 0.3269070465378666\n",
      "state terminated\n",
      "episode 3728, reward -91.0, memory_length 2000, epsilon 0.32680899213280146\n",
      "state terminated\n",
      "episode 3729, reward -128.0, memory_length 2000, epsilon 0.32671096713964576\n",
      "state terminated\n",
      "episode 3730, reward 225.0, memory_length 2000, epsilon 0.3266129715495773\n",
      "state terminated\n",
      "episode 3731, reward 148.0, memory_length 2000, epsilon 0.32651500535377653\n",
      "state terminated\n",
      "episode 3732, reward 176.0, memory_length 2000, epsilon 0.3264170685434265\n",
      "state terminated\n",
      "episode 3733, reward 39.0, memory_length 2000, epsilon 0.3263191611097129\n",
      "state terminated\n",
      "episode 3734, reward 314.0, memory_length 2000, epsilon 0.3262212830438239\n",
      "state terminated\n",
      "episode 3735, reward 60.0, memory_length 2000, epsilon 0.3261234343369507\n",
      "state terminated\n",
      "episode 3736, reward -19.0, memory_length 2000, epsilon 0.32602561498028676\n",
      "state terminated\n",
      "episode 3737, reward 184.0, memory_length 2000, epsilon 0.3259278249650283\n",
      "state terminated\n",
      "episode 3738, reward -309.0, memory_length 2000, epsilon 0.3258300642823744\n",
      "state terminated\n",
      "episode 3739, reward 279.0, memory_length 2000, epsilon 0.32573233292352655\n",
      "state terminated\n",
      "episode 3740, reward 63.0, memory_length 2000, epsilon 0.32563463087968886\n",
      "state terminated\n",
      "episode 3741, reward 234.0, memory_length 2000, epsilon 0.3255369581420681\n",
      "state terminated\n",
      "episode 3742, reward 69.0, memory_length 2000, epsilon 0.32543931470187387\n",
      "state terminated\n",
      "episode 3743, reward 371.0, memory_length 2000, epsilon 0.3253417005503181\n",
      "state terminated\n",
      "episode 3744, reward 99.0, memory_length 2000, epsilon 0.32524411567861566\n",
      "state terminated\n",
      "episode 3745, reward 186.0, memory_length 2000, epsilon 0.3251465600779838\n",
      "state terminated\n",
      "episode 3746, reward -29.0, memory_length 2000, epsilon 0.32504903373964267\n",
      "state terminated\n",
      "episode 3747, reward 291.0, memory_length 2000, epsilon 0.32495153665481474\n",
      "state terminated\n",
      "episode 3748, reward -308.0, memory_length 2000, epsilon 0.32485406881472534\n",
      "state terminated\n",
      "episode 3749, reward 21.0, memory_length 2000, epsilon 0.3247566302106023\n",
      "state terminated\n",
      "episode 3750, reward 198.0, memory_length 2000, epsilon 0.32465922083367615\n",
      "state terminated\n",
      "episode 3751, reward 163.0, memory_length 2000, epsilon 0.32456184067518024\n",
      "state terminated\n",
      "episode 3752, reward 121.0, memory_length 2000, epsilon 0.3244644897263501\n",
      "state terminated\n",
      "episode 3753, reward -90.0, memory_length 2000, epsilon 0.32436716797842435\n",
      "state terminated\n",
      "episode 3754, reward 279.0, memory_length 2000, epsilon 0.3242698754226439\n",
      "state terminated\n",
      "episode 3755, reward -5.0, memory_length 2000, epsilon 0.32417261205025244\n",
      "state terminated\n",
      "episode 3756, reward 207.0, memory_length 2000, epsilon 0.3240753778524963\n",
      "state terminated\n",
      "episode 3757, reward 65.0, memory_length 2000, epsilon 0.32397817282062424\n",
      "state terminated\n",
      "episode 3758, reward 243.0, memory_length 2000, epsilon 0.3238809969458881\n",
      "state terminated\n",
      "episode 3759, reward 13.0, memory_length 2000, epsilon 0.3237838502195419\n",
      "state terminated\n",
      "episode 3760, reward 147.0, memory_length 2000, epsilon 0.3236867326328425\n",
      "state terminated\n",
      "episode 3761, reward -5.0, memory_length 2000, epsilon 0.32358964417704916\n",
      "state terminated\n",
      "episode 3762, reward 305.0, memory_length 2000, epsilon 0.3234925848434241\n",
      "state terminated\n",
      "episode 3763, reward 324.0, memory_length 2000, epsilon 0.3233955546232318\n",
      "state terminated\n",
      "episode 3764, reward -117.0, memory_length 2000, epsilon 0.32329855350773956\n",
      "state terminated\n",
      "episode 3765, reward 184.0, memory_length 2000, epsilon 0.3232015814882175\n",
      "state terminated\n",
      "episode 3766, reward 162.0, memory_length 2000, epsilon 0.32310463855593796\n",
      "state terminated\n",
      "episode 3767, reward -117.0, memory_length 2000, epsilon 0.3230077247021761\n",
      "state terminated\n",
      "episode 3768, reward 117.0, memory_length 2000, epsilon 0.3229108399182097\n",
      "state terminated\n",
      "episode 3769, reward -250.0, memory_length 2000, epsilon 0.3228139841953191\n",
      "state terminated\n",
      "episode 3770, reward 424.0, memory_length 2000, epsilon 0.32271715752478725\n",
      "state terminated\n",
      "episode 3771, reward 369.0, memory_length 2000, epsilon 0.3226203598978998\n",
      "state terminated\n",
      "episode 3772, reward -89.0, memory_length 2000, epsilon 0.32252359130594505\n",
      "state terminated\n",
      "episode 3773, reward 372.0, memory_length 2000, epsilon 0.3224268517402136\n",
      "state terminated\n",
      "episode 3774, reward -204.0, memory_length 2000, epsilon 0.3223301411919991\n",
      "state terminated\n",
      "episode 3775, reward 7.0, memory_length 2000, epsilon 0.32223345965259753\n",
      "state terminated\n",
      "episode 3776, reward 206.0, memory_length 2000, epsilon 0.3221368071133076\n",
      "state terminated\n",
      "episode 3777, reward 387.0, memory_length 2000, epsilon 0.3220401835654304\n",
      "state terminated\n",
      "episode 3778, reward 96.0, memory_length 2000, epsilon 0.32194358900027\n",
      "state terminated\n",
      "episode 3779, reward 489.0, memory_length 2000, epsilon 0.32184702340913285\n",
      "state terminated\n",
      "episode 3780, reward -100.0, memory_length 2000, epsilon 0.321750486783328\n",
      "state terminated\n",
      "episode 3781, reward 170.0, memory_length 2000, epsilon 0.3216539791141672\n",
      "state terminated\n",
      "episode 3782, reward 84.0, memory_length 2000, epsilon 0.32155750039296477\n",
      "state terminated\n",
      "episode 3783, reward 143.0, memory_length 2000, epsilon 0.3214610506110375\n",
      "state terminated\n",
      "episode 3784, reward 189.0, memory_length 2000, epsilon 0.32136462975970503\n",
      "state terminated\n",
      "episode 3785, reward 501.0, memory_length 2000, epsilon 0.32126823783028946\n",
      "state terminated\n",
      "episode 3786, reward -181.0, memory_length 2000, epsilon 0.3211718748141155\n",
      "state terminated\n",
      "episode 3787, reward -248.0, memory_length 2000, epsilon 0.32107554070251054\n",
      "state terminated\n",
      "episode 3788, reward 298.0, memory_length 2000, epsilon 0.32097923548680446\n",
      "state terminated\n",
      "episode 3789, reward -75.0, memory_length 2000, epsilon 0.32088295915832976\n",
      "state terminated\n",
      "episode 3790, reward 130.0, memory_length 2000, epsilon 0.32078671170842155\n",
      "state terminated\n",
      "episode 3791, reward 304.0, memory_length 2000, epsilon 0.3206904931284177\n",
      "state terminated\n",
      "episode 3792, reward 42.0, memory_length 2000, epsilon 0.3205943034096584\n",
      "state terminated\n",
      "episode 3793, reward 127.0, memory_length 2000, epsilon 0.32049814254348663\n",
      "state terminated\n",
      "episode 3794, reward 6.0, memory_length 2000, epsilon 0.32040201052124795\n",
      "state terminated\n",
      "episode 3795, reward 124.0, memory_length 2000, epsilon 0.3203059073342904\n",
      "state terminated\n",
      "episode 3796, reward 98.0, memory_length 2000, epsilon 0.3202098329739647\n",
      "state terminated\n",
      "episode 3797, reward -127.0, memory_length 2000, epsilon 0.32011378743162416\n",
      "state terminated\n",
      "episode 3798, reward 297.0, memory_length 2000, epsilon 0.32001777069862475\n",
      "state terminated\n",
      "episode 3799, reward -89.0, memory_length 2000, epsilon 0.31992178276632494\n",
      "state terminated\n",
      "episode 3800, reward 162.0, memory_length 2000, epsilon 0.3198258236260858\n",
      "state terminated\n",
      "episode 3801, reward 228.0, memory_length 2000, epsilon 0.319729893269271\n",
      "state terminated\n",
      "episode 3802, reward 166.0, memory_length 2000, epsilon 0.31963399168724677\n",
      "state terminated\n",
      "episode 3803, reward 145.0, memory_length 2000, epsilon 0.319538118871382\n",
      "state terminated\n",
      "episode 3804, reward -218.0, memory_length 2000, epsilon 0.31944227481304815\n",
      "state terminated\n",
      "episode 3805, reward 101.0, memory_length 2000, epsilon 0.31934645950361923\n",
      "state terminated\n",
      "episode 3806, reward 101.0, memory_length 2000, epsilon 0.31925067293447196\n",
      "state terminated\n",
      "episode 3807, reward -222.0, memory_length 2000, epsilon 0.31915491509698546\n",
      "state terminated\n",
      "episode 3808, reward -23.0, memory_length 2000, epsilon 0.31905918598254146\n",
      "state terminated\n",
      "episode 3809, reward 190.0, memory_length 2000, epsilon 0.31896348558252446\n",
      "state terminated\n",
      "episode 3810, reward -151.0, memory_length 2000, epsilon 0.3188678138883214\n",
      "state terminated\n",
      "episode 3811, reward 337.0, memory_length 2000, epsilon 0.3187721708913217\n",
      "state terminated\n",
      "episode 3812, reward 36.0, memory_length 2000, epsilon 0.3186765565829177\n",
      "state terminated\n",
      "episode 3813, reward -76.0, memory_length 2000, epsilon 0.318580970954504\n",
      "state terminated\n",
      "episode 3814, reward 236.0, memory_length 2000, epsilon 0.3184854139974779\n",
      "state terminated\n",
      "episode 3815, reward 194.0, memory_length 2000, epsilon 0.3183898857032393\n",
      "state terminated\n",
      "episode 3816, reward -135.0, memory_length 2000, epsilon 0.3182943860631905\n",
      "state terminated\n",
      "episode 3817, reward 0.0, memory_length 2000, epsilon 0.3181989150687367\n",
      "state terminated\n",
      "episode 3818, reward 309.0, memory_length 2000, epsilon 0.31810347271128553\n",
      "state terminated\n",
      "episode 3819, reward -29.0, memory_length 2000, epsilon 0.31800805898224715\n",
      "state terminated\n",
      "episode 3820, reward 182.0, memory_length 2000, epsilon 0.31791267387303423\n",
      "state terminated\n",
      "episode 3821, reward 143.0, memory_length 2000, epsilon 0.31781731737506225\n",
      "state terminated\n",
      "episode 3822, reward 240.0, memory_length 2000, epsilon 0.31772198947974895\n",
      "state terminated\n",
      "episode 3823, reward 75.0, memory_length 2000, epsilon 0.31762669017851497\n",
      "state terminated\n",
      "episode 3824, reward 206.0, memory_length 2000, epsilon 0.31753141946278324\n",
      "state terminated\n",
      "episode 3825, reward 145.0, memory_length 2000, epsilon 0.31743617732397955\n",
      "state terminated\n",
      "episode 3826, reward -13.0, memory_length 2000, epsilon 0.31734096375353205\n",
      "state terminated\n",
      "episode 3827, reward 40.0, memory_length 2000, epsilon 0.31724577874287146\n",
      "state terminated\n",
      "episode 3828, reward 112.0, memory_length 2000, epsilon 0.3171506222834312\n",
      "state terminated\n",
      "episode 3829, reward 9.0, memory_length 2000, epsilon 0.3170554943666472\n",
      "state terminated\n",
      "episode 3830, reward 107.0, memory_length 2000, epsilon 0.31696039498395784\n",
      "state terminated\n",
      "episode 3831, reward 283.0, memory_length 2000, epsilon 0.3168653241268042\n",
      "state terminated\n",
      "episode 3832, reward 180.0, memory_length 2000, epsilon 0.31677028178663\n",
      "state terminated\n",
      "episode 3833, reward 134.0, memory_length 2000, epsilon 0.31667526795488143\n",
      "state terminated\n",
      "episode 3834, reward 62.0, memory_length 2000, epsilon 0.31658028262300714\n",
      "state terminated\n",
      "episode 3835, reward 79.0, memory_length 2000, epsilon 0.3164853257824585\n",
      "state terminated\n",
      "episode 3836, reward -62.0, memory_length 2000, epsilon 0.3163903974246894\n",
      "state terminated\n",
      "episode 3837, reward 66.0, memory_length 2000, epsilon 0.3162954975411563\n",
      "state terminated\n",
      "episode 3838, reward -136.0, memory_length 2000, epsilon 0.3162006261233181\n",
      "state terminated\n",
      "episode 3839, reward 197.0, memory_length 2000, epsilon 0.3161057831626365\n",
      "state terminated\n",
      "episode 3840, reward 171.0, memory_length 2000, epsilon 0.31601096865057565\n",
      "state terminated\n",
      "episode 3841, reward 147.0, memory_length 2000, epsilon 0.3159161825786022\n",
      "state terminated\n",
      "episode 3842, reward -55.0, memory_length 2000, epsilon 0.3158214249381853\n",
      "state terminated\n",
      "episode 3843, reward -252.0, memory_length 2000, epsilon 0.315726695720797\n",
      "state terminated\n",
      "episode 3844, reward 107.0, memory_length 2000, epsilon 0.31563199491791133\n",
      "state terminated\n",
      "episode 3845, reward 75.0, memory_length 2000, epsilon 0.3155373225210056\n",
      "state terminated\n",
      "episode 3846, reward 48.0, memory_length 2000, epsilon 0.31544267852155905\n",
      "state terminated\n",
      "episode 3847, reward 281.0, memory_length 2000, epsilon 0.3153480629110538\n",
      "state terminated\n",
      "episode 3848, reward 166.0, memory_length 2000, epsilon 0.3152534756809744\n",
      "state terminated\n",
      "episode 3849, reward 243.0, memory_length 2000, epsilon 0.31515891682280806\n",
      "state terminated\n",
      "episode 3850, reward 15.0, memory_length 2000, epsilon 0.3150643863280444\n",
      "state terminated\n",
      "episode 3851, reward 362.0, memory_length 2000, epsilon 0.3149698841881757\n",
      "state terminated\n",
      "episode 3852, reward 183.0, memory_length 2000, epsilon 0.3148754103946968\n",
      "state terminated\n",
      "episode 3853, reward 157.0, memory_length 2000, epsilon 0.31478096493910507\n",
      "state terminated\n",
      "episode 3854, reward 157.0, memory_length 2000, epsilon 0.31468654781290045\n",
      "state terminated\n",
      "episode 3855, reward 67.0, memory_length 2000, epsilon 0.31459215900758525\n",
      "state terminated\n",
      "episode 3856, reward -115.0, memory_length 2000, epsilon 0.3144977985146647\n",
      "state terminated\n",
      "episode 3857, reward 49.0, memory_length 2000, epsilon 0.3144034663256461\n",
      "state terminated\n",
      "episode 3858, reward 178.0, memory_length 2000, epsilon 0.31430916243203966\n",
      "state terminated\n",
      "episode 3859, reward 67.0, memory_length 2000, epsilon 0.3142148868253581\n",
      "state terminated\n",
      "episode 3860, reward 244.0, memory_length 2000, epsilon 0.3141206394971166\n",
      "state terminated\n",
      "episode 3861, reward 116.0, memory_length 2000, epsilon 0.3140264204388329\n",
      "state terminated\n",
      "episode 3862, reward 273.0, memory_length 2000, epsilon 0.3139322296420272\n",
      "state terminated\n",
      "episode 3863, reward -1.0, memory_length 2000, epsilon 0.31383806709822243\n",
      "state terminated\n",
      "episode 3864, reward -42.0, memory_length 2000, epsilon 0.31374393279894375\n",
      "state terminated\n",
      "episode 3865, reward 234.0, memory_length 2000, epsilon 0.3136498267357194\n",
      "state terminated\n",
      "episode 3866, reward 30.0, memory_length 2000, epsilon 0.3135557489000796\n",
      "state terminated\n",
      "episode 3867, reward 240.0, memory_length 2000, epsilon 0.31346169928355744\n",
      "state terminated\n",
      "episode 3868, reward 33.0, memory_length 2000, epsilon 0.31336767787768843\n",
      "state terminated\n",
      "episode 3869, reward -43.0, memory_length 2000, epsilon 0.3132736846740106\n",
      "state terminated\n",
      "episode 3870, reward 154.0, memory_length 2000, epsilon 0.31317971966406466\n",
      "state terminated\n",
      "episode 3871, reward 112.0, memory_length 2000, epsilon 0.3130857828393936\n",
      "state terminated\n",
      "episode 3872, reward 98.0, memory_length 2000, epsilon 0.3129918741915433\n",
      "state terminated\n",
      "episode 3873, reward 159.0, memory_length 2000, epsilon 0.31289799371206184\n",
      "state terminated\n",
      "episode 3874, reward 360.0, memory_length 2000, epsilon 0.31280414139250007\n",
      "state terminated\n",
      "episode 3875, reward 138.0, memory_length 2000, epsilon 0.3127103172244113\n",
      "state terminated\n",
      "episode 3876, reward 171.0, memory_length 2000, epsilon 0.3126165211993511\n",
      "state terminated\n",
      "episode 3877, reward 259.0, memory_length 2000, epsilon 0.3125227533088782\n",
      "state terminated\n",
      "episode 3878, reward 594.0, memory_length 2000, epsilon 0.31242901354455316\n",
      "state terminated\n",
      "episode 3879, reward -162.0, memory_length 2000, epsilon 0.3123353018979397\n",
      "state terminated\n",
      "episode 3880, reward 282.0, memory_length 2000, epsilon 0.3122416183606035\n",
      "state terminated\n",
      "episode 3881, reward 39.0, memory_length 2000, epsilon 0.3121479629241132\n",
      "state terminated\n",
      "episode 3882, reward 50.0, memory_length 2000, epsilon 0.3120543355800398\n",
      "state terminated\n",
      "episode 3883, reward 80.0, memory_length 2000, epsilon 0.3119607363199568\n",
      "state terminated\n",
      "episode 3884, reward 157.0, memory_length 2000, epsilon 0.3118671651354403\n",
      "state terminated\n",
      "episode 3885, reward 72.0, memory_length 2000, epsilon 0.31177362201806874\n",
      "state terminated\n",
      "episode 3886, reward 274.0, memory_length 2000, epsilon 0.31168010695942355\n",
      "state terminated\n",
      "episode 3887, reward 71.0, memory_length 2000, epsilon 0.31158661995108816\n",
      "state terminated\n",
      "episode 3888, reward 130.0, memory_length 2000, epsilon 0.31149316098464874\n",
      "state terminated\n",
      "episode 3889, reward 87.0, memory_length 2000, epsilon 0.311399730051694\n",
      "state terminated\n",
      "episode 3890, reward -199.0, memory_length 2000, epsilon 0.31130632714381523\n",
      "state terminated\n",
      "episode 3891, reward 170.0, memory_length 2000, epsilon 0.311212952252606\n",
      "state terminated\n",
      "episode 3892, reward 232.0, memory_length 2000, epsilon 0.31111960536966277\n",
      "state terminated\n",
      "episode 3893, reward -213.0, memory_length 2000, epsilon 0.3110262864865842\n",
      "state terminated\n",
      "episode 3894, reward 149.0, memory_length 2000, epsilon 0.3109329955949717\n",
      "state terminated\n",
      "episode 3895, reward -41.0, memory_length 2000, epsilon 0.31083973268642895\n",
      "state terminated\n",
      "episode 3896, reward 256.0, memory_length 2000, epsilon 0.3107464977525624\n",
      "state terminated\n",
      "episode 3897, reward 72.0, memory_length 2000, epsilon 0.3106532907849808\n",
      "state terminated\n",
      "episode 3898, reward -29.0, memory_length 2000, epsilon 0.3105601117752955\n",
      "state terminated\n",
      "episode 3899, reward -9.0, memory_length 2000, epsilon 0.31046696071512064\n",
      "state terminated\n",
      "episode 3900, reward 292.0, memory_length 2000, epsilon 0.3103738375960724\n",
      "state terminated\n",
      "episode 3901, reward 89.0, memory_length 2000, epsilon 0.31028074240976977\n",
      "state terminated\n",
      "episode 3902, reward -70.0, memory_length 2000, epsilon 0.31018767514783413\n",
      "state terminated\n",
      "episode 3903, reward -19.0, memory_length 2000, epsilon 0.31009463580188945\n",
      "state terminated\n",
      "episode 3904, reward 233.0, memory_length 2000, epsilon 0.31000162436356227\n",
      "state terminated\n",
      "episode 3905, reward 362.0, memory_length 2000, epsilon 0.30990864082448133\n",
      "state terminated\n",
      "episode 3906, reward -86.0, memory_length 2000, epsilon 0.30981568517627844\n",
      "state terminated\n",
      "episode 3907, reward 0.0, memory_length 2000, epsilon 0.30972275741058736\n",
      "state terminated\n",
      "episode 3908, reward -83.0, memory_length 2000, epsilon 0.30962985751904465\n",
      "state terminated\n",
      "episode 3909, reward 205.0, memory_length 2000, epsilon 0.30953698549328934\n",
      "state terminated\n",
      "episode 3910, reward 467.0, memory_length 2000, epsilon 0.30944414132496295\n",
      "state terminated\n",
      "episode 3911, reward 206.0, memory_length 2000, epsilon 0.3093513250057095\n",
      "state terminated\n",
      "episode 3912, reward 117.0, memory_length 2000, epsilon 0.3092585365271754\n",
      "state terminated\n",
      "episode 3913, reward 153.0, memory_length 2000, epsilon 0.3091657758810099\n",
      "state terminated\n",
      "episode 3914, reward -19.0, memory_length 2000, epsilon 0.30907304305886446\n",
      "state terminated\n",
      "episode 3915, reward 175.0, memory_length 2000, epsilon 0.30898033805239306\n",
      "state terminated\n",
      "episode 3916, reward 393.0, memory_length 2000, epsilon 0.30888766085325225\n",
      "state terminated\n",
      "episode 3917, reward 143.0, memory_length 2000, epsilon 0.3087950114531012\n",
      "state terminated\n",
      "episode 3918, reward 21.0, memory_length 2000, epsilon 0.3087023898436013\n",
      "state terminated\n",
      "episode 3919, reward 179.0, memory_length 2000, epsilon 0.3086097960164168\n",
      "state terminated\n",
      "episode 3920, reward 8.0, memory_length 2000, epsilon 0.30851722996321407\n",
      "state terminated\n",
      "episode 3921, reward 7.0, memory_length 2000, epsilon 0.30842469167566233\n",
      "state terminated\n",
      "episode 3922, reward -154.0, memory_length 2000, epsilon 0.308332181145433\n",
      "state terminated\n",
      "episode 3923, reward 400.0, memory_length 2000, epsilon 0.3082396983642002\n",
      "state terminated\n",
      "episode 3924, reward 197.0, memory_length 2000, epsilon 0.30814724332364046\n",
      "state terminated\n",
      "episode 3925, reward -21.0, memory_length 2000, epsilon 0.3080548160154327\n",
      "state terminated\n",
      "episode 3926, reward -103.0, memory_length 2000, epsilon 0.30796241643125866\n",
      "state terminated\n",
      "episode 3927, reward 138.0, memory_length 2000, epsilon 0.30787004456280237\n",
      "state terminated\n",
      "episode 3928, reward -95.0, memory_length 2000, epsilon 0.3077777004017503\n",
      "state terminated\n",
      "episode 3929, reward 45.0, memory_length 2000, epsilon 0.3076853839397915\n",
      "state terminated\n",
      "episode 3930, reward 270.0, memory_length 2000, epsilon 0.3075930951686174\n",
      "state terminated\n",
      "episode 3931, reward 218.0, memory_length 2000, epsilon 0.30750083407992207\n",
      "state terminated\n",
      "episode 3932, reward 5.0, memory_length 2000, epsilon 0.30740860066540193\n",
      "state terminated\n",
      "episode 3933, reward 27.0, memory_length 2000, epsilon 0.30731639491675616\n",
      "state terminated\n",
      "episode 3934, reward -69.0, memory_length 2000, epsilon 0.3072242168256862\n",
      "state terminated\n",
      "episode 3935, reward -74.0, memory_length 2000, epsilon 0.3071320663838959\n",
      "state terminated\n",
      "episode 3936, reward -53.0, memory_length 2000, epsilon 0.3070399435830917\n",
      "state terminated\n",
      "episode 3937, reward 265.0, memory_length 2000, epsilon 0.3069478484149828\n",
      "state terminated\n",
      "episode 3938, reward 142.0, memory_length 2000, epsilon 0.3068557808712803\n",
      "state terminated\n",
      "episode 3939, reward 127.0, memory_length 2000, epsilon 0.30676374094369835\n",
      "state terminated\n",
      "episode 3940, reward 134.0, memory_length 2000, epsilon 0.3066717286239533\n",
      "state terminated\n",
      "episode 3941, reward -39.0, memory_length 2000, epsilon 0.306579743903764\n",
      "state terminated\n",
      "episode 3942, reward -160.0, memory_length 2000, epsilon 0.30648778677485194\n",
      "state terminated\n",
      "episode 3943, reward 93.0, memory_length 2000, epsilon 0.3063958572289408\n",
      "state terminated\n",
      "episode 3944, reward 126.0, memory_length 2000, epsilon 0.3063039552577571\n",
      "state terminated\n",
      "episode 3945, reward -109.0, memory_length 2000, epsilon 0.3062120808530295\n",
      "state terminated\n",
      "episode 3946, reward 273.0, memory_length 2000, epsilon 0.3061202340064894\n",
      "state terminated\n",
      "episode 3947, reward 20.0, memory_length 2000, epsilon 0.30602841470987063\n",
      "state terminated\n",
      "episode 3948, reward 54.0, memory_length 2000, epsilon 0.30593662295490937\n",
      "state terminated\n",
      "episode 3949, reward 416.0, memory_length 2000, epsilon 0.3058448587333444\n",
      "state terminated\n",
      "episode 3950, reward 36.0, memory_length 2000, epsilon 0.30575312203691685\n",
      "state terminated\n",
      "episode 3951, reward -169.0, memory_length 2000, epsilon 0.30566141285737053\n",
      "state terminated\n",
      "episode 3952, reward -75.0, memory_length 2000, epsilon 0.30556973118645153\n",
      "state terminated\n",
      "episode 3953, reward 305.0, memory_length 2000, epsilon 0.30547807701590857\n",
      "state terminated\n",
      "episode 3954, reward -183.0, memory_length 2000, epsilon 0.3053864503374928\n",
      "state terminated\n",
      "episode 3955, reward 147.0, memory_length 2000, epsilon 0.3052948511429577\n",
      "state terminated\n",
      "episode 3956, reward 9.0, memory_length 2000, epsilon 0.30520327942405945\n",
      "state terminated\n",
      "episode 3957, reward 250.0, memory_length 2000, epsilon 0.3051117351725566\n",
      "state terminated\n",
      "episode 3958, reward 418.0, memory_length 2000, epsilon 0.30502021838021004\n",
      "state terminated\n",
      "episode 3959, reward -32.0, memory_length 2000, epsilon 0.3049287290387833\n",
      "state terminated\n",
      "episode 3960, reward -165.0, memory_length 2000, epsilon 0.30483726714004244\n",
      "state terminated\n",
      "episode 3961, reward 186.0, memory_length 2000, epsilon 0.30474583267575583\n",
      "state terminated\n",
      "episode 3962, reward 175.0, memory_length 2000, epsilon 0.3046544256376944\n",
      "state terminated\n",
      "episode 3963, reward 139.0, memory_length 2000, epsilon 0.3045630460176314\n",
      "state terminated\n",
      "episode 3964, reward 125.0, memory_length 2000, epsilon 0.30447169380734285\n",
      "state terminated\n",
      "episode 3965, reward 88.0, memory_length 2000, epsilon 0.3043803689986069\n",
      "state terminated\n",
      "episode 3966, reward 202.0, memory_length 2000, epsilon 0.3042890715832043\n",
      "state terminated\n",
      "episode 3967, reward 219.0, memory_length 2000, epsilon 0.3041978015529184\n",
      "state terminated\n",
      "episode 3968, reward 319.0, memory_length 2000, epsilon 0.30410655889953486\n",
      "state terminated\n",
      "episode 3969, reward -112.0, memory_length 2000, epsilon 0.3040153436148419\n",
      "state terminated\n",
      "episode 3970, reward 69.0, memory_length 2000, epsilon 0.30392415569062997\n",
      "state terminated\n",
      "episode 3971, reward 231.0, memory_length 2000, epsilon 0.3038329951186923\n",
      "state terminated\n",
      "episode 3972, reward 27.0, memory_length 2000, epsilon 0.3037418618908243\n",
      "state terminated\n",
      "episode 3973, reward 49.0, memory_length 2000, epsilon 0.30365075599882413\n",
      "state terminated\n",
      "episode 3974, reward 387.0, memory_length 2000, epsilon 0.30355967743449225\n",
      "state terminated\n",
      "episode 3975, reward 138.0, memory_length 2000, epsilon 0.3034686261896315\n",
      "state terminated\n",
      "episode 3976, reward 450.0, memory_length 2000, epsilon 0.3033776022560473\n",
      "state terminated\n",
      "episode 3977, reward 262.0, memory_length 2000, epsilon 0.3032866056255476\n",
      "state terminated\n",
      "episode 3978, reward 28.0, memory_length 2000, epsilon 0.30319563628994256\n",
      "state terminated\n",
      "episode 3979, reward 102.0, memory_length 2000, epsilon 0.3031046942410449\n",
      "state terminated\n",
      "episode 3980, reward 337.0, memory_length 2000, epsilon 0.30301377947067004\n",
      "state terminated\n",
      "episode 3981, reward 151.0, memory_length 2000, epsilon 0.3029228919706355\n",
      "state terminated\n",
      "episode 3982, reward 319.0, memory_length 2000, epsilon 0.30283203173276146\n",
      "state terminated\n",
      "episode 3983, reward 234.0, memory_length 2000, epsilon 0.3027411987488705\n",
      "state terminated\n",
      "episode 3984, reward 434.0, memory_length 2000, epsilon 0.3026503930107876\n",
      "state terminated\n",
      "episode 3985, reward 273.0, memory_length 2000, epsilon 0.30255961451034025\n",
      "state terminated\n",
      "episode 3986, reward 433.0, memory_length 2000, epsilon 0.30246886323935834\n",
      "state terminated\n",
      "episode 3987, reward 198.0, memory_length 2000, epsilon 0.30237813918967443\n",
      "state terminated\n",
      "episode 3988, reward -209.0, memory_length 2000, epsilon 0.30228744235312327\n",
      "state terminated\n",
      "episode 3989, reward 229.0, memory_length 2000, epsilon 0.30219677272154216\n",
      "state terminated\n",
      "episode 3990, reward 134.0, memory_length 2000, epsilon 0.3021061302867707\n",
      "state terminated\n",
      "episode 3991, reward 442.0, memory_length 2000, epsilon 0.3020155150406512\n",
      "state terminated\n",
      "episode 3992, reward 98.0, memory_length 2000, epsilon 0.3019249269750282\n",
      "state terminated\n",
      "episode 3993, reward 154.0, memory_length 2000, epsilon 0.3018343660817489\n",
      "state terminated\n",
      "episode 3994, reward 146.0, memory_length 2000, epsilon 0.3017438323526628\n",
      "state terminated\n",
      "episode 3995, reward 135.0, memory_length 2000, epsilon 0.30165332577962173\n",
      "state terminated\n",
      "episode 3996, reward 133.0, memory_length 2000, epsilon 0.3015628463544802\n",
      "state terminated\n",
      "episode 3997, reward 119.0, memory_length 2000, epsilon 0.3014723940690951\n",
      "state terminated\n",
      "episode 3998, reward 196.0, memory_length 2000, epsilon 0.3013819689153256\n",
      "state terminated\n",
      "episode 3999, reward 175.0, memory_length 2000, epsilon 0.30129157088503344\n",
      "state terminated\n",
      "episode 4000, reward 396.0, memory_length 2000, epsilon 0.30120119997008304\n",
      "INFO:tensorflow:Assets written to: model.pkl/assets\n",
      "Total time taken  6888.174169540405\n",
      "state terminated\n",
      "episode 4001, reward 216.0, memory_length 2000, epsilon 0.30111085616234073\n",
      "state terminated\n",
      "episode 4002, reward 252.0, memory_length 2000, epsilon 0.30102053945367574\n",
      "state terminated\n",
      "episode 4003, reward -25.0, memory_length 2000, epsilon 0.30093024983595945\n",
      "state terminated\n",
      "episode 4004, reward 452.0, memory_length 2000, epsilon 0.30083998730106587\n",
      "state terminated\n",
      "episode 4005, reward 26.0, memory_length 2000, epsilon 0.3007497518408714\n",
      "state terminated\n",
      "episode 4006, reward 238.0, memory_length 2000, epsilon 0.30065954344725465\n",
      "state terminated\n",
      "episode 4007, reward 301.0, memory_length 2000, epsilon 0.3005693621120971\n",
      "state terminated\n",
      "episode 4008, reward 115.0, memory_length 2000, epsilon 0.3004792078272824\n",
      "state terminated\n",
      "episode 4009, reward 354.0, memory_length 2000, epsilon 0.30038908058469654\n",
      "state terminated\n",
      "episode 4010, reward 210.0, memory_length 2000, epsilon 0.30029898037622815\n",
      "state terminated\n",
      "episode 4011, reward 181.0, memory_length 2000, epsilon 0.30020890719376825\n",
      "state terminated\n",
      "episode 4012, reward 300.0, memory_length 2000, epsilon 0.3001188610292101\n",
      "state terminated\n",
      "episode 4013, reward 265.0, memory_length 2000, epsilon 0.30002884187444967\n",
      "state terminated\n",
      "episode 4014, reward 237.0, memory_length 2000, epsilon 0.29993884972138524\n",
      "state terminated\n",
      "episode 4015, reward -1.0, memory_length 2000, epsilon 0.2998488845619175\n",
      "state terminated\n",
      "episode 4016, reward -51.0, memory_length 2000, epsilon 0.2997589463879496\n",
      "state terminated\n",
      "episode 4017, reward 88.0, memory_length 2000, epsilon 0.299669035191387\n",
      "state terminated\n",
      "episode 4018, reward -282.0, memory_length 2000, epsilon 0.29957915096413784\n",
      "state terminated\n",
      "episode 4019, reward 125.0, memory_length 2000, epsilon 0.2994892936981124\n",
      "state terminated\n",
      "episode 4020, reward 212.0, memory_length 2000, epsilon 0.2993994633852236\n",
      "state terminated\n",
      "episode 4021, reward -32.0, memory_length 2000, epsilon 0.29930966001738674\n",
      "state terminated\n",
      "episode 4022, reward 575.0, memory_length 2000, epsilon 0.29921988358651946\n",
      "state terminated\n",
      "episode 4023, reward -47.0, memory_length 2000, epsilon 0.299130134084542\n",
      "state terminated\n",
      "episode 4024, reward 299.0, memory_length 2000, epsilon 0.29904041150337674\n",
      "state terminated\n",
      "episode 4025, reward -127.0, memory_length 2000, epsilon 0.2989507158349487\n",
      "state terminated\n",
      "episode 4026, reward 36.0, memory_length 2000, epsilon 0.29886104707118527\n",
      "state terminated\n",
      "episode 4027, reward -125.0, memory_length 2000, epsilon 0.29877140520401624\n",
      "state terminated\n",
      "episode 4028, reward 36.0, memory_length 2000, epsilon 0.298681790225374\n",
      "state terminated\n",
      "episode 4029, reward 238.0, memory_length 2000, epsilon 0.298592202127193\n",
      "state terminated\n",
      "episode 4030, reward 48.0, memory_length 2000, epsilon 0.29850264090141043\n",
      "state terminated\n",
      "episode 4031, reward 90.0, memory_length 2000, epsilon 0.2984131065399658\n",
      "state terminated\n",
      "episode 4032, reward 15.0, memory_length 2000, epsilon 0.2983235990348009\n",
      "state terminated\n",
      "episode 4033, reward 241.0, memory_length 2000, epsilon 0.29823411837786\n",
      "state terminated\n",
      "episode 4034, reward 357.0, memory_length 2000, epsilon 0.29814466456109007\n",
      "state terminated\n",
      "episode 4035, reward 121.0, memory_length 2000, epsilon 0.2980552375764402\n",
      "state terminated\n",
      "episode 4036, reward -19.0, memory_length 2000, epsilon 0.2979658374158618\n",
      "state terminated\n",
      "episode 4037, reward 70.0, memory_length 2000, epsilon 0.297876464071309\n",
      "state terminated\n",
      "episode 4038, reward 16.0, memory_length 2000, epsilon 0.2977871175347383\n",
      "state terminated\n",
      "episode 4039, reward -71.0, memory_length 2000, epsilon 0.2976977977981082\n",
      "state terminated\n",
      "episode 4040, reward 147.0, memory_length 2000, epsilon 0.2976085048533802\n",
      "state terminated\n",
      "episode 4041, reward 61.0, memory_length 2000, epsilon 0.2975192386925178\n",
      "state terminated\n",
      "episode 4042, reward 103.0, memory_length 2000, epsilon 0.29742999930748704\n",
      "state terminated\n",
      "episode 4043, reward -87.0, memory_length 2000, epsilon 0.29734078669025654\n",
      "state terminated\n",
      "episode 4044, reward 362.0, memory_length 2000, epsilon 0.29725160083279695\n",
      "state terminated\n",
      "episode 4045, reward 33.0, memory_length 2000, epsilon 0.29716244172708167\n",
      "state terminated\n",
      "episode 4046, reward 360.0, memory_length 2000, epsilon 0.2970733093650863\n",
      "state terminated\n",
      "episode 4047, reward 166.0, memory_length 2000, epsilon 0.29698420373878903\n",
      "state terminated\n",
      "episode 4048, reward 181.0, memory_length 2000, epsilon 0.2968951248401703\n",
      "state terminated\n",
      "episode 4049, reward 459.0, memory_length 2000, epsilon 0.296806072661213\n",
      "state terminated\n",
      "episode 4050, reward 33.0, memory_length 2000, epsilon 0.2967170471939024\n",
      "state terminated\n",
      "episode 4051, reward -90.0, memory_length 2000, epsilon 0.2966280484302263\n",
      "state terminated\n",
      "episode 4052, reward 200.0, memory_length 2000, epsilon 0.29653907636217475\n",
      "state terminated\n",
      "episode 4053, reward 56.0, memory_length 2000, epsilon 0.2964501309817402\n",
      "state terminated\n",
      "episode 4054, reward 306.0, memory_length 2000, epsilon 0.29636121228091766\n",
      "state terminated\n",
      "episode 4055, reward 224.0, memory_length 2000, epsilon 0.2962723202517045\n",
      "state terminated\n",
      "episode 4056, reward 397.0, memory_length 2000, epsilon 0.2961834548861003\n",
      "state terminated\n",
      "episode 4057, reward 426.0, memory_length 2000, epsilon 0.2960946161761073\n",
      "state terminated\n",
      "episode 4058, reward 157.0, memory_length 2000, epsilon 0.2960058041137299\n",
      "state terminated\n",
      "episode 4059, reward 300.0, memory_length 2000, epsilon 0.29591701869097514\n",
      "state terminated\n",
      "episode 4060, reward 188.0, memory_length 2000, epsilon 0.2958282598998521\n",
      "state terminated\n",
      "episode 4061, reward 9.0, memory_length 2000, epsilon 0.2957395277323728\n",
      "state terminated\n",
      "episode 4062, reward 291.0, memory_length 2000, epsilon 0.2956508221805511\n",
      "state terminated\n",
      "episode 4063, reward 305.0, memory_length 2000, epsilon 0.29556214323640373\n",
      "state terminated\n",
      "episode 4064, reward -50.0, memory_length 2000, epsilon 0.29547349089194935\n",
      "state terminated\n",
      "episode 4065, reward 108.0, memory_length 2000, epsilon 0.2953848651392094\n",
      "state terminated\n",
      "episode 4066, reward 143.0, memory_length 2000, epsilon 0.2952962659702074\n",
      "state terminated\n",
      "episode 4067, reward 43.0, memory_length 2000, epsilon 0.2952076933769696\n",
      "state terminated\n",
      "episode 4068, reward 44.0, memory_length 2000, epsilon 0.2951191473515245\n",
      "state terminated\n",
      "episode 4069, reward 132.0, memory_length 2000, epsilon 0.29503062788590273\n",
      "state terminated\n",
      "episode 4070, reward 10.0, memory_length 2000, epsilon 0.2949421349721378\n",
      "state terminated\n",
      "episode 4071, reward -23.0, memory_length 2000, epsilon 0.29485366860226514\n",
      "state terminated\n",
      "episode 4072, reward 222.0, memory_length 2000, epsilon 0.29476522876832284\n",
      "state terminated\n",
      "episode 4073, reward 33.0, memory_length 2000, epsilon 0.2946768154623513\n",
      "state terminated\n",
      "episode 4074, reward 262.0, memory_length 2000, epsilon 0.2945884286763934\n",
      "state terminated\n",
      "episode 4075, reward 76.0, memory_length 2000, epsilon 0.29450006840249426\n",
      "state terminated\n",
      "episode 4076, reward 9.0, memory_length 2000, epsilon 0.2944117346327015\n",
      "state terminated\n",
      "episode 4077, reward 363.0, memory_length 2000, epsilon 0.294323427359065\n",
      "state terminated\n",
      "episode 4078, reward 172.0, memory_length 2000, epsilon 0.29423514657363725\n",
      "state terminated\n",
      "episode 4079, reward 32.0, memory_length 2000, epsilon 0.29414689226847285\n",
      "state terminated\n",
      "episode 4080, reward 288.0, memory_length 2000, epsilon 0.2940586644356289\n",
      "state terminated\n",
      "episode 4081, reward 158.0, memory_length 2000, epsilon 0.293970463067165\n",
      "state terminated\n",
      "episode 4082, reward -1.0, memory_length 2000, epsilon 0.29388228815514295\n",
      "state terminated\n",
      "episode 4083, reward -40.0, memory_length 2000, epsilon 0.2937941396916271\n",
      "state terminated\n",
      "episode 4084, reward 24.0, memory_length 2000, epsilon 0.2937060176686839\n",
      "state terminated\n",
      "episode 4085, reward 254.0, memory_length 2000, epsilon 0.2936179220783826\n",
      "state terminated\n",
      "episode 4086, reward 43.0, memory_length 2000, epsilon 0.2935298529127944\n",
      "state terminated\n",
      "episode 4087, reward 171.0, memory_length 2000, epsilon 0.29344181016399323\n",
      "state terminated\n",
      "episode 4088, reward -382.0, memory_length 2000, epsilon 0.29335379382405513\n",
      "state terminated\n",
      "episode 4089, reward 99.0, memory_length 2000, epsilon 0.2932658038850587\n",
      "state terminated\n",
      "episode 4090, reward 361.0, memory_length 2000, epsilon 0.2931778403390848\n",
      "state terminated\n",
      "episode 4091, reward 93.0, memory_length 2000, epsilon 0.29308990317821676\n",
      "state terminated\n",
      "episode 4092, reward -28.0, memory_length 2000, epsilon 0.2930019923945402\n",
      "state terminated\n",
      "episode 4093, reward 376.0, memory_length 2000, epsilon 0.29291410798014306\n",
      "state terminated\n",
      "episode 4094, reward 268.0, memory_length 2000, epsilon 0.2928262499271159\n",
      "state terminated\n",
      "episode 4095, reward -16.0, memory_length 2000, epsilon 0.2927384182275514\n",
      "state terminated\n",
      "episode 4096, reward 197.0, memory_length 2000, epsilon 0.2926506128735449\n",
      "state terminated\n",
      "episode 4097, reward -42.0, memory_length 2000, epsilon 0.2925628338571936\n",
      "state terminated\n",
      "episode 4098, reward 130.0, memory_length 2000, epsilon 0.2924750811705976\n",
      "state terminated\n",
      "episode 4099, reward 241.0, memory_length 2000, epsilon 0.2923873548058591\n",
      "state terminated\n",
      "episode 4100, reward 104.0, memory_length 2000, epsilon 0.2922996547550826\n",
      "state terminated\n",
      "episode 4101, reward -86.0, memory_length 2000, epsilon 0.2922119810103754\n",
      "state terminated\n",
      "episode 4102, reward 172.0, memory_length 2000, epsilon 0.2921243335638466\n",
      "state terminated\n",
      "episode 4103, reward -44.0, memory_length 2000, epsilon 0.29203671240760803\n",
      "state terminated\n",
      "episode 4104, reward 120.0, memory_length 2000, epsilon 0.29194911753377384\n",
      "state terminated\n",
      "episode 4105, reward 209.0, memory_length 2000, epsilon 0.29186154893446037\n",
      "state terminated\n",
      "episode 4106, reward 138.0, memory_length 2000, epsilon 0.2917740066017865\n",
      "state terminated\n",
      "episode 4107, reward 274.0, memory_length 2000, epsilon 0.2916864905278733\n",
      "state terminated\n",
      "episode 4108, reward -99.0, memory_length 2000, epsilon 0.2915990007048446\n",
      "state terminated\n",
      "episode 4109, reward 261.0, memory_length 2000, epsilon 0.2915115371248262\n",
      "state terminated\n",
      "episode 4110, reward 172.0, memory_length 2000, epsilon 0.29142409977994627\n",
      "state terminated\n",
      "episode 4111, reward 129.0, memory_length 2000, epsilon 0.2913366886623355\n",
      "state terminated\n",
      "episode 4112, reward 41.0, memory_length 2000, epsilon 0.29124930376412694\n",
      "state terminated\n",
      "episode 4113, reward -85.0, memory_length 2000, epsilon 0.2911619450774558\n",
      "state terminated\n",
      "episode 4114, reward 115.0, memory_length 2000, epsilon 0.29107461259446005\n",
      "state terminated\n",
      "episode 4115, reward -105.0, memory_length 2000, epsilon 0.2909873063072796\n",
      "state terminated\n",
      "episode 4116, reward 267.0, memory_length 2000, epsilon 0.2909000262080569\n",
      "state terminated\n",
      "episode 4117, reward -320.0, memory_length 2000, epsilon 0.29081277228893676\n",
      "state terminated\n",
      "episode 4118, reward 269.0, memory_length 2000, epsilon 0.29072554454206634\n",
      "state terminated\n",
      "episode 4119, reward 243.0, memory_length 2000, epsilon 0.29063834295959506\n",
      "state terminated\n",
      "episode 4120, reward 166.0, memory_length 2000, epsilon 0.2905511675336749\n",
      "state terminated\n",
      "episode 4121, reward -43.0, memory_length 2000, epsilon 0.29046401825645995\n",
      "state terminated\n",
      "episode 4122, reward -100.0, memory_length 2000, epsilon 0.29037689512010695\n",
      "state terminated\n",
      "episode 4123, reward 21.0, memory_length 2000, epsilon 0.29028979811677463\n",
      "state terminated\n",
      "episode 4124, reward 331.0, memory_length 2000, epsilon 0.29020272723862434\n",
      "state terminated\n",
      "episode 4125, reward -22.0, memory_length 2000, epsilon 0.29011568247781977\n",
      "state terminated\n",
      "episode 4126, reward 417.0, memory_length 2000, epsilon 0.2900286638265267\n",
      "state terminated\n",
      "episode 4127, reward 124.0, memory_length 2000, epsilon 0.2899416712769136\n",
      "state terminated\n",
      "episode 4128, reward 112.0, memory_length 2000, epsilon 0.28985470482115117\n",
      "state terminated\n",
      "episode 4129, reward 208.0, memory_length 2000, epsilon 0.28976776445141234\n",
      "state terminated\n",
      "episode 4130, reward 126.0, memory_length 2000, epsilon 0.2896808501598725\n",
      "state terminated\n",
      "episode 4131, reward 89.0, memory_length 2000, epsilon 0.2895939619387094\n",
      "state terminated\n",
      "episode 4132, reward 30.0, memory_length 2000, epsilon 0.2895070997801031\n",
      "state terminated\n",
      "episode 4133, reward -101.0, memory_length 2000, epsilon 0.2894202636762358\n",
      "state terminated\n",
      "episode 4134, reward 288.0, memory_length 2000, epsilon 0.2893334536192926\n",
      "state terminated\n",
      "episode 4135, reward 405.0, memory_length 2000, epsilon 0.28924666960146034\n",
      "state terminated\n",
      "episode 4136, reward 397.0, memory_length 2000, epsilon 0.2891599116149286\n",
      "state terminated\n",
      "episode 4137, reward 261.0, memory_length 2000, epsilon 0.28907317965188906\n",
      "state terminated\n",
      "episode 4138, reward 250.0, memory_length 2000, epsilon 0.2889864737045359\n",
      "state terminated\n",
      "episode 4139, reward 34.0, memory_length 2000, epsilon 0.2888997937650655\n",
      "state terminated\n",
      "episode 4140, reward 38.0, memory_length 2000, epsilon 0.2888131398256768\n",
      "state terminated\n",
      "episode 4141, reward 225.0, memory_length 2000, epsilon 0.2887265118785709\n",
      "state terminated\n",
      "episode 4142, reward 169.0, memory_length 2000, epsilon 0.28863990991595123\n",
      "state terminated\n",
      "episode 4143, reward -200.0, memory_length 2000, epsilon 0.2885533339300237\n",
      "state terminated\n",
      "episode 4144, reward 108.0, memory_length 2000, epsilon 0.28846678391299635\n",
      "state terminated\n",
      "episode 4145, reward 60.0, memory_length 2000, epsilon 0.28838025985707977\n",
      "state terminated\n",
      "episode 4146, reward 323.0, memory_length 2000, epsilon 0.2882937617544868\n",
      "state terminated\n",
      "episode 4147, reward 165.0, memory_length 2000, epsilon 0.28820728959743247\n",
      "state terminated\n",
      "episode 4148, reward 192.0, memory_length 2000, epsilon 0.28812084337813454\n",
      "state terminated\n",
      "episode 4149, reward 324.0, memory_length 2000, epsilon 0.28803442308881266\n",
      "state terminated\n",
      "episode 4150, reward 102.0, memory_length 2000, epsilon 0.287948028721689\n",
      "state terminated\n",
      "episode 4151, reward 100.0, memory_length 2000, epsilon 0.2878616602689882\n",
      "state terminated\n",
      "episode 4152, reward 242.0, memory_length 2000, epsilon 0.28777531772293696\n",
      "state terminated\n",
      "episode 4153, reward 4.0, memory_length 2000, epsilon 0.28768900107576456\n",
      "state terminated\n",
      "episode 4154, reward 12.0, memory_length 2000, epsilon 0.28760271031970236\n",
      "state terminated\n",
      "episode 4155, reward 290.0, memory_length 2000, epsilon 0.28751644544698435\n",
      "state terminated\n",
      "episode 4156, reward 39.0, memory_length 2000, epsilon 0.2874302064498466\n",
      "state terminated\n",
      "episode 4157, reward 117.0, memory_length 2000, epsilon 0.2873439933205277\n",
      "state terminated\n",
      "episode 4158, reward 279.0, memory_length 2000, epsilon 0.2872578060512683\n",
      "state terminated\n",
      "episode 4159, reward -64.0, memory_length 2000, epsilon 0.2871716446343117\n",
      "state terminated\n",
      "episode 4160, reward -123.0, memory_length 2000, epsilon 0.2870855090619032\n",
      "state terminated\n",
      "episode 4161, reward -270.0, memory_length 2000, epsilon 0.2869993993262908\n",
      "state terminated\n",
      "episode 4162, reward 188.0, memory_length 2000, epsilon 0.28691331541972454\n",
      "state terminated\n",
      "episode 4163, reward 363.0, memory_length 2000, epsilon 0.2868272573344569\n",
      "state terminated\n",
      "episode 4164, reward 297.0, memory_length 2000, epsilon 0.2867412250627426\n",
      "state terminated\n",
      "episode 4165, reward 359.0, memory_length 2000, epsilon 0.28665521859683873\n",
      "state terminated\n",
      "episode 4166, reward 278.0, memory_length 2000, epsilon 0.2865692379290047\n",
      "state terminated\n",
      "episode 4167, reward 285.0, memory_length 2000, epsilon 0.2864832830515022\n",
      "state terminated\n",
      "episode 4168, reward 400.0, memory_length 2000, epsilon 0.2863973539565955\n",
      "state terminated\n",
      "episode 4169, reward 4.0, memory_length 2000, epsilon 0.2863114506365508\n",
      "state terminated\n",
      "episode 4170, reward 120.0, memory_length 2000, epsilon 0.28622557308363683\n",
      "state terminated\n",
      "episode 4171, reward 297.0, memory_length 2000, epsilon 0.28613972129012466\n",
      "state terminated\n",
      "episode 4172, reward 411.0, memory_length 2000, epsilon 0.2860538952482876\n",
      "state terminated\n",
      "episode 4173, reward 67.0, memory_length 2000, epsilon 0.2859680949504013\n",
      "state terminated\n",
      "episode 4174, reward 378.0, memory_length 2000, epsilon 0.2858823203887437\n",
      "state terminated\n",
      "episode 4175, reward 332.0, memory_length 2000, epsilon 0.2857965715555952\n",
      "state terminated\n",
      "episode 4176, reward 60.0, memory_length 2000, epsilon 0.2857108484432383\n",
      "state terminated\n",
      "episode 4177, reward 76.0, memory_length 2000, epsilon 0.28562515104395797\n",
      "state terminated\n",
      "episode 4178, reward -36.0, memory_length 2000, epsilon 0.2855394793500414\n",
      "state terminated\n",
      "episode 4179, reward 81.0, memory_length 2000, epsilon 0.28545383335377816\n",
      "state terminated\n",
      "episode 4180, reward -9.0, memory_length 2000, epsilon 0.2853682130474602\n",
      "state terminated\n",
      "episode 4181, reward -40.0, memory_length 2000, epsilon 0.28528261842338143\n",
      "state terminated\n",
      "episode 4182, reward 45.0, memory_length 2000, epsilon 0.2851970494738386\n",
      "state terminated\n",
      "episode 4183, reward -100.0, memory_length 2000, epsilon 0.28511150619113046\n",
      "state terminated\n",
      "episode 4184, reward -54.0, memory_length 2000, epsilon 0.28502598856755806\n",
      "state terminated\n",
      "episode 4185, reward 186.0, memory_length 2000, epsilon 0.2849404965954248\n",
      "state terminated\n",
      "episode 4186, reward -101.0, memory_length 2000, epsilon 0.28485503026703646\n",
      "state terminated\n",
      "episode 4187, reward -127.0, memory_length 2000, epsilon 0.28476958957470094\n",
      "state terminated\n",
      "episode 4188, reward -51.0, memory_length 2000, epsilon 0.28468417451072875\n",
      "state terminated\n",
      "episode 4189, reward 105.0, memory_length 2000, epsilon 0.28459878506743247\n",
      "state terminated\n",
      "episode 4190, reward -45.0, memory_length 2000, epsilon 0.28451342123712703\n",
      "state terminated\n",
      "episode 4191, reward -328.0, memory_length 2000, epsilon 0.2844280830121297\n",
      "state terminated\n",
      "episode 4192, reward -123.0, memory_length 2000, epsilon 0.28434277038476\n",
      "state terminated\n",
      "episode 4193, reward -55.0, memory_length 2000, epsilon 0.28425748334733986\n",
      "state terminated\n",
      "episode 4194, reward -50.0, memory_length 2000, epsilon 0.2841722218921933\n",
      "state terminated\n",
      "episode 4195, reward 298.0, memory_length 2000, epsilon 0.28408698601164706\n",
      "state terminated\n",
      "episode 4196, reward -14.0, memory_length 2000, epsilon 0.2840017756980297\n",
      "state terminated\n",
      "episode 4197, reward 286.0, memory_length 2000, epsilon 0.2839165909436723\n",
      "state terminated\n",
      "episode 4198, reward 377.0, memory_length 2000, epsilon 0.2838314317409083\n",
      "state terminated\n",
      "episode 4199, reward 26.0, memory_length 2000, epsilon 0.2837462980820734\n",
      "state terminated\n",
      "episode 4200, reward 126.0, memory_length 2000, epsilon 0.28366118995950546\n",
      "state terminated\n",
      "episode 4201, reward 252.0, memory_length 2000, epsilon 0.2835761073655448\n",
      "state terminated\n",
      "episode 4202, reward 96.0, memory_length 2000, epsilon 0.283491050292534\n",
      "state terminated\n",
      "episode 4203, reward 80.0, memory_length 2000, epsilon 0.28340601873281795\n",
      "state terminated\n",
      "episode 4204, reward 216.0, memory_length 2000, epsilon 0.28332101267874377\n",
      "state terminated\n",
      "episode 4205, reward -183.0, memory_length 2000, epsilon 0.2832360321226609\n",
      "state terminated\n",
      "episode 4206, reward 152.0, memory_length 2000, epsilon 0.2831510770569211\n",
      "state terminated\n",
      "episode 4207, reward 186.0, memory_length 2000, epsilon 0.2830661474738784\n",
      "state terminated\n",
      "episode 4208, reward 180.0, memory_length 2000, epsilon 0.28298124336588926\n",
      "state terminated\n",
      "episode 4209, reward 250.0, memory_length 2000, epsilon 0.2828963647253122\n",
      "state terminated\n",
      "episode 4210, reward -63.0, memory_length 2000, epsilon 0.2828115115445081\n",
      "state terminated\n",
      "episode 4211, reward 224.0, memory_length 2000, epsilon 0.2827266838158403\n",
      "state terminated\n",
      "episode 4212, reward 508.0, memory_length 2000, epsilon 0.2826418815316742\n",
      "state terminated\n",
      "episode 4213, reward 208.0, memory_length 2000, epsilon 0.2825571046843776\n",
      "state terminated\n",
      "episode 4214, reward -46.0, memory_length 2000, epsilon 0.28247235326632064\n",
      "state terminated\n",
      "episode 4215, reward 208.0, memory_length 2000, epsilon 0.28238762726987565\n",
      "state terminated\n",
      "episode 4216, reward 225.0, memory_length 2000, epsilon 0.2823029266874173\n",
      "state terminated\n",
      "episode 4217, reward 235.0, memory_length 2000, epsilon 0.28221825151132257\n",
      "state terminated\n",
      "episode 4218, reward 237.0, memory_length 2000, epsilon 0.2821336017339707\n",
      "state terminated\n",
      "episode 4219, reward 270.0, memory_length 2000, epsilon 0.28204897734774304\n",
      "state terminated\n",
      "episode 4220, reward 577.0, memory_length 2000, epsilon 0.28196437834502364\n",
      "state terminated\n",
      "episode 4221, reward 102.0, memory_length 2000, epsilon 0.28187980471819846\n",
      "state terminated\n",
      "episode 4222, reward 341.0, memory_length 2000, epsilon 0.28179525645965586\n",
      "state terminated\n",
      "episode 4223, reward 35.0, memory_length 2000, epsilon 0.28171073356178655\n",
      "state terminated\n",
      "episode 4224, reward 99.0, memory_length 2000, epsilon 0.2816262360169835\n",
      "state terminated\n",
      "episode 4225, reward -36.0, memory_length 2000, epsilon 0.2815417638176419\n",
      "state terminated\n",
      "episode 4226, reward -1.0, memory_length 2000, epsilon 0.28145731695615916\n",
      "state terminated\n",
      "episode 4227, reward 207.0, memory_length 2000, epsilon 0.28137289542493515\n",
      "state terminated\n",
      "episode 4228, reward 296.0, memory_length 2000, epsilon 0.2812884992163719\n",
      "state terminated\n",
      "episode 4229, reward 72.0, memory_length 2000, epsilon 0.28120412832287384\n",
      "state terminated\n",
      "episode 4230, reward 264.0, memory_length 2000, epsilon 0.2811197827368474\n",
      "state terminated\n",
      "episode 4231, reward 96.0, memory_length 2000, epsilon 0.2810354624507017\n",
      "state terminated\n",
      "episode 4232, reward 81.0, memory_length 2000, epsilon 0.28095116745684784\n",
      "state terminated\n",
      "episode 4233, reward 234.0, memory_length 2000, epsilon 0.2808668977476992\n",
      "state terminated\n",
      "episode 4234, reward 70.0, memory_length 2000, epsilon 0.2807826533156714\n",
      "state terminated\n",
      "episode 4235, reward -93.0, memory_length 2000, epsilon 0.28069843415318274\n",
      "state terminated\n",
      "episode 4236, reward 25.0, memory_length 2000, epsilon 0.28061424025265336\n",
      "state terminated\n",
      "episode 4237, reward 196.0, memory_length 2000, epsilon 0.2805300716065057\n",
      "state terminated\n",
      "episode 4238, reward 211.0, memory_length 2000, epsilon 0.2804459282071648\n",
      "state terminated\n",
      "episode 4239, reward 308.0, memory_length 2000, epsilon 0.28036181004705757\n",
      "state terminated\n",
      "episode 4240, reward 165.0, memory_length 2000, epsilon 0.28027771711861343\n",
      "state terminated\n",
      "episode 4241, reward 238.0, memory_length 2000, epsilon 0.2801936494142639\n",
      "state terminated\n",
      "episode 4242, reward -6.0, memory_length 2000, epsilon 0.2801096069264431\n",
      "state terminated\n",
      "episode 4243, reward 23.0, memory_length 2000, epsilon 0.28002558964758717\n",
      "state terminated\n",
      "episode 4244, reward 296.0, memory_length 2000, epsilon 0.2799415975701345\n",
      "state terminated\n",
      "episode 4245, reward 57.0, memory_length 2000, epsilon 0.2798576306865257\n",
      "state terminated\n",
      "episode 4246, reward 45.0, memory_length 2000, epsilon 0.2797736889892039\n",
      "state terminated\n",
      "episode 4247, reward 332.0, memory_length 2000, epsilon 0.2796897724706144\n",
      "state terminated\n",
      "episode 4248, reward -42.0, memory_length 2000, epsilon 0.2796058811232044\n",
      "state terminated\n",
      "episode 4249, reward 192.0, memory_length 2000, epsilon 0.279522014939424\n",
      "state terminated\n",
      "episode 4250, reward 45.0, memory_length 2000, epsilon 0.27943817391172515\n",
      "state terminated\n",
      "episode 4251, reward 120.0, memory_length 2000, epsilon 0.27935435803256214\n",
      "state terminated\n",
      "episode 4252, reward 93.0, memory_length 2000, epsilon 0.27927056729439154\n",
      "state terminated\n",
      "episode 4253, reward 312.0, memory_length 2000, epsilon 0.2791868016896722\n",
      "state terminated\n",
      "episode 4254, reward 376.0, memory_length 2000, epsilon 0.27910306121086514\n",
      "state terminated\n",
      "episode 4255, reward 55.0, memory_length 2000, epsilon 0.27901934585043375\n",
      "state terminated\n",
      "episode 4256, reward -67.0, memory_length 2000, epsilon 0.27893565560084377\n",
      "state terminated\n",
      "episode 4257, reward 112.0, memory_length 2000, epsilon 0.278851990454563\n",
      "state terminated\n",
      "episode 4258, reward 351.0, memory_length 2000, epsilon 0.2787683504040615\n",
      "state terminated\n",
      "episode 4259, reward 26.0, memory_length 2000, epsilon 0.2786847354418117\n",
      "state terminated\n",
      "episode 4260, reward 157.0, memory_length 2000, epsilon 0.27860114556028837\n",
      "state terminated\n",
      "episode 4261, reward 201.0, memory_length 2000, epsilon 0.2785175807519682\n",
      "state terminated\n",
      "episode 4262, reward 31.0, memory_length 2000, epsilon 0.2784340410093305\n",
      "state terminated\n",
      "episode 4263, reward 149.0, memory_length 2000, epsilon 0.2783505263248568\n",
      "state terminated\n",
      "episode 4264, reward -72.0, memory_length 2000, epsilon 0.2782670366910306\n",
      "state terminated\n",
      "episode 4265, reward 39.0, memory_length 2000, epsilon 0.2781835721003379\n",
      "state terminated\n",
      "episode 4266, reward 247.0, memory_length 2000, epsilon 0.27810013254526683\n",
      "state terminated\n",
      "episode 4267, reward 17.0, memory_length 2000, epsilon 0.2780167180183079\n",
      "state terminated\n",
      "episode 4268, reward 401.0, memory_length 2000, epsilon 0.27793332851195374\n",
      "state terminated\n",
      "episode 4269, reward 250.0, memory_length 2000, epsilon 0.2778499640186994\n",
      "state terminated\n",
      "episode 4270, reward 262.0, memory_length 2000, epsilon 0.277766624531042\n",
      "state terminated\n",
      "episode 4271, reward 5.0, memory_length 2000, epsilon 0.277683310041481\n",
      "state terminated\n",
      "episode 4272, reward -68.0, memory_length 2000, epsilon 0.27760002054251803\n",
      "state terminated\n",
      "episode 4273, reward 82.0, memory_length 2000, epsilon 0.27751675602665715\n",
      "state terminated\n",
      "episode 4274, reward -31.0, memory_length 2000, epsilon 0.2774335164864046\n",
      "state terminated\n",
      "episode 4275, reward 110.0, memory_length 2000, epsilon 0.27735030191426846\n",
      "state terminated\n",
      "episode 4276, reward 333.0, memory_length 2000, epsilon 0.27726711230275985\n",
      "state terminated\n",
      "episode 4277, reward 154.0, memory_length 2000, epsilon 0.2771839476443915\n",
      "state terminated\n",
      "episode 4278, reward 25.0, memory_length 2000, epsilon 0.2771008079316787\n",
      "state terminated\n",
      "episode 4279, reward 305.0, memory_length 2000, epsilon 0.2770176931571387\n",
      "state terminated\n",
      "episode 4280, reward -47.0, memory_length 2000, epsilon 0.27693460331329134\n",
      "state terminated\n",
      "episode 4281, reward 136.0, memory_length 2000, epsilon 0.27685153839265836\n",
      "state terminated\n",
      "episode 4282, reward 184.0, memory_length 2000, epsilon 0.27676849838776413\n",
      "state terminated\n",
      "episode 4283, reward 76.0, memory_length 2000, epsilon 0.2766854832911349\n",
      "state terminated\n",
      "episode 4284, reward -114.0, memory_length 2000, epsilon 0.2766024930952994\n",
      "state terminated\n",
      "episode 4285, reward 187.0, memory_length 2000, epsilon 0.27651952779278843\n",
      "state terminated\n",
      "episode 4286, reward 251.0, memory_length 2000, epsilon 0.27643658737613513\n",
      "state terminated\n",
      "episode 4287, reward -56.0, memory_length 2000, epsilon 0.2763536718378749\n",
      "state terminated\n",
      "episode 4288, reward 395.0, memory_length 2000, epsilon 0.2762707811705453\n",
      "state terminated\n",
      "episode 4289, reward 119.0, memory_length 2000, epsilon 0.2761879153666862\n",
      "state terminated\n",
      "episode 4290, reward 267.0, memory_length 2000, epsilon 0.2761050744188397\n",
      "state terminated\n",
      "episode 4291, reward 3.0, memory_length 2000, epsilon 0.2760222583195501\n",
      "state terminated\n",
      "episode 4292, reward 74.0, memory_length 2000, epsilon 0.27593946706136385\n",
      "state terminated\n",
      "episode 4293, reward 323.0, memory_length 2000, epsilon 0.2758567006368299\n",
      "state terminated\n",
      "episode 4294, reward 287.0, memory_length 2000, epsilon 0.27577395903849916\n",
      "state terminated\n",
      "episode 4295, reward 261.0, memory_length 2000, epsilon 0.2756912422589249\n",
      "state terminated\n",
      "episode 4296, reward 198.0, memory_length 2000, epsilon 0.2756085502906626\n",
      "state terminated\n",
      "episode 4297, reward -9.0, memory_length 2000, epsilon 0.27552588312627013\n",
      "state terminated\n",
      "episode 4298, reward 363.0, memory_length 2000, epsilon 0.27544324075830723\n",
      "state terminated\n",
      "episode 4299, reward 282.0, memory_length 2000, epsilon 0.27536062317933624\n",
      "state terminated\n",
      "episode 4300, reward -268.0, memory_length 2000, epsilon 0.2752780303819215\n",
      "state terminated\n",
      "episode 4301, reward -52.0, memory_length 2000, epsilon 0.27519546235862974\n",
      "state terminated\n",
      "episode 4302, reward 233.0, memory_length 2000, epsilon 0.2751129191020296\n",
      "state terminated\n",
      "episode 4303, reward 290.0, memory_length 2000, epsilon 0.2750304006046925\n",
      "state terminated\n",
      "episode 4304, reward 27.0, memory_length 2000, epsilon 0.2749479068591916\n",
      "state terminated\n",
      "episode 4305, reward 288.0, memory_length 2000, epsilon 0.2748654378581026\n",
      "state terminated\n",
      "episode 4306, reward 44.0, memory_length 2000, epsilon 0.2747829935940031\n",
      "state terminated\n",
      "episode 4307, reward 132.0, memory_length 2000, epsilon 0.27470057405947323\n",
      "state terminated\n",
      "episode 4308, reward 90.0, memory_length 2000, epsilon 0.27461817924709514\n",
      "state terminated\n",
      "episode 4309, reward 132.0, memory_length 2000, epsilon 0.27453580914945347\n",
      "state terminated\n",
      "episode 4310, reward 79.0, memory_length 2000, epsilon 0.27445346375913476\n",
      "state terminated\n",
      "episode 4311, reward 265.0, memory_length 2000, epsilon 0.274371143068728\n",
      "state terminated\n",
      "episode 4312, reward 132.0, memory_length 2000, epsilon 0.2742888470708243\n",
      "state terminated\n",
      "episode 4313, reward 355.0, memory_length 2000, epsilon 0.274206575758017\n",
      "state terminated\n",
      "episode 4314, reward -81.0, memory_length 2000, epsilon 0.27412432912290174\n",
      "state terminated\n",
      "episode 4315, reward 243.0, memory_length 2000, epsilon 0.27404210715807625\n",
      "state terminated\n",
      "episode 4316, reward 144.0, memory_length 2000, epsilon 0.27395990985614055\n",
      "state terminated\n",
      "episode 4317, reward 254.0, memory_length 2000, epsilon 0.273877737209697\n",
      "state terminated\n",
      "episode 4318, reward -30.0, memory_length 2000, epsilon 0.27379558921134994\n",
      "state terminated\n",
      "episode 4319, reward 46.0, memory_length 2000, epsilon 0.27371346585370615\n",
      "state terminated\n",
      "episode 4320, reward 45.0, memory_length 2000, epsilon 0.2736313671293744\n",
      "state terminated\n",
      "episode 4321, reward 258.0, memory_length 2000, epsilon 0.2735492930309659\n",
      "state terminated\n",
      "episode 4322, reward 120.0, memory_length 2000, epsilon 0.2734672435510939\n",
      "state terminated\n",
      "episode 4323, reward 156.0, memory_length 2000, epsilon 0.27338521868237414\n",
      "state terminated\n",
      "episode 4324, reward 247.0, memory_length 2000, epsilon 0.27330321841742417\n",
      "state terminated\n",
      "episode 4325, reward 166.0, memory_length 2000, epsilon 0.27322124274886406\n",
      "state terminated\n",
      "episode 4326, reward 153.0, memory_length 2000, epsilon 0.27313929166931594\n",
      "state terminated\n",
      "episode 4327, reward -99.0, memory_length 2000, epsilon 0.2730573651714043\n",
      "state terminated\n",
      "episode 4328, reward -58.0, memory_length 2000, epsilon 0.27297546324775573\n",
      "state terminated\n",
      "episode 4329, reward 276.0, memory_length 2000, epsilon 0.27289358589099894\n",
      "state terminated\n",
      "episode 4330, reward -55.0, memory_length 2000, epsilon 0.2728117330937651\n",
      "state terminated\n",
      "episode 4331, reward 227.0, memory_length 2000, epsilon 0.2727299048486875\n",
      "state terminated\n",
      "episode 4332, reward 24.0, memory_length 2000, epsilon 0.27264810114840143\n",
      "state terminated\n",
      "episode 4333, reward 319.0, memory_length 2000, epsilon 0.2725663219855447\n",
      "state terminated\n",
      "episode 4334, reward 113.0, memory_length 2000, epsilon 0.2724845673527571\n",
      "state terminated\n",
      "episode 4335, reward 342.0, memory_length 2000, epsilon 0.2724028372426807\n",
      "state terminated\n",
      "episode 4336, reward 126.0, memory_length 2000, epsilon 0.2723211316479599\n",
      "state terminated\n",
      "episode 4337, reward 351.0, memory_length 2000, epsilon 0.27223945056124116\n",
      "state terminated\n",
      "episode 4338, reward 63.0, memory_length 2000, epsilon 0.27215779397517315\n",
      "state terminated\n",
      "episode 4339, reward 262.0, memory_length 2000, epsilon 0.2720761618824068\n",
      "state terminated\n",
      "episode 4340, reward 544.0, memory_length 2000, epsilon 0.2719945542755951\n",
      "state terminated\n",
      "episode 4341, reward 306.0, memory_length 2000, epsilon 0.27191297114739355\n",
      "state terminated\n",
      "episode 4342, reward -87.0, memory_length 2000, epsilon 0.2718314124904595\n",
      "state terminated\n",
      "episode 4343, reward 229.0, memory_length 2000, epsilon 0.2717498782974529\n",
      "state terminated\n",
      "episode 4344, reward 249.0, memory_length 2000, epsilon 0.2716683685610354\n",
      "state terminated\n",
      "episode 4345, reward 75.0, memory_length 2000, epsilon 0.2715868832738713\n",
      "state terminated\n",
      "episode 4346, reward 425.0, memory_length 2000, epsilon 0.2715054224286269\n",
      "state terminated\n",
      "episode 4347, reward 158.0, memory_length 2000, epsilon 0.27142398601797074\n",
      "state terminated\n",
      "episode 4348, reward 206.0, memory_length 2000, epsilon 0.2713425740345734\n",
      "state terminated\n",
      "episode 4349, reward 156.0, memory_length 2000, epsilon 0.2712611864711079\n",
      "state terminated\n",
      "episode 4350, reward 396.0, memory_length 2000, epsilon 0.2711798233202495\n",
      "state terminated\n",
      "episode 4351, reward 189.0, memory_length 2000, epsilon 0.2710984845746753\n",
      "state terminated\n",
      "episode 4352, reward 179.0, memory_length 2000, epsilon 0.27101717022706484\n",
      "state terminated\n",
      "episode 4353, reward 93.0, memory_length 2000, epsilon 0.27093588027009996\n",
      "state terminated\n",
      "episode 4354, reward -74.0, memory_length 2000, epsilon 0.2708546146964645\n",
      "state terminated\n",
      "episode 4355, reward 64.0, memory_length 2000, epsilon 0.27077337349884445\n",
      "state terminated\n",
      "episode 4356, reward 277.0, memory_length 2000, epsilon 0.27069215666992824\n",
      "state terminated\n",
      "episode 4357, reward 182.0, memory_length 2000, epsilon 0.2706109642024064\n",
      "state terminated\n",
      "episode 4358, reward 232.0, memory_length 2000, epsilon 0.27052979608897143\n",
      "state terminated\n",
      "episode 4359, reward 115.0, memory_length 2000, epsilon 0.2704486523223183\n",
      "state terminated\n",
      "episode 4360, reward 28.0, memory_length 2000, epsilon 0.2703675328951441\n",
      "state terminated\n",
      "episode 4361, reward 56.0, memory_length 2000, epsilon 0.27028643780014805\n",
      "state terminated\n",
      "episode 4362, reward -269.0, memory_length 2000, epsilon 0.2702053670300315\n",
      "state terminated\n",
      "episode 4363, reward 2.0, memory_length 2000, epsilon 0.27012432057749824\n",
      "state terminated\n",
      "episode 4364, reward 288.0, memory_length 2000, epsilon 0.270043298435254\n",
      "state terminated\n",
      "episode 4365, reward 353.0, memory_length 2000, epsilon 0.2699623005960068\n",
      "state terminated\n",
      "episode 4366, reward 452.0, memory_length 2000, epsilon 0.2698813270524668\n",
      "state terminated\n",
      "episode 4367, reward 116.0, memory_length 2000, epsilon 0.2698003777973465\n",
      "state terminated\n",
      "episode 4368, reward 242.0, memory_length 2000, epsilon 0.26971945282336035\n",
      "state terminated\n",
      "episode 4369, reward -45.0, memory_length 2000, epsilon 0.2696385521232251\n",
      "state terminated\n",
      "episode 4370, reward 156.0, memory_length 2000, epsilon 0.2695576756896597\n",
      "state terminated\n",
      "episode 4371, reward 360.0, memory_length 2000, epsilon 0.2694768235153853\n",
      "state terminated\n",
      "episode 4372, reward 72.0, memory_length 2000, epsilon 0.26939599559312527\n",
      "state terminated\n",
      "episode 4373, reward -215.0, memory_length 2000, epsilon 0.269315191915605\n",
      "state terminated\n",
      "episode 4374, reward -3.0, memory_length 2000, epsilon 0.2692344124755522\n",
      "state terminated\n",
      "episode 4375, reward 59.0, memory_length 2000, epsilon 0.2691536572656966\n",
      "state terminated\n",
      "episode 4376, reward 291.0, memory_length 2000, epsilon 0.26907292627877044\n",
      "state terminated\n",
      "episode 4377, reward -5.0, memory_length 2000, epsilon 0.2689922195075078\n",
      "state terminated\n",
      "episode 4378, reward 262.0, memory_length 2000, epsilon 0.2689115369446451\n",
      "state terminated\n",
      "episode 4379, reward 21.0, memory_length 2000, epsilon 0.26883087858292093\n",
      "state terminated\n",
      "episode 4380, reward 155.0, memory_length 2000, epsilon 0.268750244415076\n",
      "state terminated\n",
      "episode 4381, reward -27.0, memory_length 2000, epsilon 0.2686696344338532\n",
      "state terminated\n",
      "episode 4382, reward 244.0, memory_length 2000, epsilon 0.26858904863199773\n",
      "state terminated\n",
      "episode 4383, reward -27.0, memory_length 2000, epsilon 0.26850848700225677\n",
      "state terminated\n",
      "episode 4384, reward 179.0, memory_length 2000, epsilon 0.26842794953737986\n",
      "state terminated\n",
      "episode 4385, reward -38.0, memory_length 2000, epsilon 0.2683474362301186\n",
      "state terminated\n",
      "episode 4386, reward 270.0, memory_length 2000, epsilon 0.26826694707322674\n",
      "state terminated\n",
      "episode 4387, reward 26.0, memory_length 2000, epsilon 0.2681864820594604\n",
      "state terminated\n",
      "episode 4388, reward -191.0, memory_length 2000, epsilon 0.26810604118157755\n",
      "state terminated\n",
      "episode 4389, reward 206.0, memory_length 2000, epsilon 0.2680256244323385\n",
      "state terminated\n",
      "episode 4390, reward -9.0, memory_length 2000, epsilon 0.26794523180450597\n",
      "state terminated\n",
      "episode 4391, reward 268.0, memory_length 2000, epsilon 0.2678648632908444\n",
      "state terminated\n",
      "episode 4392, reward -2.0, memory_length 2000, epsilon 0.26778451888412075\n",
      "state terminated\n",
      "episode 4393, reward -59.0, memory_length 2000, epsilon 0.267704198577104\n",
      "state terminated\n",
      "episode 4394, reward 281.0, memory_length 2000, epsilon 0.2676239023625653\n",
      "state terminated\n",
      "episode 4395, reward 49.0, memory_length 2000, epsilon 0.267543630233278\n",
      "state terminated\n",
      "episode 4396, reward 186.0, memory_length 2000, epsilon 0.2674633821820175\n",
      "state terminated\n",
      "episode 4397, reward -86.0, memory_length 2000, epsilon 0.2673831582015616\n",
      "state terminated\n",
      "episode 4398, reward 128.0, memory_length 2000, epsilon 0.2673029582846902\n",
      "state terminated\n",
      "episode 4399, reward -10.0, memory_length 2000, epsilon 0.2672227824241852\n",
      "state terminated\n",
      "episode 4400, reward 162.0, memory_length 2000, epsilon 0.2671426306128308\n",
      "state terminated\n",
      "episode 4401, reward 39.0, memory_length 2000, epsilon 0.2670625028434133\n",
      "state terminated\n",
      "episode 4402, reward -37.0, memory_length 2000, epsilon 0.2669823991087213\n",
      "state terminated\n",
      "episode 4403, reward 228.0, memory_length 2000, epsilon 0.2669023194015453\n",
      "state terminated\n",
      "episode 4404, reward 198.0, memory_length 2000, epsilon 0.26682226371467826\n",
      "state terminated\n",
      "episode 4405, reward 268.0, memory_length 2000, epsilon 0.2667422320409152\n",
      "state terminated\n",
      "episode 4406, reward 9.0, memory_length 2000, epsilon 0.2666622243730532\n",
      "state terminated\n",
      "episode 4407, reward -15.0, memory_length 2000, epsilon 0.2665822407038915\n",
      "state terminated\n",
      "episode 4408, reward 80.0, memory_length 2000, epsilon 0.2665022810262317\n",
      "state terminated\n",
      "episode 4409, reward -32.0, memory_length 2000, epsilon 0.2664223453328773\n",
      "state terminated\n",
      "episode 4410, reward 121.0, memory_length 2000, epsilon 0.26634243361663423\n",
      "state terminated\n",
      "episode 4411, reward -100.0, memory_length 2000, epsilon 0.26626254587031034\n",
      "state terminated\n",
      "episode 4412, reward -123.0, memory_length 2000, epsilon 0.26618268208671575\n",
      "state terminated\n",
      "episode 4413, reward 326.0, memory_length 2000, epsilon 0.26610284225866276\n",
      "state terminated\n",
      "episode 4414, reward 411.0, memory_length 2000, epsilon 0.26602302637896574\n",
      "state terminated\n",
      "episode 4415, reward -44.0, memory_length 2000, epsilon 0.26594323444044127\n",
      "state terminated\n",
      "episode 4416, reward 206.0, memory_length 2000, epsilon 0.265863466435908\n",
      "state terminated\n",
      "episode 4417, reward -9.0, memory_length 2000, epsilon 0.26578372235818704\n",
      "state terminated\n",
      "episode 4418, reward -141.0, memory_length 2000, epsilon 0.2657040022001012\n",
      "state terminated\n",
      "episode 4419, reward 224.0, memory_length 2000, epsilon 0.2656243059544757\n",
      "state terminated\n",
      "episode 4420, reward 398.0, memory_length 2000, epsilon 0.265544633614138\n",
      "state terminated\n",
      "episode 4421, reward 386.0, memory_length 2000, epsilon 0.26546498517191747\n",
      "state terminated\n",
      "episode 4422, reward 82.0, memory_length 2000, epsilon 0.26538536062064577\n",
      "state terminated\n",
      "episode 4423, reward 449.0, memory_length 2000, epsilon 0.26530575995315664\n",
      "state terminated\n",
      "episode 4424, reward -20.0, memory_length 2000, epsilon 0.2652261831622862\n",
      "state terminated\n",
      "episode 4425, reward 50.0, memory_length 2000, epsilon 0.26514663024087237\n",
      "state terminated\n",
      "episode 4426, reward -54.0, memory_length 2000, epsilon 0.2650671011817554\n",
      "state terminated\n",
      "episode 4427, reward 207.0, memory_length 2000, epsilon 0.2649875959777778\n",
      "state terminated\n",
      "episode 4428, reward 277.0, memory_length 2000, epsilon 0.264908114621784\n",
      "state terminated\n",
      "episode 4429, reward 21.0, memory_length 2000, epsilon 0.2648286571066206\n",
      "state terminated\n",
      "episode 4430, reward 211.0, memory_length 2000, epsilon 0.2647492234251366\n",
      "state terminated\n",
      "episode 4431, reward -60.0, memory_length 2000, epsilon 0.2646698135701829\n",
      "state terminated\n",
      "episode 4432, reward 351.0, memory_length 2000, epsilon 0.2645904275346126\n",
      "state terminated\n",
      "episode 4433, reward 184.0, memory_length 2000, epsilon 0.26451106531128094\n",
      "state terminated\n",
      "episode 4434, reward 265.0, memory_length 2000, epsilon 0.2644317268930453\n",
      "state terminated\n",
      "episode 4435, reward 342.0, memory_length 2000, epsilon 0.2643524122727653\n",
      "state terminated\n",
      "episode 4436, reward 400.0, memory_length 2000, epsilon 0.2642731214433025\n",
      "state terminated\n",
      "episode 4437, reward -11.0, memory_length 2000, epsilon 0.2641938543975209\n",
      "state terminated\n",
      "episode 4438, reward 76.0, memory_length 2000, epsilon 0.2641146111282864\n",
      "state terminated\n",
      "episode 4439, reward 134.0, memory_length 2000, epsilon 0.264035391628467\n",
      "state terminated\n",
      "episode 4440, reward 149.0, memory_length 2000, epsilon 0.2639561958909331\n",
      "state terminated\n",
      "episode 4441, reward 71.0, memory_length 2000, epsilon 0.26387702390855694\n",
      "state terminated\n",
      "episode 4442, reward -69.0, memory_length 2000, epsilon 0.2637978756742132\n",
      "state terminated\n",
      "episode 4443, reward 61.0, memory_length 2000, epsilon 0.2637187511807783\n",
      "state terminated\n",
      "episode 4444, reward 265.0, memory_length 2000, epsilon 0.26363965042113124\n",
      "state terminated\n",
      "episode 4445, reward 200.0, memory_length 2000, epsilon 0.263560573388153\n",
      "state terminated\n",
      "episode 4446, reward 47.0, memory_length 2000, epsilon 0.2634815200747264\n",
      "state terminated\n",
      "episode 4447, reward -215.0, memory_length 2000, epsilon 0.2634024904737369\n",
      "state terminated\n",
      "episode 4448, reward -18.0, memory_length 2000, epsilon 0.2633234845780717\n",
      "state terminated\n",
      "episode 4449, reward 204.0, memory_length 2000, epsilon 0.26324450238062025\n",
      "state terminated\n",
      "episode 4450, reward 88.0, memory_length 2000, epsilon 0.26316554387427415\n",
      "state terminated\n",
      "episode 4451, reward -56.0, memory_length 2000, epsilon 0.26308660905192727\n",
      "state terminated\n",
      "episode 4452, reward 92.0, memory_length 2000, epsilon 0.2630076979064753\n",
      "state terminated\n",
      "episode 4453, reward 453.0, memory_length 2000, epsilon 0.26292881043081645\n",
      "state terminated\n",
      "episode 4454, reward 243.0, memory_length 2000, epsilon 0.2628499466178506\n",
      "state terminated\n",
      "episode 4455, reward 304.0, memory_length 2000, epsilon 0.26277110646048013\n",
      "state terminated\n",
      "episode 4456, reward 220.0, memory_length 2000, epsilon 0.26269228995160937\n",
      "state terminated\n",
      "episode 4457, reward -141.0, memory_length 2000, epsilon 0.26261349708414505\n",
      "state terminated\n",
      "episode 4458, reward 171.0, memory_length 2000, epsilon 0.2625347278509955\n",
      "state terminated\n",
      "episode 4459, reward 22.0, memory_length 2000, epsilon 0.2624559822450717\n",
      "state terminated\n",
      "episode 4460, reward 81.0, memory_length 2000, epsilon 0.2623772602592865\n",
      "state terminated\n",
      "episode 4461, reward 321.0, memory_length 2000, epsilon 0.2622985618865548\n",
      "state terminated\n",
      "episode 4462, reward 170.0, memory_length 2000, epsilon 0.26221988711979394\n",
      "state terminated\n",
      "episode 4463, reward 33.0, memory_length 2000, epsilon 0.26214123595192307\n",
      "state terminated\n",
      "episode 4464, reward 338.0, memory_length 2000, epsilon 0.2620626083758636\n",
      "state terminated\n",
      "episode 4465, reward -63.0, memory_length 2000, epsilon 0.26198400438453906\n",
      "state terminated\n",
      "episode 4466, reward 138.0, memory_length 2000, epsilon 0.2619054239708751\n",
      "state terminated\n",
      "episode 4467, reward 1.0, memory_length 2000, epsilon 0.2618268671277995\n",
      "state terminated\n",
      "episode 4468, reward -27.0, memory_length 2000, epsilon 0.2617483338482421\n",
      "state terminated\n",
      "episode 4469, reward 144.0, memory_length 2000, epsilon 0.26166982412513495\n",
      "state terminated\n",
      "episode 4470, reward 44.0, memory_length 2000, epsilon 0.26159133795141204\n",
      "state terminated\n",
      "episode 4471, reward 144.0, memory_length 2000, epsilon 0.26151287532000983\n",
      "state terminated\n",
      "episode 4472, reward 237.0, memory_length 2000, epsilon 0.26143443622386653\n",
      "state terminated\n",
      "episode 4473, reward -109.0, memory_length 2000, epsilon 0.26135602065592267\n",
      "state terminated\n",
      "episode 4474, reward 96.0, memory_length 2000, epsilon 0.2612776286091209\n",
      "state terminated\n",
      "episode 4475, reward -48.0, memory_length 2000, epsilon 0.2611992600764058\n",
      "state terminated\n",
      "episode 4476, reward 121.0, memory_length 2000, epsilon 0.2611209150507244\n",
      "state terminated\n",
      "episode 4477, reward -50.0, memory_length 2000, epsilon 0.26104259352502535\n",
      "state terminated\n",
      "episode 4478, reward 175.0, memory_length 2000, epsilon 0.26096429549225997\n",
      "state terminated\n",
      "episode 4479, reward 251.0, memory_length 2000, epsilon 0.2608860209453814\n",
      "state terminated\n",
      "episode 4480, reward 177.0, memory_length 2000, epsilon 0.2608077698773449\n",
      "state terminated\n",
      "episode 4481, reward 391.0, memory_length 2000, epsilon 0.26072954228110784\n",
      "state terminated\n",
      "episode 4482, reward -50.0, memory_length 2000, epsilon 0.26065133814962976\n",
      "state terminated\n",
      "episode 4483, reward 325.0, memory_length 2000, epsilon 0.26057315747587223\n",
      "state terminated\n",
      "episode 4484, reward 312.0, memory_length 2000, epsilon 0.2604950002527991\n",
      "state terminated\n",
      "episode 4485, reward -9.0, memory_length 2000, epsilon 0.26041686647337625\n",
      "state terminated\n",
      "episode 4486, reward 144.0, memory_length 2000, epsilon 0.2603387561305715\n",
      "state terminated\n",
      "episode 4487, reward 215.0, memory_length 2000, epsilon 0.2602606692173549\n",
      "state terminated\n",
      "episode 4488, reward 9.0, memory_length 2000, epsilon 0.2601826057266988\n",
      "state terminated\n",
      "episode 4489, reward 166.0, memory_length 2000, epsilon 0.2601045656515774\n",
      "state terminated\n",
      "episode 4490, reward 156.0, memory_length 2000, epsilon 0.260026548984967\n",
      "state terminated\n",
      "episode 4491, reward 184.0, memory_length 2000, epsilon 0.25994855571984626\n",
      "state terminated\n",
      "episode 4492, reward 99.0, memory_length 2000, epsilon 0.25987058584919565\n",
      "state terminated\n",
      "episode 4493, reward -26.0, memory_length 2000, epsilon 0.259792639365998\n",
      "state terminated\n",
      "episode 4494, reward 155.0, memory_length 2000, epsilon 0.25971471626323805\n",
      "state terminated\n",
      "episode 4495, reward 1.0, memory_length 2000, epsilon 0.25963681653390275\n",
      "state terminated\n",
      "episode 4496, reward 214.0, memory_length 2000, epsilon 0.259558940170981\n",
      "state terminated\n",
      "episode 4497, reward 228.0, memory_length 2000, epsilon 0.25948108716746415\n",
      "state terminated\n",
      "episode 4498, reward 292.0, memory_length 2000, epsilon 0.2594032575163453\n",
      "state terminated\n",
      "episode 4499, reward 269.0, memory_length 2000, epsilon 0.25932545121061984\n",
      "state terminated\n",
      "episode 4500, reward -72.0, memory_length 2000, epsilon 0.2592476682432851\n",
      "state terminated\n",
      "episode 4501, reward 180.0, memory_length 2000, epsilon 0.2591699086073407\n",
      "state terminated\n",
      "episode 4502, reward 123.0, memory_length 2000, epsilon 0.2590921722957883\n",
      "state terminated\n",
      "episode 4503, reward -13.0, memory_length 2000, epsilon 0.25901445930163147\n",
      "state terminated\n",
      "episode 4504, reward 96.0, memory_length 2000, epsilon 0.2589367696178762\n",
      "state terminated\n",
      "episode 4505, reward 142.0, memory_length 2000, epsilon 0.2588591032375304\n",
      "state terminated\n",
      "episode 4506, reward 112.0, memory_length 2000, epsilon 0.25878146015360404\n",
      "state terminated\n",
      "episode 4507, reward -5.0, memory_length 2000, epsilon 0.2587038403591093\n",
      "state terminated\n",
      "episode 4508, reward 35.0, memory_length 2000, epsilon 0.2586262438470604\n",
      "state terminated\n",
      "episode 4509, reward 216.0, memory_length 2000, epsilon 0.2585486706104736\n",
      "state terminated\n",
      "episode 4510, reward 153.0, memory_length 2000, epsilon 0.2584711206423672\n",
      "state terminated\n",
      "episode 4511, reward 241.0, memory_length 2000, epsilon 0.25839359393576194\n",
      "state terminated\n",
      "episode 4512, reward 150.0, memory_length 2000, epsilon 0.2583160904836803\n",
      "state terminated\n",
      "episode 4513, reward 257.0, memory_length 2000, epsilon 0.258238610279147\n",
      "state terminated\n",
      "episode 4514, reward 211.0, memory_length 2000, epsilon 0.2581611533151888\n",
      "state terminated\n",
      "episode 4515, reward -72.0, memory_length 2000, epsilon 0.25808371958483456\n",
      "state terminated\n",
      "episode 4516, reward 155.0, memory_length 2000, epsilon 0.2580063090811152\n",
      "state terminated\n",
      "episode 4517, reward 196.0, memory_length 2000, epsilon 0.25792892179706384\n",
      "state terminated\n",
      "episode 4518, reward 220.0, memory_length 2000, epsilon 0.2578515577257157\n",
      "state terminated\n",
      "episode 4519, reward 170.0, memory_length 2000, epsilon 0.2577742168601079\n",
      "state terminated\n",
      "episode 4520, reward -41.0, memory_length 2000, epsilon 0.25769689919327976\n",
      "state terminated\n",
      "episode 4521, reward 216.0, memory_length 2000, epsilon 0.2576196047182728\n",
      "state terminated\n",
      "episode 4522, reward -322.0, memory_length 2000, epsilon 0.2575423334281303\n",
      "state terminated\n",
      "episode 4523, reward 44.0, memory_length 2000, epsilon 0.2574650853158981\n",
      "state terminated\n",
      "episode 4524, reward -177.0, memory_length 2000, epsilon 0.2573878603746237\n",
      "state terminated\n",
      "episode 4525, reward -43.0, memory_length 2000, epsilon 0.2573106585973569\n",
      "state terminated\n",
      "episode 4526, reward 213.0, memory_length 2000, epsilon 0.25723347997714957\n",
      "state terminated\n",
      "episode 4527, reward 167.0, memory_length 2000, epsilon 0.2571563245070556\n",
      "state terminated\n",
      "episode 4528, reward 12.0, memory_length 2000, epsilon 0.257079192180131\n",
      "state terminated\n",
      "episode 4529, reward 168.0, memory_length 2000, epsilon 0.2570020829894339\n",
      "state terminated\n",
      "episode 4530, reward -71.0, memory_length 2000, epsilon 0.2569249969280244\n",
      "state terminated\n",
      "episode 4531, reward 435.0, memory_length 2000, epsilon 0.2568479339889648\n",
      "state terminated\n",
      "episode 4532, reward 54.0, memory_length 2000, epsilon 0.2567708941653195\n",
      "state terminated\n",
      "episode 4533, reward 195.0, memory_length 2000, epsilon 0.2566938774501548\n",
      "state terminated\n",
      "episode 4534, reward 184.0, memory_length 2000, epsilon 0.2566168838365393\n",
      "state terminated\n",
      "episode 4535, reward 209.0, memory_length 2000, epsilon 0.25653991331754344\n",
      "state terminated\n",
      "episode 4536, reward 390.0, memory_length 2000, epsilon 0.25646296588624\n",
      "state terminated\n",
      "episode 4537, reward 142.0, memory_length 2000, epsilon 0.25638604153570355\n",
      "state terminated\n",
      "episode 4538, reward 357.0, memory_length 2000, epsilon 0.25630914025901114\n",
      "state terminated\n",
      "episode 4539, reward -69.0, memory_length 2000, epsilon 0.2562322620492415\n",
      "state terminated\n",
      "episode 4540, reward 306.0, memory_length 2000, epsilon 0.2561554068994756\n",
      "state terminated\n",
      "episode 4541, reward -126.0, memory_length 2000, epsilon 0.2560785748027965\n",
      "state terminated\n",
      "episode 4542, reward -139.0, memory_length 2000, epsilon 0.25600176575228933\n",
      "state terminated\n",
      "episode 4543, reward 219.0, memory_length 2000, epsilon 0.2559249797410412\n",
      "state terminated\n",
      "episode 4544, reward 81.0, memory_length 2000, epsilon 0.2558482167621414\n",
      "state terminated\n",
      "episode 4545, reward 63.0, memory_length 2000, epsilon 0.2557714768086814\n",
      "state terminated\n",
      "episode 4546, reward 692.0, memory_length 2000, epsilon 0.2556947598737544\n",
      "state terminated\n",
      "episode 4547, reward -6.0, memory_length 2000, epsilon 0.25561806595045594\n",
      "state terminated\n",
      "episode 4548, reward 307.0, memory_length 2000, epsilon 0.2555413950318836\n",
      "state terminated\n",
      "episode 4549, reward 256.0, memory_length 2000, epsilon 0.25546474711113704\n",
      "state terminated\n",
      "episode 4550, reward 152.0, memory_length 2000, epsilon 0.25538812218131784\n",
      "state terminated\n",
      "episode 4551, reward -91.0, memory_length 2000, epsilon 0.25531152023552983\n",
      "state terminated\n",
      "episode 4552, reward 211.0, memory_length 2000, epsilon 0.25523494126687885\n",
      "state terminated\n",
      "episode 4553, reward 6.0, memory_length 2000, epsilon 0.2551583852684727\n",
      "state terminated\n",
      "episode 4554, reward 269.0, memory_length 2000, epsilon 0.2550818522334214\n",
      "state terminated\n",
      "episode 4555, reward 48.0, memory_length 2000, epsilon 0.255005342154837\n",
      "state terminated\n",
      "episode 4556, reward 333.0, memory_length 2000, epsilon 0.25492885502583357\n",
      "state terminated\n",
      "episode 4557, reward 28.0, memory_length 2000, epsilon 0.2548523908395272\n",
      "state terminated\n",
      "episode 4558, reward 127.0, memory_length 2000, epsilon 0.25477594958903627\n",
      "state terminated\n",
      "episode 4559, reward -70.0, memory_length 2000, epsilon 0.2546995312674809\n",
      "state terminated\n",
      "episode 4560, reward -10.0, memory_length 2000, epsilon 0.2546231358679836\n",
      "state terminated\n",
      "episode 4561, reward 127.0, memory_length 2000, epsilon 0.2545467633836686\n",
      "state terminated\n",
      "episode 4562, reward 116.0, memory_length 2000, epsilon 0.25447041380766255\n",
      "state terminated\n",
      "episode 4563, reward 204.0, memory_length 2000, epsilon 0.25439408713309386\n",
      "state terminated\n",
      "episode 4564, reward 97.0, memory_length 2000, epsilon 0.25431778335309324\n",
      "state terminated\n",
      "episode 4565, reward 325.0, memory_length 2000, epsilon 0.25424150246079324\n",
      "state terminated\n",
      "episode 4566, reward 297.0, memory_length 2000, epsilon 0.25416524444932864\n",
      "state terminated\n",
      "episode 4567, reward 76.0, memory_length 2000, epsilon 0.25408900931183626\n",
      "state terminated\n",
      "episode 4568, reward -68.0, memory_length 2000, epsilon 0.2540127970414549\n",
      "state terminated\n",
      "episode 4569, reward 83.0, memory_length 2000, epsilon 0.25393660763132536\n",
      "state terminated\n",
      "episode 4570, reward -201.0, memory_length 2000, epsilon 0.2538604410745907\n",
      "state terminated\n",
      "episode 4571, reward 261.0, memory_length 2000, epsilon 0.25378429736439595\n",
      "state terminated\n",
      "episode 4572, reward 541.0, memory_length 2000, epsilon 0.2537081764938881\n",
      "state terminated\n",
      "episode 4573, reward -25.0, memory_length 2000, epsilon 0.2536320784562163\n",
      "state terminated\n",
      "episode 4574, reward 299.0, memory_length 2000, epsilon 0.25355600324453176\n",
      "state terminated\n",
      "episode 4575, reward 162.0, memory_length 2000, epsilon 0.2534799508519877\n",
      "state terminated\n",
      "episode 4576, reward 76.0, memory_length 2000, epsilon 0.2534039212717394\n",
      "state terminated\n",
      "episode 4577, reward -83.0, memory_length 2000, epsilon 0.2533279144969441\n",
      "state terminated\n",
      "episode 4578, reward 221.0, memory_length 2000, epsilon 0.2532519305207613\n",
      "state terminated\n",
      "episode 4579, reward 144.0, memory_length 2000, epsilon 0.2531759693363525\n",
      "state terminated\n",
      "episode 4580, reward 422.0, memory_length 2000, epsilon 0.253100030936881\n",
      "state terminated\n",
      "episode 4581, reward -127.0, memory_length 2000, epsilon 0.25302411531551255\n",
      "state terminated\n",
      "episode 4582, reward 146.0, memory_length 2000, epsilon 0.2529482224654146\n",
      "state terminated\n",
      "episode 4583, reward 116.0, memory_length 2000, epsilon 0.25287235237975686\n",
      "state terminated\n",
      "episode 4584, reward 149.0, memory_length 2000, epsilon 0.252796505051711\n",
      "state terminated\n",
      "episode 4585, reward 103.0, memory_length 2000, epsilon 0.25272068047445073\n",
      "state terminated\n",
      "episode 4586, reward 79.0, memory_length 2000, epsilon 0.2526448786411519\n",
      "state terminated\n",
      "episode 4587, reward -19.0, memory_length 2000, epsilon 0.25256909954499235\n",
      "state terminated\n",
      "episode 4588, reward -203.0, memory_length 2000, epsilon 0.2524933431791519\n",
      "state terminated\n",
      "episode 4589, reward 260.0, memory_length 2000, epsilon 0.25241760953681247\n",
      "state terminated\n",
      "episode 4590, reward -6.0, memory_length 2000, epsilon 0.2523418986111582\n",
      "state terminated\n",
      "episode 4591, reward 144.0, memory_length 2000, epsilon 0.2522662103953748\n",
      "state terminated\n",
      "episode 4592, reward 206.0, memory_length 2000, epsilon 0.2521905448826506\n",
      "state terminated\n",
      "episode 4593, reward 359.0, memory_length 2000, epsilon 0.2521149020661756\n",
      "state terminated\n",
      "episode 4594, reward 138.0, memory_length 2000, epsilon 0.25203928193914193\n",
      "state terminated\n",
      "episode 4595, reward -3.0, memory_length 2000, epsilon 0.2519636844947438\n",
      "state terminated\n",
      "episode 4596, reward 225.0, memory_length 2000, epsilon 0.25188810972617753\n",
      "state terminated\n",
      "episode 4597, reward -29.0, memory_length 2000, epsilon 0.2518125576266413\n",
      "state terminated\n",
      "episode 4598, reward -64.0, memory_length 2000, epsilon 0.25173702818933524\n",
      "state terminated\n",
      "episode 4599, reward 139.0, memory_length 2000, epsilon 0.25166152140746206\n",
      "state terminated\n",
      "episode 4600, reward 147.0, memory_length 2000, epsilon 0.25158603727422596\n",
      "state terminated\n",
      "episode 4601, reward -2.0, memory_length 2000, epsilon 0.25151057578283337\n",
      "state terminated\n",
      "episode 4602, reward 75.0, memory_length 2000, epsilon 0.2514351369264928\n",
      "state terminated\n",
      "episode 4603, reward 270.0, memory_length 2000, epsilon 0.25135972069841467\n",
      "state terminated\n",
      "episode 4604, reward -122.0, memory_length 2000, epsilon 0.25128432709181153\n",
      "state terminated\n",
      "episode 4605, reward 171.0, memory_length 2000, epsilon 0.2512089560998981\n",
      "state terminated\n",
      "episode 4606, reward 443.0, memory_length 2000, epsilon 0.2511336077158908\n",
      "state terminated\n",
      "episode 4607, reward 381.0, memory_length 2000, epsilon 0.25105828193300844\n",
      "state terminated\n",
      "episode 4608, reward 509.0, memory_length 2000, epsilon 0.2509829787444716\n",
      "state terminated\n",
      "episode 4609, reward 269.0, memory_length 2000, epsilon 0.250907698143503\n",
      "state terminated\n",
      "episode 4610, reward 346.0, memory_length 2000, epsilon 0.25083244012332745\n",
      "state terminated\n",
      "episode 4611, reward 353.0, memory_length 2000, epsilon 0.2507572046771716\n",
      "state terminated\n",
      "episode 4612, reward 121.0, memory_length 2000, epsilon 0.2506819917982644\n",
      "state terminated\n",
      "episode 4613, reward 291.0, memory_length 2000, epsilon 0.2506068014798366\n",
      "state terminated\n",
      "episode 4614, reward 12.0, memory_length 2000, epsilon 0.2505316337151211\n",
      "state terminated\n",
      "episode 4615, reward -118.0, memory_length 2000, epsilon 0.2504564884973528\n",
      "state terminated\n",
      "episode 4616, reward 245.0, memory_length 2000, epsilon 0.25038136581976866\n",
      "state terminated\n",
      "episode 4617, reward 301.0, memory_length 2000, epsilon 0.25030626567560765\n",
      "state terminated\n",
      "episode 4618, reward 256.0, memory_length 2000, epsilon 0.2502311880581106\n",
      "state terminated\n",
      "episode 4619, reward 162.0, memory_length 2000, epsilon 0.25015613296052075\n",
      "state terminated\n",
      "episode 4620, reward 187.0, memory_length 2000, epsilon 0.25008110037608305\n",
      "state terminated\n",
      "episode 4621, reward -266.0, memory_length 2000, epsilon 0.2500060902980445\n",
      "state terminated\n",
      "episode 4622, reward -36.0, memory_length 2000, epsilon 0.24993110271965424\n",
      "state terminated\n",
      "episode 4623, reward 153.0, memory_length 2000, epsilon 0.24985613763416342\n",
      "state terminated\n",
      "episode 4624, reward 395.0, memory_length 2000, epsilon 0.2497811950348251\n",
      "state terminated\n",
      "episode 4625, reward 6.0, memory_length 2000, epsilon 0.24970627491489455\n",
      "state terminated\n",
      "episode 4626, reward 48.0, memory_length 2000, epsilon 0.2496313772676289\n",
      "state terminated\n",
      "episode 4627, reward 455.0, memory_length 2000, epsilon 0.2495565020862874\n",
      "state terminated\n",
      "episode 4628, reward -18.0, memory_length 2000, epsilon 0.24948164936413122\n",
      "state terminated\n",
      "episode 4629, reward 211.0, memory_length 2000, epsilon 0.24940681909442367\n",
      "state terminated\n",
      "episode 4630, reward 133.0, memory_length 2000, epsilon 0.24933201127043003\n",
      "state terminated\n",
      "episode 4631, reward -186.0, memory_length 2000, epsilon 0.2492572258854175\n",
      "state terminated\n",
      "episode 4632, reward 164.0, memory_length 2000, epsilon 0.2491824629326555\n",
      "state terminated\n",
      "episode 4633, reward 340.0, memory_length 2000, epsilon 0.24910772240541537\n",
      "state terminated\n",
      "episode 4634, reward 283.0, memory_length 2000, epsilon 0.2490330042969704\n",
      "state terminated\n",
      "episode 4635, reward 184.0, memory_length 2000, epsilon 0.24895830860059598\n",
      "state terminated\n",
      "episode 4636, reward -106.0, memory_length 2000, epsilon 0.2488836353095695\n",
      "state terminated\n",
      "episode 4637, reward 40.0, memory_length 2000, epsilon 0.2488089844171704\n",
      "state terminated\n",
      "episode 4638, reward -105.0, memory_length 2000, epsilon 0.24873435591668\n",
      "state terminated\n",
      "episode 4639, reward 31.0, memory_length 2000, epsilon 0.24865974980138184\n",
      "state terminated\n",
      "episode 4640, reward 144.0, memory_length 2000, epsilon 0.24858516606456132\n",
      "state terminated\n",
      "episode 4641, reward 288.0, memory_length 2000, epsilon 0.24851060469950595\n",
      "state terminated\n",
      "episode 4642, reward 206.0, memory_length 2000, epsilon 0.24843606569950513\n",
      "state terminated\n",
      "episode 4643, reward 321.0, memory_length 2000, epsilon 0.2483615490578504\n",
      "state terminated\n",
      "episode 4644, reward 3.0, memory_length 2000, epsilon 0.24828705476783527\n",
      "state terminated\n",
      "episode 4645, reward 284.0, memory_length 2000, epsilon 0.24821258282275516\n",
      "state terminated\n",
      "episode 4646, reward 379.0, memory_length 2000, epsilon 0.24813813321590775\n",
      "state terminated\n",
      "episode 4647, reward 430.0, memory_length 2000, epsilon 0.2480637059405925\n",
      "state terminated\n",
      "episode 4648, reward 381.0, memory_length 2000, epsilon 0.24798930099011093\n",
      "state terminated\n",
      "episode 4649, reward -68.0, memory_length 2000, epsilon 0.24791491835776663\n",
      "state terminated\n",
      "episode 4650, reward 27.0, memory_length 2000, epsilon 0.24784055803686517\n",
      "state terminated\n",
      "episode 4651, reward 296.0, memory_length 2000, epsilon 0.24776622002071402\n",
      "state terminated\n",
      "episode 4652, reward 117.0, memory_length 2000, epsilon 0.24769190430262286\n",
      "state terminated\n",
      "episode 4653, reward 84.0, memory_length 2000, epsilon 0.2476176108759033\n",
      "state terminated\n",
      "episode 4654, reward 207.0, memory_length 2000, epsilon 0.24754333973386888\n",
      "state terminated\n",
      "episode 4655, reward 274.0, memory_length 2000, epsilon 0.2474690908698352\n",
      "state terminated\n",
      "episode 4656, reward 38.0, memory_length 2000, epsilon 0.24739486427711987\n",
      "state terminated\n",
      "episode 4657, reward -183.0, memory_length 2000, epsilon 0.24732065994904248\n",
      "state terminated\n",
      "episode 4658, reward 96.0, memory_length 2000, epsilon 0.2472464778789246\n",
      "state terminated\n",
      "episode 4659, reward 254.0, memory_length 2000, epsilon 0.24717231806008996\n",
      "state terminated\n",
      "episode 4660, reward 144.0, memory_length 2000, epsilon 0.2470981804858641\n",
      "state terminated\n",
      "episode 4661, reward 114.0, memory_length 2000, epsilon 0.24702406514957467\n",
      "state terminated\n",
      "episode 4662, reward 186.0, memory_length 2000, epsilon 0.24694997204455127\n",
      "state terminated\n",
      "episode 4663, reward 50.0, memory_length 2000, epsilon 0.2468759011641255\n",
      "state terminated\n",
      "episode 4664, reward 42.0, memory_length 2000, epsilon 0.246801852501631\n",
      "state terminated\n",
      "episode 4665, reward 59.0, memory_length 2000, epsilon 0.24672782605040336\n",
      "state terminated\n",
      "episode 4666, reward 189.0, memory_length 2000, epsilon 0.24665382180378026\n",
      "state terminated\n",
      "episode 4667, reward 255.0, memory_length 2000, epsilon 0.2465798397551013\n",
      "state terminated\n",
      "episode 4668, reward -106.0, memory_length 2000, epsilon 0.24650587989770809\n",
      "state terminated\n",
      "episode 4669, reward 8.0, memory_length 2000, epsilon 0.24643194222494422\n",
      "state terminated\n",
      "episode 4670, reward 205.0, memory_length 2000, epsilon 0.24635802673015533\n",
      "state terminated\n",
      "episode 4671, reward 399.0, memory_length 2000, epsilon 0.246284133406689\n",
      "state terminated\n",
      "episode 4672, reward -195.0, memory_length 2000, epsilon 0.24621026224789483\n",
      "state terminated\n",
      "episode 4673, reward 233.0, memory_length 2000, epsilon 0.24613641324712446\n",
      "state terminated\n",
      "episode 4674, reward 198.0, memory_length 2000, epsilon 0.24606258639773143\n",
      "state terminated\n",
      "episode 4675, reward 532.0, memory_length 2000, epsilon 0.24598878169307137\n",
      "state terminated\n",
      "episode 4676, reward 70.0, memory_length 2000, epsilon 0.2459149991265018\n",
      "state terminated\n",
      "episode 4677, reward 371.0, memory_length 2000, epsilon 0.24584123869138233\n",
      "state terminated\n",
      "episode 4678, reward 332.0, memory_length 2000, epsilon 0.24576750038107445\n",
      "state terminated\n",
      "episode 4679, reward 209.0, memory_length 2000, epsilon 0.2456937841889418\n",
      "state terminated\n",
      "episode 4680, reward 323.0, memory_length 2000, epsilon 0.24562009010834995\n",
      "state terminated\n",
      "episode 4681, reward 137.0, memory_length 2000, epsilon 0.24554641813266634\n",
      "state terminated\n",
      "episode 4682, reward -41.0, memory_length 2000, epsilon 0.24547276825526052\n",
      "state terminated\n",
      "episode 4683, reward 283.0, memory_length 2000, epsilon 0.24539914046950403\n",
      "state terminated\n",
      "episode 4684, reward -172.0, memory_length 2000, epsilon 0.24532553476877034\n",
      "state terminated\n",
      "episode 4685, reward 287.0, memory_length 2000, epsilon 0.2452519511464349\n",
      "state terminated\n",
      "episode 4686, reward 73.0, memory_length 2000, epsilon 0.24517838959587526\n",
      "state terminated\n",
      "episode 4687, reward 305.0, memory_length 2000, epsilon 0.24510485011047087\n",
      "state terminated\n",
      "episode 4688, reward 135.0, memory_length 2000, epsilon 0.24503133268360314\n",
      "state terminated\n",
      "episode 4689, reward 0.0, memory_length 2000, epsilon 0.24495783730865553\n",
      "state terminated\n",
      "episode 4690, reward -237.0, memory_length 2000, epsilon 0.24488436397901342\n",
      "state terminated\n",
      "episode 4691, reward 94.0, memory_length 2000, epsilon 0.24481091268806426\n",
      "state terminated\n",
      "episode 4692, reward 41.0, memory_length 2000, epsilon 0.24473748342919735\n",
      "state terminated\n",
      "episode 4693, reward 148.0, memory_length 2000, epsilon 0.24466407619580416\n",
      "state terminated\n",
      "episode 4694, reward -11.0, memory_length 2000, epsilon 0.244590690981278\n",
      "state terminated\n",
      "episode 4695, reward 219.0, memory_length 2000, epsilon 0.2445173277790142\n",
      "state terminated\n",
      "episode 4696, reward 45.0, memory_length 2000, epsilon 0.24444398658241004\n",
      "state terminated\n",
      "episode 4697, reward 197.0, memory_length 2000, epsilon 0.24437066738486485\n",
      "state terminated\n",
      "episode 4698, reward 43.0, memory_length 2000, epsilon 0.24429737017977984\n",
      "state terminated\n",
      "episode 4699, reward 207.0, memory_length 2000, epsilon 0.24422409496055836\n",
      "state terminated\n",
      "episode 4700, reward 279.0, memory_length 2000, epsilon 0.2441508417206056\n",
      "state terminated\n",
      "episode 4701, reward 331.0, memory_length 2000, epsilon 0.24407761045332874\n",
      "state terminated\n",
      "episode 4702, reward 4.0, memory_length 2000, epsilon 0.24400440115213698\n",
      "state terminated\n",
      "episode 4703, reward 233.0, memory_length 2000, epsilon 0.24393121381044153\n",
      "state terminated\n",
      "episode 4704, reward 169.0, memory_length 2000, epsilon 0.24385804842165545\n",
      "state terminated\n",
      "episode 4705, reward 83.0, memory_length 2000, epsilon 0.24378490497919386\n",
      "state terminated\n",
      "episode 4706, reward 54.0, memory_length 2000, epsilon 0.24371178347647393\n",
      "state terminated\n",
      "episode 4707, reward -131.0, memory_length 2000, epsilon 0.24363868390691468\n",
      "state terminated\n",
      "episode 4708, reward 160.0, memory_length 2000, epsilon 0.24356560626393714\n",
      "state terminated\n",
      "episode 4709, reward 513.0, memory_length 2000, epsilon 0.24349255054096433\n",
      "state terminated\n",
      "episode 4710, reward 207.0, memory_length 2000, epsilon 0.24341951673142123\n",
      "state terminated\n",
      "episode 4711, reward -100.0, memory_length 2000, epsilon 0.24334650482873482\n",
      "state terminated\n",
      "episode 4712, reward 133.0, memory_length 2000, epsilon 0.24327351482633391\n",
      "state terminated\n",
      "episode 4713, reward 292.0, memory_length 2000, epsilon 0.2432005467176496\n",
      "state terminated\n",
      "episode 4714, reward -28.0, memory_length 2000, epsilon 0.24312760049611465\n",
      "state terminated\n",
      "episode 4715, reward 80.0, memory_length 2000, epsilon 0.2430546761551639\n",
      "state terminated\n",
      "episode 4716, reward 109.0, memory_length 2000, epsilon 0.24298177368823415\n",
      "state terminated\n",
      "episode 4717, reward 362.0, memory_length 2000, epsilon 0.24290889308876423\n",
      "state terminated\n",
      "episode 4718, reward 178.0, memory_length 2000, epsilon 0.2428360343501948\n",
      "state terminated\n",
      "episode 4719, reward 331.0, memory_length 2000, epsilon 0.24276319746596864\n",
      "state terminated\n",
      "episode 4720, reward 267.0, memory_length 2000, epsilon 0.24269038242953042\n",
      "state terminated\n",
      "episode 4721, reward 139.0, memory_length 2000, epsilon 0.2426175892343268\n",
      "state terminated\n",
      "episode 4722, reward 79.0, memory_length 2000, epsilon 0.24254481787380638\n",
      "state terminated\n",
      "episode 4723, reward 233.0, memory_length 2000, epsilon 0.2424720683414197\n",
      "state terminated\n",
      "episode 4724, reward 75.0, memory_length 2000, epsilon 0.24239934063061938\n",
      "state terminated\n",
      "episode 4725, reward 369.0, memory_length 2000, epsilon 0.2423266347348598\n",
      "state terminated\n",
      "episode 4726, reward 327.0, memory_length 2000, epsilon 0.24225395064759755\n",
      "state terminated\n",
      "episode 4727, reward 212.0, memory_length 2000, epsilon 0.24218128836229105\n",
      "state terminated\n",
      "episode 4728, reward 337.0, memory_length 2000, epsilon 0.2421086478724007\n",
      "state terminated\n",
      "episode 4729, reward 184.0, memory_length 2000, epsilon 0.24203602917138875\n",
      "state terminated\n",
      "episode 4730, reward 241.0, memory_length 2000, epsilon 0.24196343225271963\n",
      "state terminated\n",
      "episode 4731, reward 219.0, memory_length 2000, epsilon 0.24189085710985955\n",
      "state terminated\n",
      "episode 4732, reward 129.0, memory_length 2000, epsilon 0.24181830373627675\n",
      "state terminated\n",
      "episode 4733, reward 178.0, memory_length 2000, epsilon 0.24174577212544146\n",
      "state terminated\n",
      "episode 4734, reward 148.0, memory_length 2000, epsilon 0.24167326227082586\n",
      "state terminated\n",
      "episode 4735, reward 297.0, memory_length 2000, epsilon 0.24160077416590403\n",
      "state terminated\n",
      "episode 4736, reward 308.0, memory_length 2000, epsilon 0.24152830780415202\n",
      "state terminated\n",
      "episode 4737, reward 225.0, memory_length 2000, epsilon 0.2414558631790479\n",
      "state terminated\n",
      "episode 4738, reward -112.0, memory_length 2000, epsilon 0.2413834402840716\n",
      "state terminated\n",
      "episode 4739, reward -41.0, memory_length 2000, epsilon 0.24131103911270507\n",
      "state terminated\n",
      "episode 4740, reward -48.0, memory_length 2000, epsilon 0.24123865965843225\n",
      "state terminated\n",
      "episode 4741, reward 198.0, memory_length 2000, epsilon 0.24116630191473895\n",
      "state terminated\n",
      "episode 4742, reward 16.0, memory_length 2000, epsilon 0.241093965875113\n",
      "state terminated\n",
      "episode 4743, reward 39.0, memory_length 2000, epsilon 0.24102165153304414\n",
      "state terminated\n",
      "episode 4744, reward 341.0, memory_length 2000, epsilon 0.2409493588820241\n",
      "state terminated\n",
      "episode 4745, reward 170.0, memory_length 2000, epsilon 0.2408770879155465\n",
      "state terminated\n",
      "episode 4746, reward -52.0, memory_length 2000, epsilon 0.24080483862710692\n",
      "state terminated\n",
      "episode 4747, reward 38.0, memory_length 2000, epsilon 0.24073261101020302\n",
      "state terminated\n",
      "episode 4748, reward 91.0, memory_length 2000, epsilon 0.2406604050583343\n",
      "state terminated\n",
      "episode 4749, reward 61.0, memory_length 2000, epsilon 0.2405882207650022\n",
      "state terminated\n",
      "episode 4750, reward 399.0, memory_length 2000, epsilon 0.24051605812371013\n",
      "state terminated\n",
      "episode 4751, reward 274.0, memory_length 2000, epsilon 0.24044391712796342\n",
      "state terminated\n",
      "episode 4752, reward 36.0, memory_length 2000, epsilon 0.2403717977712694\n",
      "state terminated\n",
      "episode 4753, reward 133.0, memory_length 2000, epsilon 0.24029970004713735\n",
      "state terminated\n",
      "episode 4754, reward 217.0, memory_length 2000, epsilon 0.2402276239490785\n",
      "state terminated\n",
      "episode 4755, reward 202.0, memory_length 2000, epsilon 0.240155569470606\n",
      "state terminated\n",
      "episode 4756, reward 183.0, memory_length 2000, epsilon 0.24008353660523488\n",
      "state terminated\n",
      "episode 4757, reward 135.0, memory_length 2000, epsilon 0.2400115253464822\n",
      "state terminated\n",
      "episode 4758, reward 13.0, memory_length 2000, epsilon 0.23993953568786697\n",
      "state terminated\n",
      "episode 4759, reward 121.0, memory_length 2000, epsilon 0.23986756762291006\n",
      "state terminated\n",
      "episode 4760, reward 221.0, memory_length 2000, epsilon 0.23979562114513447\n",
      "state terminated\n",
      "episode 4761, reward 101.0, memory_length 2000, epsilon 0.23972369624806494\n",
      "state terminated\n",
      "episode 4762, reward 123.0, memory_length 2000, epsilon 0.23965179292522823\n",
      "state terminated\n",
      "episode 4763, reward 179.0, memory_length 2000, epsilon 0.23957991117015304\n",
      "state terminated\n",
      "episode 4764, reward 158.0, memory_length 2000, epsilon 0.23950805097637\n",
      "state terminated\n",
      "episode 4765, reward 306.0, memory_length 2000, epsilon 0.23943621233741177\n",
      "state terminated\n",
      "episode 4766, reward 144.0, memory_length 2000, epsilon 0.2393643952468127\n",
      "state terminated\n",
      "episode 4767, reward 75.0, memory_length 2000, epsilon 0.23929259969810943\n",
      "state terminated\n",
      "episode 4768, reward 310.0, memory_length 2000, epsilon 0.23922082568484032\n",
      "state terminated\n",
      "episode 4769, reward 144.0, memory_length 2000, epsilon 0.23914907320054565\n",
      "state terminated\n",
      "episode 4770, reward 98.0, memory_length 2000, epsilon 0.23907734223876775\n",
      "state terminated\n",
      "episode 4771, reward 125.0, memory_length 2000, epsilon 0.2390056327930508\n",
      "state terminated\n",
      "episode 4772, reward 29.0, memory_length 2000, epsilon 0.23893394485694092\n",
      "state terminated\n",
      "episode 4773, reward -168.0, memory_length 2000, epsilon 0.23886227842398627\n",
      "state terminated\n",
      "episode 4774, reward 200.0, memory_length 2000, epsilon 0.23879063348773688\n",
      "state terminated\n",
      "episode 4775, reward 132.0, memory_length 2000, epsilon 0.23871901004174464\n",
      "state terminated\n",
      "episode 4776, reward 351.0, memory_length 2000, epsilon 0.23864740807956347\n",
      "state terminated\n",
      "episode 4777, reward 108.0, memory_length 2000, epsilon 0.23857582759474918\n",
      "state terminated\n",
      "episode 4778, reward -159.0, memory_length 2000, epsilon 0.23850426858085955\n",
      "state terminated\n",
      "episode 4779, reward 243.0, memory_length 2000, epsilon 0.23843273103145418\n",
      "state terminated\n",
      "episode 4780, reward 263.0, memory_length 2000, epsilon 0.23836121494009482\n",
      "state terminated\n",
      "episode 4781, reward 63.0, memory_length 2000, epsilon 0.23828972030034495\n",
      "state terminated\n",
      "episode 4782, reward -27.0, memory_length 2000, epsilon 0.2382182471057701\n",
      "state terminated\n",
      "episode 4783, reward 250.0, memory_length 2000, epsilon 0.23814679534993763\n",
      "state terminated\n",
      "episode 4784, reward -51.0, memory_length 2000, epsilon 0.23807536502641694\n",
      "state terminated\n",
      "episode 4785, reward 36.0, memory_length 2000, epsilon 0.23800395612877923\n",
      "state terminated\n",
      "episode 4786, reward 99.0, memory_length 2000, epsilon 0.23793256865059767\n",
      "state terminated\n",
      "episode 4787, reward 329.0, memory_length 2000, epsilon 0.23786120258544755\n",
      "state terminated\n",
      "episode 4788, reward 111.0, memory_length 2000, epsilon 0.23778985792690577\n",
      "state terminated\n",
      "episode 4789, reward 216.0, memory_length 2000, epsilon 0.2377185346685514\n",
      "state terminated\n",
      "episode 4790, reward 258.0, memory_length 2000, epsilon 0.23764723280396527\n",
      "state terminated\n",
      "episode 4791, reward -55.0, memory_length 2000, epsilon 0.2375759523267303\n",
      "state terminated\n",
      "episode 4792, reward 54.0, memory_length 2000, epsilon 0.23750469323043116\n",
      "state terminated\n",
      "episode 4793, reward -142.0, memory_length 2000, epsilon 0.23743345550865452\n",
      "state terminated\n",
      "episode 4794, reward 3.0, memory_length 2000, epsilon 0.2373622391549891\n",
      "state terminated\n",
      "episode 4795, reward 279.0, memory_length 2000, epsilon 0.2372910441630254\n",
      "state terminated\n",
      "episode 4796, reward 36.0, memory_length 2000, epsilon 0.2372198705263558\n",
      "state terminated\n",
      "episode 4797, reward 148.0, memory_length 2000, epsilon 0.2371487182385747\n",
      "state terminated\n",
      "episode 4798, reward 314.0, memory_length 2000, epsilon 0.2370775872932784\n",
      "state terminated\n",
      "episode 4799, reward 120.0, memory_length 2000, epsilon 0.23700647768406508\n",
      "state terminated\n",
      "episode 4800, reward 202.0, memory_length 2000, epsilon 0.23693538940453496\n",
      "state terminated\n",
      "episode 4801, reward 286.0, memory_length 2000, epsilon 0.23686432244829006\n",
      "state terminated\n",
      "episode 4802, reward 79.0, memory_length 2000, epsilon 0.23679327680893433\n",
      "state terminated\n",
      "episode 4803, reward -90.0, memory_length 2000, epsilon 0.23672225248007367\n",
      "state terminated\n",
      "episode 4804, reward 169.0, memory_length 2000, epsilon 0.2366512494553159\n",
      "state terminated\n",
      "episode 4805, reward -133.0, memory_length 2000, epsilon 0.23658026772827073\n",
      "state terminated\n",
      "episode 4806, reward -100.0, memory_length 2000, epsilon 0.23650930729254976\n",
      "state terminated\n",
      "episode 4807, reward 458.0, memory_length 2000, epsilon 0.23643836814176666\n",
      "state terminated\n",
      "episode 4808, reward -282.0, memory_length 2000, epsilon 0.23636745026953687\n",
      "state terminated\n",
      "episode 4809, reward -62.0, memory_length 2000, epsilon 0.23629655366947772\n",
      "state terminated\n",
      "episode 4810, reward -4.0, memory_length 2000, epsilon 0.2362256783352086\n",
      "state terminated\n",
      "episode 4811, reward 354.0, memory_length 2000, epsilon 0.23615482426035067\n",
      "state terminated\n",
      "episode 4812, reward 166.0, memory_length 2000, epsilon 0.23608399143852712\n",
      "state terminated\n",
      "episode 4813, reward -100.0, memory_length 2000, epsilon 0.23601317986336287\n",
      "state terminated\n",
      "episode 4814, reward 8.0, memory_length 2000, epsilon 0.23594238952848504\n",
      "state terminated\n",
      "episode 4815, reward 47.0, memory_length 2000, epsilon 0.23587162042752238\n",
      "state terminated\n",
      "episode 4816, reward 180.0, memory_length 2000, epsilon 0.23580087255410576\n",
      "state terminated\n",
      "episode 4817, reward 134.0, memory_length 2000, epsilon 0.23573014590186783\n",
      "state terminated\n",
      "episode 4818, reward -58.0, memory_length 2000, epsilon 0.23565944046444318\n",
      "state terminated\n",
      "episode 4819, reward 308.0, memory_length 2000, epsilon 0.23558875623546832\n",
      "state terminated\n",
      "episode 4820, reward 45.0, memory_length 2000, epsilon 0.23551809320858164\n",
      "state terminated\n",
      "episode 4821, reward 291.0, memory_length 2000, epsilon 0.2354474513774236\n",
      "state terminated\n",
      "episode 4822, reward 153.0, memory_length 2000, epsilon 0.23537683073563628\n",
      "state terminated\n",
      "episode 4823, reward 169.0, memory_length 2000, epsilon 0.2353062312768639\n",
      "state terminated\n",
      "episode 4824, reward 45.0, memory_length 2000, epsilon 0.2352356529947525\n",
      "state terminated\n",
      "episode 4825, reward 317.0, memory_length 2000, epsilon 0.23516509588295004\n",
      "state terminated\n",
      "episode 4826, reward 324.0, memory_length 2000, epsilon 0.2350945599351063\n",
      "state terminated\n",
      "episode 4827, reward 0.0, memory_length 2000, epsilon 0.23502404514487318\n",
      "state terminated\n",
      "episode 4828, reward 70.0, memory_length 2000, epsilon 0.23495355150590427\n",
      "state terminated\n",
      "episode 4829, reward 143.0, memory_length 2000, epsilon 0.23488307901185515\n",
      "state terminated\n",
      "episode 4830, reward 27.0, memory_length 2000, epsilon 0.23481262765638333\n",
      "state terminated\n",
      "episode 4831, reward -57.0, memory_length 2000, epsilon 0.23474219743314814\n",
      "state terminated\n",
      "episode 4832, reward 172.0, memory_length 2000, epsilon 0.23467178833581084\n",
      "state terminated\n",
      "episode 4833, reward -27.0, memory_length 2000, epsilon 0.23460140035803465\n",
      "state terminated\n",
      "episode 4834, reward 208.0, memory_length 2000, epsilon 0.23453103349348467\n",
      "state terminated\n",
      "episode 4835, reward 108.0, memory_length 2000, epsilon 0.23446068773582787\n",
      "state terminated\n",
      "episode 4836, reward 213.0, memory_length 2000, epsilon 0.23439036307873315\n",
      "state terminated\n",
      "episode 4837, reward 48.0, memory_length 2000, epsilon 0.23432005951587123\n",
      "state terminated\n",
      "episode 4838, reward 81.0, memory_length 2000, epsilon 0.23424977704091482\n",
      "state terminated\n",
      "episode 4839, reward 29.0, memory_length 2000, epsilon 0.23417951564753853\n",
      "state terminated\n",
      "episode 4840, reward 83.0, memory_length 2000, epsilon 0.23410927532941875\n",
      "state terminated\n",
      "episode 4841, reward 7.0, memory_length 2000, epsilon 0.23403905608023395\n",
      "state terminated\n",
      "episode 4842, reward 103.0, memory_length 2000, epsilon 0.23396885789366437\n",
      "state terminated\n",
      "episode 4843, reward 364.0, memory_length 2000, epsilon 0.23389868076339215\n",
      "state terminated\n",
      "episode 4844, reward 87.0, memory_length 2000, epsilon 0.23382852468310134\n",
      "state terminated\n",
      "episode 4845, reward 234.0, memory_length 2000, epsilon 0.23375838964647794\n",
      "state terminated\n",
      "episode 4846, reward 197.0, memory_length 2000, epsilon 0.2336882756472097\n",
      "state terminated\n",
      "episode 4847, reward 233.0, memory_length 2000, epsilon 0.23361818267898649\n",
      "state terminated\n",
      "episode 4848, reward 76.0, memory_length 2000, epsilon 0.23354811073549983\n",
      "state terminated\n",
      "episode 4849, reward 225.0, memory_length 2000, epsilon 0.23347805981044334\n",
      "state terminated\n",
      "episode 4850, reward 198.0, memory_length 2000, epsilon 0.2334080298975124\n",
      "state terminated\n",
      "episode 4851, reward 290.0, memory_length 2000, epsilon 0.23333802099040427\n",
      "state terminated\n",
      "episode 4852, reward 43.0, memory_length 2000, epsilon 0.2332680330828182\n",
      "state terminated\n",
      "episode 4853, reward 57.0, memory_length 2000, epsilon 0.2331980661684552\n",
      "state terminated\n",
      "episode 4854, reward -4.0, memory_length 2000, epsilon 0.2331281202410184\n",
      "state terminated\n",
      "episode 4855, reward 2.0, memory_length 2000, epsilon 0.23305819529421254\n",
      "state terminated\n",
      "episode 4856, reward 173.0, memory_length 2000, epsilon 0.23298829132174445\n",
      "state terminated\n",
      "episode 4857, reward 283.0, memory_length 2000, epsilon 0.23291840831732272\n",
      "state terminated\n",
      "episode 4858, reward 218.0, memory_length 2000, epsilon 0.2328485462746579\n",
      "state terminated\n",
      "episode 4859, reward 35.0, memory_length 2000, epsilon 0.2327787051874624\n",
      "state terminated\n",
      "episode 4860, reward 102.0, memory_length 2000, epsilon 0.23270888504945048\n",
      "state terminated\n",
      "episode 4861, reward 225.0, memory_length 2000, epsilon 0.2326390858543384\n",
      "state terminated\n",
      "episode 4862, reward 337.0, memory_length 2000, epsilon 0.2325693075958442\n",
      "state terminated\n",
      "episode 4863, reward 196.0, memory_length 2000, epsilon 0.23249955026768787\n",
      "state terminated\n",
      "episode 4864, reward 318.0, memory_length 2000, epsilon 0.2324298138635912\n",
      "state terminated\n",
      "episode 4865, reward 125.0, memory_length 2000, epsilon 0.23236009837727795\n",
      "state terminated\n",
      "episode 4866, reward 219.0, memory_length 2000, epsilon 0.2322904038024737\n",
      "state terminated\n",
      "episode 4867, reward 430.0, memory_length 2000, epsilon 0.23222073013290592\n",
      "state terminated\n",
      "episode 4868, reward 325.0, memory_length 2000, epsilon 0.23215107736230403\n",
      "state terminated\n",
      "episode 4869, reward 175.0, memory_length 2000, epsilon 0.23208144548439927\n",
      "state terminated\n",
      "episode 4870, reward 189.0, memory_length 2000, epsilon 0.23201183449292478\n",
      "state terminated\n",
      "episode 4871, reward -31.0, memory_length 2000, epsilon 0.2319422443816155\n",
      "state terminated\n",
      "episode 4872, reward 301.0, memory_length 2000, epsilon 0.23187267514420842\n",
      "state terminated\n",
      "episode 4873, reward -139.0, memory_length 2000, epsilon 0.2318031267744422\n",
      "state terminated\n",
      "episode 4874, reward 360.0, memory_length 2000, epsilon 0.23173359926605758\n",
      "state terminated\n",
      "episode 4875, reward 97.0, memory_length 2000, epsilon 0.23166409261279708\n",
      "state terminated\n",
      "episode 4876, reward -23.0, memory_length 2000, epsilon 0.23159460680840502\n",
      "state terminated\n",
      "episode 4877, reward 22.0, memory_length 2000, epsilon 0.23152514184662779\n",
      "state terminated\n",
      "episode 4878, reward -73.0, memory_length 2000, epsilon 0.23145569772121344\n",
      "state terminated\n",
      "episode 4879, reward 341.0, memory_length 2000, epsilon 0.23138627442591203\n",
      "state terminated\n",
      "episode 4880, reward 164.0, memory_length 2000, epsilon 0.23131687195447548\n",
      "state terminated\n",
      "episode 4881, reward 512.0, memory_length 2000, epsilon 0.23124749030065755\n",
      "state terminated\n",
      "episode 4882, reward 118.0, memory_length 2000, epsilon 0.23117812945821395\n",
      "state terminated\n",
      "episode 4883, reward 180.0, memory_length 2000, epsilon 0.23110878942090213\n",
      "state terminated\n",
      "episode 4884, reward -89.0, memory_length 2000, epsilon 0.23103947018248155\n",
      "state terminated\n",
      "episode 4885, reward 140.0, memory_length 2000, epsilon 0.23097017173671341\n",
      "state terminated\n",
      "episode 4886, reward 200.0, memory_length 2000, epsilon 0.2309008940773609\n",
      "state terminated\n",
      "episode 4887, reward -14.0, memory_length 2000, epsilon 0.23083163719818892\n",
      "state terminated\n",
      "episode 4888, reward 98.0, memory_length 2000, epsilon 0.23076240109296453\n",
      "state terminated\n",
      "episode 4889, reward 184.0, memory_length 2000, epsilon 0.23069318575545641\n",
      "state terminated\n",
      "episode 4890, reward 189.0, memory_length 2000, epsilon 0.23062399117943513\n",
      "state terminated\n",
      "episode 4891, reward 30.0, memory_length 2000, epsilon 0.23055481735867323\n",
      "state terminated\n",
      "episode 4892, reward 246.0, memory_length 2000, epsilon 0.23048566428694503\n",
      "state terminated\n",
      "episode 4893, reward 277.0, memory_length 2000, epsilon 0.23041653195802678\n",
      "state terminated\n",
      "episode 4894, reward 166.0, memory_length 2000, epsilon 0.23034742036569653\n",
      "state terminated\n",
      "episode 4895, reward 202.0, memory_length 2000, epsilon 0.2302783295037343\n",
      "state terminated\n",
      "episode 4896, reward 89.0, memory_length 2000, epsilon 0.2302092593659219\n",
      "state terminated\n",
      "episode 4897, reward 158.0, memory_length 2000, epsilon 0.23014020994604298\n",
      "state terminated\n",
      "episode 4898, reward -19.0, memory_length 2000, epsilon 0.23007118123788312\n",
      "state terminated\n",
      "episode 4899, reward 271.0, memory_length 2000, epsilon 0.23000217323522973\n",
      "state terminated\n",
      "episode 4900, reward 126.0, memory_length 2000, epsilon 0.229933185931872\n",
      "state terminated\n",
      "episode 4901, reward 85.0, memory_length 2000, epsilon 0.22986421932160123\n",
      "state terminated\n",
      "episode 4902, reward 325.0, memory_length 2000, epsilon 0.22979527339821035\n",
      "state terminated\n",
      "episode 4903, reward 179.0, memory_length 2000, epsilon 0.22972634815549425\n",
      "state terminated\n",
      "episode 4904, reward 444.0, memory_length 2000, epsilon 0.22965744358724965\n",
      "state terminated\n",
      "episode 4905, reward 234.0, memory_length 2000, epsilon 0.2295885596872751\n",
      "state terminated\n",
      "episode 4906, reward -34.0, memory_length 2000, epsilon 0.2295196964493711\n",
      "state terminated\n",
      "episode 4907, reward 342.0, memory_length 2000, epsilon 0.22945085386733985\n",
      "state terminated\n",
      "episode 4908, reward -107.0, memory_length 2000, epsilon 0.22938203193498566\n",
      "state terminated\n",
      "episode 4909, reward 105.0, memory_length 2000, epsilon 0.22931323064611453\n",
      "state terminated\n",
      "episode 4910, reward 138.0, memory_length 2000, epsilon 0.2292444499945343\n",
      "state terminated\n",
      "episode 4911, reward 148.0, memory_length 2000, epsilon 0.2291756899740547\n",
      "state terminated\n",
      "episode 4912, reward 29.0, memory_length 2000, epsilon 0.22910695057848737\n",
      "state terminated\n",
      "episode 4913, reward -111.0, memory_length 2000, epsilon 0.22903823180164576\n",
      "state terminated\n",
      "episode 4914, reward -120.0, memory_length 2000, epsilon 0.22896953363734512\n",
      "state terminated\n",
      "episode 4915, reward 211.0, memory_length 2000, epsilon 0.22890085607940266\n",
      "state terminated\n",
      "episode 4916, reward 57.0, memory_length 2000, epsilon 0.22883219912163744\n",
      "state terminated\n",
      "episode 4917, reward 159.0, memory_length 2000, epsilon 0.22876356275787033\n",
      "state terminated\n",
      "episode 4918, reward 468.0, memory_length 2000, epsilon 0.22869494698192397\n",
      "state terminated\n",
      "episode 4919, reward -25.0, memory_length 2000, epsilon 0.228626351787623\n",
      "state terminated\n",
      "episode 4920, reward -23.0, memory_length 2000, epsilon 0.2285577771687938\n",
      "state terminated\n",
      "episode 4921, reward 62.0, memory_length 2000, epsilon 0.22848922311926478\n",
      "state terminated\n",
      "episode 4922, reward 206.0, memory_length 2000, epsilon 0.22842068963286594\n",
      "state terminated\n",
      "episode 4923, reward -258.0, memory_length 2000, epsilon 0.2283521767034294\n",
      "state terminated\n",
      "episode 4924, reward 344.0, memory_length 2000, epsilon 0.22828368432478882\n",
      "state terminated\n",
      "episode 4925, reward 17.0, memory_length 2000, epsilon 0.22821521249078003\n",
      "state terminated\n",
      "episode 4926, reward 381.0, memory_length 2000, epsilon 0.22814676119524052\n",
      "state terminated\n",
      "episode 4927, reward 124.0, memory_length 2000, epsilon 0.22807833043200965\n",
      "state terminated\n",
      "episode 4928, reward -26.0, memory_length 2000, epsilon 0.22800992019492866\n",
      "state terminated\n",
      "episode 4929, reward 530.0, memory_length 2000, epsilon 0.2279415304778407\n",
      "state terminated\n",
      "episode 4930, reward 53.0, memory_length 2000, epsilon 0.22787316127459062\n",
      "state terminated\n",
      "episode 4931, reward 291.0, memory_length 2000, epsilon 0.22780481257902518\n",
      "state terminated\n",
      "episode 4932, reward 403.0, memory_length 2000, epsilon 0.22773648438499305\n",
      "state terminated\n",
      "episode 4933, reward 168.0, memory_length 2000, epsilon 0.22766817668634468\n",
      "state terminated\n",
      "episode 4934, reward 150.0, memory_length 2000, epsilon 0.2275998894769323\n",
      "state terminated\n",
      "episode 4935, reward 303.0, memory_length 2000, epsilon 0.22753162275061017\n",
      "state terminated\n",
      "episode 4936, reward -1.0, memory_length 2000, epsilon 0.22746337650123424\n",
      "state terminated\n",
      "episode 4937, reward 108.0, memory_length 2000, epsilon 0.22739515072266236\n",
      "state terminated\n",
      "episode 4938, reward -3.0, memory_length 2000, epsilon 0.2273269454087542\n",
      "state terminated\n",
      "episode 4939, reward 40.0, memory_length 2000, epsilon 0.22725876055337127\n",
      "state terminated\n",
      "episode 4940, reward 279.0, memory_length 2000, epsilon 0.22719059615037693\n",
      "state terminated\n",
      "episode 4941, reward 238.0, memory_length 2000, epsilon 0.2271224521936364\n",
      "state terminated\n",
      "episode 4942, reward 193.0, memory_length 2000, epsilon 0.22705432867701672\n",
      "state terminated\n",
      "episode 4943, reward -244.0, memory_length 2000, epsilon 0.22698622559438678\n",
      "state terminated\n",
      "episode 4944, reward 16.0, memory_length 2000, epsilon 0.22691814293961732\n",
      "state terminated\n",
      "episode 4945, reward 60.0, memory_length 2000, epsilon 0.22685008070658086\n",
      "state terminated\n",
      "episode 4946, reward 329.0, memory_length 2000, epsilon 0.22678203888915183\n",
      "state terminated\n",
      "episode 4947, reward 91.0, memory_length 2000, epsilon 0.2267140174812064\n",
      "state terminated\n",
      "episode 4948, reward 47.0, memory_length 2000, epsilon 0.22664601647662272\n",
      "state terminated\n",
      "episode 4949, reward 165.0, memory_length 2000, epsilon 0.22657803586928071\n",
      "state terminated\n",
      "episode 4950, reward 372.0, memory_length 2000, epsilon 0.22651007565306205\n",
      "state terminated\n",
      "episode 4951, reward 273.0, memory_length 2000, epsilon 0.22644213582185038\n",
      "state terminated\n",
      "episode 4952, reward 115.0, memory_length 2000, epsilon 0.2263742163695311\n",
      "state terminated\n",
      "episode 4953, reward -50.0, memory_length 2000, epsilon 0.2263063172899914\n",
      "state terminated\n",
      "episode 4954, reward 241.0, memory_length 2000, epsilon 0.22623843857712037\n",
      "state terminated\n",
      "episode 4955, reward 103.0, memory_length 2000, epsilon 0.22617058022480904\n",
      "state terminated\n",
      "episode 4956, reward 7.0, memory_length 2000, epsilon 0.22610274222695007\n",
      "state terminated\n",
      "episode 4957, reward 462.0, memory_length 2000, epsilon 0.22603492457743804\n",
      "state terminated\n",
      "episode 4958, reward 341.0, memory_length 2000, epsilon 0.2259671272701694\n",
      "state terminated\n",
      "episode 4959, reward 94.0, memory_length 2000, epsilon 0.22589935029904232\n",
      "state terminated\n",
      "episode 4960, reward 233.0, memory_length 2000, epsilon 0.22583159365795696\n",
      "state terminated\n",
      "episode 4961, reward 32.0, memory_length 2000, epsilon 0.2257638573408151\n",
      "state terminated\n",
      "episode 4962, reward 283.0, memory_length 2000, epsilon 0.22569614134152066\n",
      "state terminated\n",
      "episode 4963, reward 261.0, memory_length 2000, epsilon 0.22562844565397905\n",
      "state terminated\n",
      "episode 4964, reward 7.0, memory_length 2000, epsilon 0.22556077027209773\n",
      "state terminated\n",
      "episode 4965, reward -54.0, memory_length 2000, epsilon 0.22549311518978588\n",
      "state terminated\n",
      "episode 4966, reward 346.0, memory_length 2000, epsilon 0.2254254804009545\n",
      "state terminated\n",
      "episode 4967, reward 322.0, memory_length 2000, epsilon 0.2253578658995165\n",
      "state terminated\n",
      "episode 4968, reward 263.0, memory_length 2000, epsilon 0.22529027167938664\n",
      "state terminated\n",
      "episode 4969, reward 152.0, memory_length 2000, epsilon 0.22522269773448136\n",
      "state terminated\n",
      "episode 4970, reward -28.0, memory_length 2000, epsilon 0.22515514405871903\n",
      "state terminated\n",
      "episode 4971, reward 390.0, memory_length 2000, epsilon 0.22508761064601984\n",
      "state terminated\n",
      "episode 4972, reward -9.0, memory_length 2000, epsilon 0.22502009749030577\n",
      "state terminated\n",
      "episode 4973, reward 248.0, memory_length 2000, epsilon 0.2249526045855006\n",
      "state terminated\n",
      "episode 4974, reward -24.0, memory_length 2000, epsilon 0.22488513192552995\n",
      "state terminated\n",
      "episode 4975, reward -36.0, memory_length 2000, epsilon 0.22481767950432138\n",
      "state terminated\n",
      "episode 4976, reward 316.0, memory_length 2000, epsilon 0.2247502473158041\n",
      "state terminated\n",
      "episode 4977, reward 179.0, memory_length 2000, epsilon 0.22468283535390923\n",
      "state terminated\n",
      "episode 4978, reward -12.0, memory_length 2000, epsilon 0.22461544361256972\n",
      "state terminated\n",
      "episode 4979, reward 328.0, memory_length 2000, epsilon 0.22454807208572028\n",
      "state terminated\n",
      "episode 4980, reward 133.0, memory_length 2000, epsilon 0.22448072076729744\n",
      "state terminated\n",
      "episode 4981, reward 373.0, memory_length 2000, epsilon 0.2244133896512396\n",
      "state terminated\n",
      "episode 4982, reward 40.0, memory_length 2000, epsilon 0.22434607873148704\n",
      "state terminated\n",
      "episode 4983, reward 102.0, memory_length 2000, epsilon 0.22427878800198173\n",
      "state terminated\n",
      "episode 4984, reward 88.0, memory_length 2000, epsilon 0.22421151745666743\n",
      "state terminated\n",
      "episode 4985, reward 99.0, memory_length 2000, epsilon 0.22414426708948992\n",
      "state terminated\n",
      "episode 4986, reward 183.0, memory_length 2000, epsilon 0.22407703689439656\n",
      "state terminated\n",
      "episode 4987, reward 180.0, memory_length 2000, epsilon 0.2240098268653367\n",
      "state terminated\n",
      "episode 4988, reward 178.0, memory_length 2000, epsilon 0.22394263699626132\n",
      "state terminated\n",
      "episode 4989, reward -280.0, memory_length 2000, epsilon 0.2238754672811235\n",
      "state terminated\n",
      "episode 4990, reward 354.0, memory_length 2000, epsilon 0.22380831771387788\n",
      "state terminated\n",
      "episode 4991, reward 4.0, memory_length 2000, epsilon 0.223741188288481\n",
      "state terminated\n",
      "episode 4992, reward 17.0, memory_length 2000, epsilon 0.22367407899889122\n",
      "state terminated\n",
      "episode 4993, reward -57.0, memory_length 2000, epsilon 0.2236069898390687\n",
      "state terminated\n",
      "episode 4994, reward 333.0, memory_length 2000, epsilon 0.22353992080297536\n",
      "state terminated\n",
      "episode 4995, reward 209.0, memory_length 2000, epsilon 0.2234728718845751\n",
      "state terminated\n",
      "episode 4996, reward 342.0, memory_length 2000, epsilon 0.22340584307783348\n",
      "state terminated\n",
      "episode 4997, reward 90.0, memory_length 2000, epsilon 0.22333883437671787\n",
      "state terminated\n",
      "episode 4998, reward 235.0, memory_length 2000, epsilon 0.2232718457751975\n",
      "state terminated\n",
      "episode 4999, reward 378.0, memory_length 2000, epsilon 0.22320487726724342\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rewards_per_episode, episodes, avg_rewards_per_episode = [], [], []\n",
    "env = CabDriver()\n",
    "agent = DQNAgent(action_size=len(env.action_space), state_size=len(env.state_encod_arch1(env.state_init)))\n",
    "\n",
    "for episode in range(Episodes):\n",
    "    # Call the environment\n",
    "    env = CabDriver()\n",
    "    score = 0\n",
    "    # Call all the initialised variables of the environment\n",
    "    action_space, state_space, state = env.reset()\n",
    "    terminal_state = False\n",
    "    t = 0\n",
    "    count = 1\n",
    "    while not terminal_state:\n",
    "        #print(\"count = {}\".format(count))\n",
    "        count += 1\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        possible_actions_index, actions = env.requests(state)\n",
    "        action_index, action = agent.get_action(env.state_encod_arch1(state), env.action_space, possible_actions_index)\n",
    "        # 2. Evaluate your reward and next state\n",
    "        next_state, wait_time, transit_time, ride_time = env.next_state_func(state, action, Time_matrix)\n",
    "        reward = env.reward_func(state, action, Time_matrix)\n",
    "        # 3. Append the experience to the memory\n",
    "        agent.append_sample(env.state_encod_arch1(state), action_index, reward, env.state_encod_arch1(next_state))\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        agent.train_model()\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "        score += reward\n",
    "        state = next_state\n",
    "        t += wait_time + transit_time + ride_time\n",
    "        if t >= 24 * 30:\n",
    "            print(\"state terminated\")\n",
    "            terminal_state = True\n",
    "\n",
    "    # store total reward obtained in this episode\n",
    "    rewards_per_episode.append(score)\n",
    "    episodes.append(episode)\n",
    "\n",
    "    # epsilon decay\n",
    "    if agent.epsilon > agent.epsilon_min:\n",
    "        agent.epsilon = agent.epsilon_min + (agent.epsilon_max - agent.epsilon_min) * np.exp(-agent.epsilon_decay*episode)\n",
    "\n",
    "    # every episode:\n",
    "    print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3}\".format(episode, score, len(agent.memory), agent.epsilon))\n",
    "    # every few episodes:\n",
    "    if episode % 10 == 0:\n",
    "        # store q-values of some prespecified state-action pairs\n",
    "        agent.store_q_values()\n",
    "    if episode % 1000 == 0:\n",
    "        agent.save(name=\"model.h5\")\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Total time taken ',elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGySAyC3e3wP"
   },
   "source": [
    "Rewards are started increasing after 4000 episodes and if we try to run for more episodes then we can see more rewards. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAE0PJ-cCKLK"
   },
   "source": [
    "## Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1629109049412,
     "user": {
      "displayName": "Prashant Bande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEKnUOejpvS-UF0xdxbhX8fVTa3QebhtPWUxF7QA=s64",
      "userId": "14011116341686666445"
     },
     "user_tz": -330
    },
    "id": "RR3CH-rRCKLK",
    "outputId": "e0b9507b-3120-4a28-9cf1-ad8d6f998c65"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check Convergence by tracking total rewards per episode vs episode number\n",
    "plt.plot(list(range(len(rewards_per_episode))), rewards_per_episode)\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"total rewards\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 584,
     "status": "ok",
     "timestamp": 1629108139454,
     "user": {
      "displayName": "Prashant Bande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEKnUOejpvS-UF0xdxbhX8fVTa3QebhtPWUxF7QA=s64",
      "userId": "14011116341686666445"
     },
     "user_tz": -330
    },
    "id": "1aLqGYYxCKLK",
    "outputId": "156a7816-c7d0-42b7-ce3a-abf047cffc1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-223.09, -198.95, -183.52, -175.6, -179.7, -124.96, -94.16, -92.1, -90.09, -54.44, -84.84, -20.45, -48.69, -45.92, -15.68, -13.2, -1.8, 7.96, -2.15, 30.16, 30.46, 32.69, 38.54, 60.04, 70.5, 82.05, 10.76, 67.3, 32.99, 70.91, 61.61, 87.8, 90.3, 72.84, 105.79, 99.53, 111.1, 104.24, 100.48, 126.02, 136.87, 110.86, 149.45, 130.37, 127.99, 119.01, 149.72, 146.64, 134.23, 148.52]\n"
     ]
    }
   ],
   "source": [
    "# Average reward per 100 episode\n",
    "avg_rewards = []\n",
    "episodes = len(rewards_per_episode)\n",
    "index = 0\n",
    "track_total_reward = 0\n",
    "for episode_number in range(episodes):\n",
    "    if index != 100:\n",
    "        track_total_reward += rewards_per_episode[episode_number]\n",
    "        index += 1\n",
    "    else:\n",
    "        avg_rewards.append(track_total_reward/index)\n",
    "        track_total_reward = rewards_per_episode[episode_number]\n",
    "        index = 1\n",
    "\n",
    "avg_rewards.append(track_total_reward/index)\n",
    "        \n",
    "    \n",
    "print(avg_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1629108143178,
     "user": {
      "displayName": "Prashant Bande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEKnUOejpvS-UF0xdxbhX8fVTa3QebhtPWUxF7QA=s64",
      "userId": "14011116341686666445"
     },
     "user_tz": -330
    },
    "id": "SBqIyGBFCKLK",
    "outputId": "55060139-abeb-405e-cff7-37f470f1dcc6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Check Convergence by tracking average rewards per episode vs episode number\n",
    "plt.plot(list(range(len(avg_rewards))), avg_rewards)\n",
    "plt.ylabel(\"avg rewards\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6Ag0Y7DCKLK"
   },
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCZArgPqCKLL"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1629108153986,
     "user": {
      "displayName": "Prashant Bande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEKnUOejpvS-UF0xdxbhX8fVTa3QebhtPWUxF7QA=s64",
      "userId": "14011116341686666445"
     },
     "user_tz": -330
    },
    "id": "ScVqCOPKCKLL"
   },
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1629108156285,
     "user": {
      "displayName": "Prashant Bande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEKnUOejpvS-UF0xdxbhX8fVTa3QebhtPWUxF7QA=s64",
      "userId": "14011116341686666445"
     },
     "user_tz": -330
    },
    "id": "1M-aLOGECKLM",
    "outputId": "29d34322-655e-4c5d-e443-16f6fd4b35f4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cT7hSKCwCKLN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DQN_Agent_Arch1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
